
@report{chang_bigtable_nodate,
	title = {Bigtable: A Distributed Storage System for Structured Data},
	abstract = {Bigtable is a distributed storage system for managing structured data that is designed to scale to a very large size: petabytes of data across thousands of commodity servers. Many projects at Google store data in Bigtable, including web indexing, Google Earth, and Google Finance. These applications place very different demands on Bigtable, both in terms of data size (from {URLs} to web pages to satellite imagery) and latency requirements (from backend bulk processing to real-time data serving). Despite these varied demands, Bigtable has successfully provided a flexible, high-performance solution for all of these Google products. In this paper we describe the simple data model provided by Bigtable, which gives clients dynamic control over data layout and format, and we describe the design and implementation of Bigtable.},
	author = {Chang, Fay and Dean, Jeffrey and Ghemawat, Sanjay and Hsieh, Wilson C and Wallach, Deborah A and Burrows, Mike and Chandra, Tushar and Fikes, Andrew and Gruber, Robert E},
	keywords = {database, distributed, google, storage},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/EZA32TLS/bigtable-osdi06.pdf:application/pdf},
}

@report{lakshman_cassandra-decentralized_nodate,
	title = {Cassandra-A Decentralized Structured Storage System},
	abstract = {Cassandra is a distributed storage system for managing very large amounts of structured data spread out across many commodity servers, while providing highly available service with no single point of failure. Cassandra aims to run on top of an infrastructure of hundreds of nodes (possibly spread across different data centers). At this scale, small and large components fail continuously. The way Cassandra manages the persistent state in the face of these failures drives the reliability and scalability of the software systems relying on this service. While in many ways Cassandra resembles a database and shares many design and implementation strategies therewith, Cassandra does not support a full rela-tional data model; instead, it provides clients with a simple data model that supports dynamic control over data layout and format. Cassandra system was designed to run on cheap commodity hardware and handle high write through-put while not sacrificing read efficiency.},
	author = {Lakshman, Avinash and Prashant, Facebook and Facebook, Malik},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/799Y9YWJ/cassandra.pdf:application/pdf},
}

@report{jiang_hadoop_nodate,
	title = {Hadoop Scheduling Base On Data Lacality Hadoop Scheduling Base On Data Locality},
	abstract = {In hadoop, the job scheduling is an independent module, users can design their own job scheduler based on their actual application requirements, thereby meet their specific business needs. Currently, hadoop has three schedulers: {FIFO}, computing capacity scheduling and fair scheduling policy, all of them are take task allocation strategy that considerate data locality simply. They neither support data locality well nor fully apply to all cases of jobs scheduling. In this paper, we took the concept of resources-prefetch into consideration, and proposed a job scheduling algorithm based on data locality. By estimate the remaining time to complete a task, compared with the time to transfer a resources block, to preselect candidate nodes for task allocation. Then we preselect a non-local map tasks from the unfinished job queue as resources-prefetch tasks. Getting information of resources blocks of preselected map task, select a nearest resources blocks from the candidate node and transferred to local through network. Thus we would ensure data locality good enough. Eventually, we design a experiment and proved resources-prefetch method can guarantee good job data locality and reduce the time to complete the job to a certain extent.},
	author = {Jiang, Bo and Wu, Jiaying and Shi, Xiuyu and Huang, Ruhuan},
	keywords = {data locality, Hadoop, resources-prefetch, scheduling},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/UUSYBST2/hadoop scheduling base on data locality.pdf:application/pdf},
}

@report{dean_mapreduce_nodate,
	title = {{MapReduce}: Simplified Data Processing on Large Clusters},
	abstract = {{MapReduce} is a programming model and an associated implementation for processing and generating large data sets. Users specify a map function that processes a key/value pair to generate a set of intermediate key/value pairs, and a reduce function that merges all intermediate values associated with the same intermediate key. Many real world tasks are expressible in this model, as shown in the paper. Programs written in this functional style are automatically parallelized and executed on a large cluster of commodity machines. The run-time system takes care of the details of partitioning the input data, scheduling the pro-gram's execution across a set of machines, handling machine failures, and managing the required inter-machine communication. This allows programmers without any experience with parallel and distributed systems to easily utilize the resources of a large distributed system. Our implementation of {MapReduce} runs on a large cluster of commodity machines and is highly scalable: a typical {MapReduce} computation processes many ter-abytes of data on thousands of machines. Programmers find the system easy to use: hundreds of {MapReduce} programs have been implemented and upwards of one thousand {MapReduce} jobs are executed on Google's clusters every day.},
	author = {Dean, Jeffrey and Ghemawat, Sanjay},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/BPDCNQZ3/mapreduce-osdi04.pdf:application/pdf},
}

@book{acm_special_interest_group_in_operating_systems_sosp_2007,
	title = {{SOSP} '07 : proceedings of the 21st {ACM} Symposium on Operating Systems Principles : Stevenson, Washington, {USA} : October 14-17, 2007},
	isbn = {978-1-59593-591-5},
	abstract = {"{ACM} order number 83300706"--Page ii.},
	pagetotal = {367},
	publisher = {Association for Computing Machinery},
	author = {{ACM Special Interest Group in Operating Systems.}},
	date = {2007},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/A52G5E7J/amazon-dynamo-sosp2007.pdf:application/pdf},
}

@inproceedings{verma_large-scale_2015,
	title = {Large-scale cluster management at Google with Borg},
	isbn = {978-1-4503-3238-5},
	doi = {10.1145/2741948.2741964},
	abstract = {Google's Borg system is a cluster manager that runs hundreds of thousands of jobs, from many thousands of different applications, across a number of clusters each with up to tens of thousands of machines. It achieves high utilization by combining admission control, efficient task-packing, over-commitment, and machine sharing with process-level performance isolation. It supports high-availability applications with runtime features that minimize fault-recovery time, and scheduling policies that reduce the probability of correlated failures. Borg simplifies life for its users by offering a declarative job specification language, name service integration, real-time job monitoring, and tools to analyze and simulate system behavior. We present a summary of the Borg system architecture and features, important design decisions, a quantitative analysis of some of its policy decisions, and a qualitative examination of lessons learned from a decade of operational experience with it.},
	booktitle = {Proceedings of the 10th European Conference on Computer Systems, {EuroSys} 2015},
	publisher = {Association for Computing Machinery},
	author = {Verma, Abhishek and Pedrosa, Luis and Korupolu, Madhukar and Oppenheimer, David and Tune, Eric and Wilkes, John},
	date = {2015-04-17},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/N8LYFLIA/google borg.pdf:application/pdf},
}

@report{nishtala_scaling_nodate,
	title = {Scaling Memcache at Facebook},
	abstract = {Memcached is a well known, simple, in-memory caching solution. This paper describes how Facebook leverages memcached as a building block to construct and scale a distributed key-value store that supports the world's largest social network. Our system handles billions of requests per second and holds trillions of items to deliver a rich experience for over a billion users around the world.},
	pages = {385},
	author = {Nishtala, Rajesh and Fugal, Hans and Grimm, Steven and Kwiatkowski, Marc and Lee, Herman and Li, Harry C and Mcelroy, Ryan and Paleczny, Mike and Peek, Daniel and Saab, Paul and Stafford, David and Tung, Tony and Venkataramani, Venkateshwaran},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/U9FZRLQL/scaling memcached.pdf:application/pdf},
}

@report{sichel_price_1913,
	title = {The Price of Nails since 1695: A Window into Economic Change},
	url = {http://www.nber.org/papers/w29617.ack},
	author = {Sichel, Daniel E},
	date = {1913},
	keywords = {and Entrepreneurship, Development of the American Economy, Innovation, Productivity},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/L77Q7KYH/The Price of Nailes Since 1695.pdf:application/pdf},
}

@report{lang_security_nodate,
	title = {Security Keys: Practical Cryptographic Second Factors for the Modern Web},
	url = {https://github.com/google/u2f-},
	abstract = {"Security Keys" are second-factor devices that protect users against phishing and man-in-the-middle attacks. Users carry a single device and can self-register it with any online service that supports the protocol. The devices are simple to implement and deploy, simple to use, privacy preserving, and secure against strong attackers. We have shipped support for Security Keys in the Chrome web browser and in Google's online services. We show that Security Keys lead to both an increased level of security and user satisfaction by analyzing a two year deployment which began within Google and has extended to our consumer-facing web applications. The Security Key design has been standardized by the {FIDO} Alliance, an organization with more than 250 member companies spanning the industry. Currently, Security Keys have been deployed by Google, Dropbox, and {GitHub}. An updated and extended tech report is available at https://github.com/google/u2f-ref-code/docs/{SecurityKeys}\_TechReport.pdf.},
	author = {Lang, Juan and Czeskis, Alexei and Balfanz, Dirk and Schilder, Marius and Srinivas, Sampath},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/4YZLHXBD/security keys.pdf:application/pdf},
}

@book{sigchi_group__us_um3i14_nodate,
	title = {{UM}3I'14 : proceedings of the 2014 {ACM} Workshop on Understanding and Modeling Multiparty, Multimodal Interactions : November 16, 2014, Istanbul, Turkey},
	isbn = {978-1-4503-0652-2},
	abstract = {"Co-located with: {ICMI} 2014."},
	pagetotal = {52},
	author = {{SIGCHI (Group : U.S.)} and {Association for Computing Machinery} and {ACM Digital Library.} and ICMI (Conference) (16th : 2014 : Istanbul, Turkey)},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/TEJXDSWA/Kafka.pdf:application/pdf},
}

@book{usenix_association_proceedings_2004,
	title = {Proceedings of the general track : 2004 {USENIX} Annual Technical Conference, June 27-July 2, 2004, Boston, {MA}, {USA}.},
	isbn = {978-1-931971-21-8},
	pagetotal = {296},
	publisher = {{USENIX} Association},
	author = {{USENIX Association.}},
	date = {2004},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/DF2X7M55/wormhole.pdf:application/pdf},
}

@inproceedings{park_3sigma_2018,
	title = {3Sigma: Distribution-based cluster scheduling for runtime uncertainty},
	volume = {2018-January},
	isbn = {978-1-4503-5584-1},
	doi = {10.1145/3190508.3190515},
	abstract = {The 3Sigma cluster scheduling system uses job runtime histories in a new way. Knowing how long each job will execute enables a scheduler to more effectively pack jobs with diverse time concerns (e.g., deadline vs. the-sooner-the-better) and placement preferences on heterogeneous cluster resources. But, existing schedulers use single-point estimates (e.g., mean or median of a relevant subset of historical runtimes), and we show that they are fragile in the face of real-world estimate error profiles. In particular, analysis of job traces from three different large-scale cluster environments shows that, while the runtimes of many jobs can be predicted well, even state-of-the-art predictors have wide error profiles with 8–23\% of predictions off by a factor of two or more. Instead of reducing relevant history to a single point, 3Sigma schedules jobs based on full distributions of relevant runtime histories and explicitly creates plans that mitigate the effects of anticipated runtime uncertainty. Experiments with workloads derived from the same traces show that 3Sigma greatly outperforms a state-of-the-art scheduler that uses point estimates from a state-of-the-art predictor; in fact, the performance of 3Sigma approaches the end-to-end performance of a scheduler based on a hypothetical, perfect runtime predictor. 3Sigma reduces {SLO} miss rate, increases cluster goodput, and improves or matches latency for best effort jobs.},
	booktitle = {Proceedings of the 13th {EuroSys} Conference, {EuroSys} 2018},
	publisher = {Association for Computing Machinery, Inc},
	author = {Park, Jun Woo and Tumanov, Alexey and Jiang, Angela and Kozuch, Michael A. and Ganger, Gregory R.},
	date = {2018-04-23},
	keywords = {distributed, cluster scheduling},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/EF8AUCDE/3sigma.pdf:application/pdf},
}

@book{amvrosiadis_diversity_nodate,
	title = {On the diversity of cluster workloads and its impact on research results},
	isbn = {978-1-939133-02-1},
	url = {https://www.usenix.org/conference/atc18/presentation/amvrosiadis},
	abstract = {Six years ago, Google released an invaluable set of scheduler logs which has already been used in more than 450 publications. We find that the scarcity of other data sources, however, is leading researchers to overfit their work to Google's dataset characteristics. We demonstrate this overfitting by introducing four new traces from two private and two High Performance Computing ({HPC}) clusters. Our analysis shows that the private cluster workloads, consisting of data analytics jobs expected to be more closely related to the Google workload, display more similarity to the {HPC} cluster workloads. This observation suggests that additional traces should be considered when evaluating the generality of new research. To aid the community in moving forward, we release the four analyzed traces, including: the longest publicly available trace spanning all 61 months of an {HPC} clus-ter's lifetime and a trace from a 300,000-core {HPC} cluster , the largest cluster with a publicly available trace. We present an analysis of the private and {HPC} cluster traces that spans job characteristics, workload heterogeneity, resource utilization, and failure rates. We contrast our findings with the Google trace characteristics and identify affected work in the literature. Finally, we demonstrate the importance of dataset plurality and diversity by evaluating the performance of a job runtime predictor using all four of our traces and the Google trace.},
	author = {Amvrosiadis, George and Woo Park, Jun and Ganger, Gregory R and Gibson, Garth A and Baseman, Elisabeth and {DeBardeleben}, Nathan},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/89DM5FBY/diversity of cluster workloads.pdf:application/pdf},
}

@report{ghemawat_google_2003,
	title = {The Google File System},
	abstract = {We have designed and implemented the Google File System , a scalable distributed file system for large distributed data-intensive applications. It provides fault tolerance while running on inexpensive commodity hardware, and it delivers high aggregate performance to a large number of clients. While sharing many of the same goals as previous distributed file systems, our design has been driven by observations of our application workloads and technological environment , both current and anticipated, that reflect a marked departure from some earlier file system assumptions. This has led us to reexamine traditional choices and explore radically different design points. The file system has successfully met our storage needs. It is widely deployed within Google as the storage platform for the generation and processing of data used by our service as well as research and development efforts that require large data sets. The largest cluster to date provides hundreds of terabytes of storage across thousands of disks on over a thousand machines, and it is concurrently accessed by hundreds of clients. In this paper, we present file system interface extensions designed to support distributed applications, discuss many aspects of our design, and report measurements from both micro-benchmarks and real world use.},
	author = {Ghemawat, Sanjay and Gobioff, Howard and Leung Google, Shun-Tak},
	date = {2003},
	keywords = {clustered storage, D [4]: 3-Distributed file systems General Terms Design, data storage, measurement Keywords Fault tolerance, performance, reliability, scalability},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/9NIVRSX4/gfs-sosp2003.pdf:application/pdf;PDF:/Users/alex/Documents/Zotoro/storage/K2XSIEH2/gfs.pdf:application/pdf},
}

@book{usenix_association_proceedings_2005,
	title = {Proceedings of the 19th Large Installation Systems Administration Conference ({LISA} '05) : December 4-9, 2005, San Diego, {CA}, {USA}},
	isbn = {978-1-931971-38-6},
	pagetotal = {277},
	publisher = {{USENIX} Association},
	author = {{USENIX Association.}},
	date = {2005},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/DBE75FU3/dont cry over spilled records.pdf:application/pdf},
}

@inproceedings{delgado_kairos_2018,
	title = {Kairos: Preemptive data center scheduling without runtime estimates},
	isbn = {978-1-4503-6011-1},
	doi = {10.1145/3267809.3267838},
	abstract = {The vast majority of data center schedulers use task runtime estimates to improve the quality of their scheduling decisions. Knowledge about runtimes allows the schedulers, among other things, to achieve better load balance and to avoid head-of-line blocking. Obtaining accurate runtime estimates is, however, far from trivial, and erroneous estimates lead to sub-optimal scheduling decisions. Techniques to mitigate the effect of inaccurate estimates have shown some success, but the fundamental problem remains. This paper presents Kairos, a novel data center scheduler that assumes no prior information on task runtimes. Kairos introduces a distributed approximation of the Least Attained Service ({LAS}) scheduling policy. Kairos consists of a centralized scheduler and per-node schedulers. The per-node schedulers implement {LAS} for tasks on their node, using preemption as necessary to avoid head-of-line blocking. The centralized scheduler distributes tasks among nodes in a manner that balances the load and imposes on each node a workload in which {LAS} provides favorable performance. We have implemented Kairos in {YARN}. We compare its performance against the {YARN} {FIFO} scheduler and Big-C, an open-source state-of-the-art {YARN}-based scheduler that also uses preemption. Compared to {YARN} {FIFO}, Kairos reduces the median job completion time by 73\% and the 99th percentile by 30\%. Compared to Big-C, the improvements are 37\% for the median and 57\% for the 99th percentile. We evaluate Kairos at scale by implementing it in the Eagle simulator and comparing its performance against Eagle. Kairos improves the 99th percentile of short job completion times by up to 55\% for the Google trace and 85\% for the Yahoo trace.},
	pages = {135--148},
	booktitle = {{SoCC} 2018 - Proceedings of the 2018 {ACM} Symposium on Cloud Computing},
	publisher = {Association for Computing Machinery, Inc},
	author = {Delgado, Pamela and Didona, Diego and Dinu, Florin and Zwaenepoel, Willy},
	date = {2018-10-11},
	keywords = {Cloud computing, Data center, Scheduling},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/4TV424UN/Kairos.pdf:application/pdf},
}

@book{acm_special_interest_group_in_operating_systems_eurosys12_nodate,
	title = {{EuroSys}'12 : proceedings of the {EuroSys} 2012 Conference, April 10-13, 2012, Bern, Switzerland},
	isbn = {978-1-4503-1223-3},
	abstract = {"{ACM} Order Number: 534123"--Copyright page.},
	pagetotal = {379},
	author = {{ACM Special Interest Group in Operating Systems} and {VMware} and {Universität Bern} and {Université de Neuchâtel} and {USENIX Association.} and {Association for Computing Machinery} and EuroSys (Conference), organizer.},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/JB2Z4JVN/Jockey.pdf:application/pdf},
}

@book{usenix_association_papers_2005,
	title = {Papers presented at the Workshop on Wireless Traffic Measurements and Modeling : June 5, 2005, Seattle, {WA}, {USA}},
	isbn = {978-1-931971-33-1},
	pagetotal = {44},
	publisher = {{USENIX} Association},
	author = {{USENIX Association.} and {ACM SIGMOBILE.} and {ACM Special Interest Group in Operating Systems.} and {ACM Digital Library.}},
	date = {2005},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/PJYPGLIM/osdi16-grandl-altruistic.pdf:application/pdf;PDF:/Users/alex/Documents/Zotoro/storage/TKVJ62NG/osdi16-jyothi.pdf:application/pdf},
}

@book{jajoo_this_nodate,
	title = {This paper is included in the Proceedings of the 19th {USENIX} Symposium on Networked Systems Design and Implementation. Open access to the Proceedings of the 19th {USENIX} Symposium on Networked Systems Design and Implementation is sponsored by A Case for Task Sampling based Learning for Cluster Job Scheduling A Case for Task Sampling based Learning for Cluster Job Scheduling},
	isbn = {978-1-939133-27-4},
	url = {https://www.usenix.org/conference/nsdi22/presentation/jajoo},
	abstract = {The ability to accurately estimate job runtime properties allows a scheduler to eeectively schedule jobs. State-of-the-art online cluster job schedulers use history-based learning, which uses past job execution information to estimate the runtime properties of newly arrived jobs. However, with fast-paced development in cluster technology (in both hardware and software) and changing user inputs, job runtime properties can change over time, which lead to inaccurate predictions. In this paper, we explore the potential and limitation of real-time learning of job runtime properties, by proactively sampling and scheduling a small fraction of the tasks of each job. Such a task-sampling-based approach exploits the similarity among runtime properties of the tasks of the same job and is inherently immune to changing job behavior. Our analytical and experimental analysis of 3 production traces with diierent skew and job distribution shows that learning in space can be substantially more accurate. Our simulation and testbed evaluation on Azure of the two learning approaches anchored in a generic job scheduler using 3 production cluster job traces shows that despite its online overhead, learning in space reduces the average Job Completion Time ({JCT}) by 1.28×, 1.56×, and 1.32× compared to the prior-art history-based predictor. Finally, we show how sampling-based learning can be extended to schedule {DAG} jobs and achieve similar speedups over the prior-art history-based predictor.},
	author = {Jajoo, Akshay and Charlie Hu, Y and Lin, Xiaojun and Deng, Nan},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/3RMBHCIH/nsdi22-paper-jajoo_5.pdf:application/pdf},
}

@article{jalaparti_network-aware_2015,
	title = {Network-Aware Scheduling for Data-Parallel Jobs},
	volume = {45},
	issn = {19435819},
	doi = {10.1145/2785956.2787488},
	abstract = {To reduce the impact of network congestion on big data jobs, cluster management frameworks use various heuristics to schedule compute tasks and/or network flows. Most of these schedulers consider the job input data fixed and greedily schedule the tasks and flows that are ready to run. However, a large fraction of production jobs are recurring with predictable characteristics, which allows us to plan ahead for them. Coordinating the placement of data and tasks of these jobs allows for significantly improving their network locality and freeing up bandwidth, which can be used by other jobs running on the cluster. With this intuition, we develop Corral, a scheduling framework that uses characteristics of future workloads to determine an offline schedule which (i) jointly places data and compute to achieve better data locality, and (ii) isolates jobs both spatially (by scheduling them in different parts of the cluster) and temporally, improving their performance. We implement Corral on Apache Yarn, and evaluate it on a 210 machine cluster using production workloads. Compared to Yarn's capacity scheduler, Corral reduces the makespan of these workloads up to 33\% and the median completion time up to 56\%, with 20-90\% reduction in data transferred across racks.},
	pages = {407--420},
	number = {4},
	journaltitle = {Computer Communication Review},
	author = {Jalaparti, Virajith and Bodik, Peter and Menache, Ishai and Rao, Sriram and Makarychev, Konstantin and Caesar, Matthew},
	date = {2015-08-17},
	note = {Publisher: Association for Computing Machinery},
	keywords = {Cluster schedulers, Cross-layer optimization, Data-intensive applications, Joint data and compute placement},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/N3KRBDTJ/p407.pdf:application/pdf},
}

@inproceedings{chung_stratus_2018,
	title = {Stratus: Cost-aware container scheduling in the public cloud},
	isbn = {978-1-4503-6011-1},
	doi = {10.1145/3267809.3267819},
	abstract = {Stratus is a new cluster scheduler specialized for orchestrating batch job execution on virtual clusters, dynamically allocated collections of virtual machine instances on public {IaaS} platforms. Unlike schedulers for conventional clusters, Stratus focuses primarily on dollar cost considerations, since public clouds provide effectively unlimited, highly heterogeneous resources allocated on demand. But, since resources are charged-for while allocated, Stratus aggressively packs tasks onto machines, guided by job runtime estimates, trying to make allocated resources be either mostly full (highly utilized) or empty (so they can be released to save money). Simulation experiments based on cluster workload traces from Google and {TwoSigma} show that Stratus reduces cost by 17–44\% compared to state-of-the-art approaches to virtual cluster scheduling.},
	pages = {121--134},
	booktitle = {{SoCC} 2018 - Proceedings of the 2018 {ACM} Symposium on Cloud Computing},
	publisher = {Association for Computing Machinery, Inc},
	author = {Chung, Andrew and Park, Jun Woo and Ganger, Gregory R.},
	date = {2018-10-11},
	keywords = {Cloud computing, Cluster scheduling, Transient server},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/CYWML87C/p121-Chung.pdf:application/pdf},
}

@inproceedings{grandl_multi-resource_2015,
	title = {Multi-resource packing for cluster schedulers},
	volume = {44},
	isbn = {978-1-4503-2836-4},
	doi = {10.1145/2619239.2626334},
	abstract = {Tasks in modern data-parallel clusters have highly diverse resource requirements along {CPU},memory, disk and network. We {presentTetris}, amulti-resource cluster scheduler that packs tasks to machines based on their requirements of all resource types. Doing so avoids resource fragmentation as well as over-allocation of the resources that are not explicitly allocated, both of which are drawbacks of current schedulers. Tetris adapts heuristics for the multidimensional bin packing problem to the context of cluster schedulers wherein task arrivals and machine availability change in an online manner and wherein task's resource needs change with time and with the machine that the task is placed at. In addition, Tetris improves average job completion time by preferentially serving jobs that have less remaining work. We observe that fair allocations do not o.er the best performance and the above heuristics are compatible with a large class of fairness policies; hence, we show how to simultaneously achieve good performance and fairness. Tracedriven simulations and deployment of our Apache {YARN} prototype on a 250 node cluster show gains of over 30\% in makespan and job completion time while achieving nearly perfect fairness.},
	pages = {455--466},
	booktitle = {Computer Communication Review},
	publisher = {Association for Computing Machinery},
	author = {Grandl, Robert and Ananthanarayanan, Ganesh and Kandula, Srikanth and Rao, Sriram and Akella, Aditya},
	date = {2015-02-25},
	note = {Issue: 4
{ISSN}: 19435819},
	keywords = {Cluster schedulers, Completion time, Fairness, Makespan, Multi-dimensional packing},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/PVFCSGDC/multi-resource packing for cluster schedulers.pdf:application/pdf},
}

@report{corbett_spanner_nodate,
	title = {Spanner: Google's Globally-Distributed Database},
	abstract = {Spanner is Google's scalable, multi-version, globally-distributed, and synchronously-replicated database. It is the first system to distribute data at global scale and support externally-consistent distributed transactions. This paper describes how Spanner is structured, its feature set, the rationale underlying various design decisions, and a novel time {API} that exposes clock uncertainty. This {API} and its implementation are critical to supporting external consistency and a variety of powerful features: non-blocking reads in the past, lock-free read-only transactions , and atomic schema changes, across all of Spanner.},
	author = {Corbett, James C and Dean, Jeffrey and Epstein, Michael and Fikes, Andrew and Frost, Christopher and Furman, J J and Ghemawat, Sanjay and Gubarev, Andrey and Heiser, Christopher and Hochschild, Peter and Hsieh, Wilson and Kanthak, Sebastian and Kogan, Eugene and Li, Hongyi and Lloyd, Alexander and Melnik, Sergey and Mwaura, David and Nagle, David and Quinlan, Sean and Rao, Rajesh and Rolig, Lindsay and Saito, Yasushi and Szymaniak, Michal and Taylor, Christopher and Wang, Ruth and Woodford, Dale},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/K9DZU795/spanner-osdi2012.pdf:application/pdf},
}

@book{imperial_college_eurosys_nodate,
	title = {{EuroSys} 2016 : proceedings of the Eleventh European Conference on Computer Systems : April 18-21, 2016, London, United Kingdom.},
	isbn = {978-1-4503-4240-7},
	pagetotal = {605},
	author = {Imperial College, London and {Association for Computing Machinery} and {ACM Special Interest Group in Operating Systems.}},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/7MLU8MRB/tetrisched-tumanov-eurosys16.pdf:application/pdf},
}

@inproceedings{isard_dryad_2007,
	title = {Dryad: Distributed data-parallel programs from sequential building blocks},
	doi = {10.1145/1272996.1273005},
	abstract = {Dryad is a general-purpose distributed execution engine for coarse-grain data-parallel applications. A Dryad application combines computational "vertices" with communication "channels" to form a dataflow graph. Dryad runs the application by executing the vertices of this graph on a set of available computers, communicating as appropriate through flies, {TCP} pipes, and shared-memory {FIFOs}. The vertices provided by the application developer are quite simple and are usually written as sequential programs with no thread creation or locking. Concurrency arises from Dryad scheduling vertices to run simultaneously on multiple computers, or on multiple {CPU} cores within a computer. The application can discover the size and placement of data at run time, and modify the graph as the computation progresses to make efficient use of the available resources. Dryad is designed to scale from powerful multi-core single computers, through small clusters of computers, to data centers with thousands of computers. The Dryad execution engine handles all the difficult problems of creating a large distributed, concurrent application: scheduling the use of computers and their {CPUs}, recovering from communication or computer failures, and transporting data between vertices. Copyright 2007 {ACM}.},
	booktitle = {Operating Systems Review ({ACM})},
	author = {Isard, Michael and Budiu, Mihai and Yu, Yuan and Birrell, Andrew and Fetterly, Dennis},
	date = {2007},
	note = {{ISSN}: 01635980},
}

@inproceedings{hindman_mesos_2011,
	title = {Mesos: A platform for fine-grained resource sharing in the data center},
	abstract = {We present Mesos, a platform for sharing commodity clusters between multiple diverse cluster computing frameworks, such as Hadoop and {MPI}. Sharing improves cluster utilization and avoids per-framework data replication. Mesos shares resources in a fine-grained manner, allowing frameworks to achieve data locality by taking turns reading data stored on each machine. To support the sophisticated schedulers of today's frameworks, Mesos introduces a distributed two-level scheduling mechanism called resource offers. Mesos decides how many resources to offer each framework, while frameworks decide which resources to accept and which computations to run on them. Our results show that Mesos can achieve near-optimal data locality when sharing the cluster among diverse frameworks, can scale to 50,000 (emulated) nodes, and is resilient to failures.},
	booktitle = {Proceedings of {NSDI} 2011: 8th {USENIX} Symposium on Networked Systems Design and Implementation},
	author = {Hindman, Benjamin and Konwinski, Andy and Zaharia, Matei and Ghodsi, Ali and Joseph, Anthony D. and Katz, Randy and Shenker, Scott and Stoica, Ion},
	date = {2011},
}

@inproceedings{buyya_nimrodg_2000,
	title = {Nimrod/G: An architecture for a resource management and scheduling system in a global computational grid},
	volume = {1},
	doi = {10.1109/HPC.2000.846563},
	abstract = {The availability of powerful microprocessors and high-speed networks as commodity components has enabled high-performance computing on distributed systems (wide-area cluster computing). In this environment, as the resources are usually distributed geographically at various levels (department, enterprise or worldwide), there is a great challenge in integrating, coordinating and presenting them as a single resource to the user, thus forming a computational grid. Another challenge comes from the distributed ownership of resources, with each resource having its own access policy, cost and mechanism. The proposed Nimrod/G grid-enabled resource management and scheduling system builds on our earlier work on Nimrod (D. Abramson et al., 1994, 1995, 1997, 2000) and follows a modular and component-based architecture enabling extensibility, portability, ease of development, and interoperability of independently developed components. It uses the {GUSTO} ({GlobUS} {TOolkit}) services and can be easily extended to operate with any other emerging grid middleware services. It focuses on the management and scheduling of computations over dynamic resources scattered geographically across the Internet at department, enterprise or global levels, with particular emphasis on developing scheduling schemes based on the concept of computational economy for a real testbed, namely the Globus testbed ({GUSTO}).},
	booktitle = {Proceedings - 4th International Conference/Exhibition on High Performance Computing in the Asia-Pacific Region, {HPC}-Asia 2000},
	author = {Buyya, R. and Abramson, D. and Giddy, J.},
	date = {2000},
}

@inproceedings{isard_quincy_2009,
	title = {Quincy: Fair scheduling for distributed computing clusters},
	doi = {10.1145/1629575.1629601},
	abstract = {This paper addresses the problem of scheduling concurrent jobs on clusters where application data is stored on the computing nodes. This setting, in which scheduling computations close to their data is crucial for performance, is increasingly common and arises in systems such as {MapReduce}, Hadoop, and Dryad as well as many grid-computing environments. We argue that data-intensive computation benefits from a fine-grain resource sharing model that differs from the coarser semi-static resource allocations implemented by most existing cluster computing architectures. The problem of scheduling with locality and fairness constraints has not previously been extensively studied under this resource-sharing model. We introduce a powerful and flexible new framework for scheduling concurrent distributed jobs with fine-grain resource sharing. The scheduling problem is mapped to a graph datastructure, where edge weights and capacities encode the competing demands of data locality, fairness, and starvation-freedom, and a standard solver computes the optimal online schedule according to a global cost model. We evaluate our implementation of this framework, which we call Quincy, on a cluster of a few hundred computers using a varied workload of data-and {CPU}-intensive jobs. We evaluate Quincy against an existing queue-based algorithm and implement several policies for each scheduler, with and without fairness constraints. Quincy gets better fairness when fairness is requested, while substantially improving data locality. The volume of data transferred across the cluster is reduced by up to a factor of 3.9 in our experiments, leading to a throughput increase of up to 40\%. Copyright 2009 {ACM}.},
	booktitle = {{SOSP}'09 - Proceedings of the 22nd {ACM} {SIGOPS} Symposium on Operating Systems Principles},
	author = {Isard, Michael and Prabhakaran, Vijayan and Currey, Jon and Wieder, Udi and Talwar, Kunal and Goldberg, Andrew},
	date = {2009},
}

@inproceedings{ousterhout_sparrow_2013,
	title = {Sparrow: Distributed, low latency scheduling},
	doi = {10.1145/2517349.2522716},
	abstract = {Large-scale data analytics frameworks are shifting towards shorter task durations and larger degrees of parallelism to provide low latency. Scheduling highly parallel jobs that complete in hundreds of milliseconds poses a major challenge for task schedulers, which will need to schedule millions of tasks per second on appropriate machines while offering millisecond-level latency and high availability. We demonstrate that a decentralized, randomized sampling approach provides near-optimal performance while avoiding the throughput and availability limitations of a centralized design. We implement and deploy our scheduler, Sparrow, on a 110-machine cluster and demonstrate that Sparrow performs within 12\% of an ideal scheduler. © 2013 {ACM}.},
	booktitle = {{SOSP} 2013 - Proceedings of the 24th {ACM} Symposium on Operating Systems Principles},
	author = {Ousterhout, Kay and Wendell, Patrick and Zaharia, Matei and Stoica, Ion},
	date = {2013},
}

@article{ge_powerpack_2010,
	title = {{PowerPack}: Energy profiling and analysis of high-performance systems and applications},
	volume = {21},
	issn = {10459219},
	doi = {10.1109/TPDS.2009.76},
	abstract = {Energy efficiency is a major concern in modern high-performance computing system design. In the past few years, there has been mounting evidence that power usage limits system scale and computing density, and thus, ultimately system performance. However, despite the impact of power and energy on the computer systems community, few studies provide insight to where and how power is consumed on high-performance systems and applications. In previous work, we designed a framework called {PowerPack} that was the first tool to isolate the power consumption of devices including disks, memory, {NICs}, and processors in a high-performance cluster and correlate these measurements to application functions. In this work, we extend our framework to support systems with multicore, multiprocessor-based nodes, and then provide in-depth analyses of the energy consumption of parallel applications on clusters of these systems. These analyses include the impacts of chip multiprocessing on power and energy efficiency, and its interaction with application executions. In addition, we use {PowerPack} to study the power dynamics and energy efficiencies of dynamic voltage and frequency scaling ({DVFS}) techniques on clusters. Our experiments reveal conclusively how intelligent {DVFS} scheduling can enhance system energy efficiency while maintaining performance. © 2010 {IEEE}.},
	number = {5},
	journaltitle = {{IEEE} Transactions on Parallel and Distributed Systems},
	author = {Ge, Rong and Feng, Xizhou and Song, Shuaiwen and Chang, Hung Ching and Li, Dong and Cameron, Kirk W.},
	date = {2010},
}

@inproceedings{thomson_calvin_2012,
	title = {Calvin: Fast distributed transactions for partitioned database systems},
	doi = {10.1145/2213836.2213838},
	abstract = {Many distributed storage systems achieve high data access throughput via partitioning and replication, each system with its own advantages and tradeoffs. In order to achieve high scalability, however, today's systems generally reduce transactional support, disallowing single transactions from spanning multiple partitions. Calvin is a practical transaction scheduling and data replication layer that uses a deterministic ordering guarantee to significantly reduce the normally prohibitive contention costs associated with distributed transactions. Unlike previous deterministic database system prototypes, Calvin supports disk-based storage, scales near-linearly on a cluster of commodity machines, and has no single point of failure. By replicating transaction inputs rather than effects, Calvin is also able to support multiple consistency levels - including Paxos-based strong consistency across geographically distant replicas - at no cost to transactional throughput. © 2012 {ACM}.},
	booktitle = {Proceedings of the {ACM} {SIGMOD} International Conference on Management of Data},
	author = {Thomson, Alexander and Diamond, Thaddeus and Weng, Shu Chun and Ren, Kun and Shao, Philip and Abadi, Daniel J.},
	date = {2012},
	note = {{ISSN}: 07308078},
}

@inproceedings{shafer_hadoop_2010,
	title = {The Hadoop distributed filesystem: Balancing portability and performance},
	doi = {10.1109/ISPASS.2010.5452045},
	abstract = {Hadoop is a popular open-source implementation of {MapReduce} for the analysis of large datasets. To manage storage resources across the cluster, Hadoop uses a distributed user-level filesystem. This filesystem - {HDFS} - is written in Java and designed for portability across heterogeneous hardware and software platforms. This paper analyzes the performance of {HDFS} and uncovers several performance issues. First, architectural bottlenecks exist in the Hadoop implementation that result in inefficient {HDFS} usage due to delays in scheduling new {MapReduce} tasks. Second, portability limitations prevent the Java implementation from exploiting features of the native platform. Third, {HDFS} implicitly makes portability assumptions about how the native platform manages storage resources, even though native filesystems and I/O schedulers vary widely in design and behavior. This paper investigates the root causes of these performance bottlenecks in order to evaluate tradeoffs between portability and performance in the Hadoop distributed filesystem. ©2010 {IEEE}.},
	booktitle = {{ISPASS} 2010 - {IEEE} International Symposium on Performance Analysis of Systems and Software},
	author = {Shafer, Jeffrey and Rixner, Scott and Cox, Alan L.},
	date = {2010},
}

@inproceedings{boutin_apollo_2014,
	title = {Apollo: Scalable and coordinated scheduling for cloud-scale computing},
	abstract = {Efficiently scheduling data-parallel computation jobs over cloud-scale computing clusters is critical for job performance, system throughput, and resource utilization. It is becoming even more challenging with growing cluster sizes and more complex workloads with diverse characteristics. This paper presents Apollo, a highly scalable and coordinated scheduling framework, which has been deployed on production clusters at Microsoft to schedule thousands of computations with millions of tasks efficiently and effectively on tens of thousands of machines daily. The framework performs scheduling decisions in a distributed manner, utilizing global cluster information via a loosely coordinated mechanism. Each scheduling decision considers future resource availability and optimizes various performance and system factors together in a single unified model. Apollo is robust, with means to cope with unexpected system dynamics, and can take advantage of idle system resources gracefully while supplying guaranteed resources when needed.},
	booktitle = {Proceedings of the 11th {USENIX} Symposium on Operating Systems Design and Implementation, {OSDI} 2014},
	author = {Boutin, Eric and Ekanayake, Jaliya and Lin, Wei and Shi, Bing and Zhou, Jingren and Qian, Zhengping and Wu, Ming and Zhou, Lidong},
	date = {2014},
}

@article{sugiharat_reliable_2008,
	title = {Reliable cache architectures and task scheduling for multiprocessor systems},
	volume = {E91-C},
	issn = {17451353},
	doi = {10.1093/ietele/e91-c.4.410},
	abstract = {This paper proposes a task scheduling approach for reliable cache architectures ({RCAs}) of multiprocessor systems. The {RCAs} dynamically switch their operation modes for reducing the usage of vulnerable {SRAMs} under real-time constraints. A mixed integer programming model has been built for minimizing vulnerability under real-time constraints. Experimental results have shown that our task scheduling approach achieved 47.7 99,9\% less vulnerability than a conventional one. Copyright © 2008 The Institute of Electronics, Information and Communication Engineers.},
	pages = {410--417},
	number = {4},
	journaltitle = {{IEICE} Transactions on Electronics},
	author = {Sugiharat, Makoto and Ishihara, Tohru and Murakami, Kazuaki},
	date = {2008},
	note = {Publisher: Institute of Electronics, Information and Communication, Engineers, {IEICE}},
	keywords = {Cache architecture, {DRAM}, Reliability, {SIMM}, Single event upset, Task scheduling},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/DNE6THIJ/Task_Scheduling_for_Reliable_Cache_Architectures_o.pdf:application/pdf},
}

@article{berg_towards_2017,
	title = {Towards Optimality in Parallel Scheduling},
	volume = {1},
	doi = {10.1145/3154499},
	abstract = {To keep pace with Moore's law, chip designers have focused on increasing the number of cores per chip rather than single core performance. In turn, modern jobs are often designed to run on any number of cores. However, to effectively leverage these multi-core chips, one must address the question of how many cores to assign to each job. Given that jobs receive sublinear speedups from additional cores, there is an obvious tradeoff: allocating more cores to an individual job reduces the job's runtime, but in turn decreases the efficiency of the overall system. We ask how the system should schedule jobs across cores so as to minimize the mean response time over a stream of incoming jobs.To answer this question, we develop an analytical model of jobs running on a multi-core machine. We prove that {EQUI}, a policy which continuously divides cores evenly across jobs, is optimal when all jobs follow a single speedup curve and have exponentially distributed sizes. {EQUI} requires jobs to change their level of parallelization while they run. Since this is not possible for all workloads, we consider a class of "fixed-width" policies, which choose a single level of parallelization, k, to use for all jobs. We prove that, surprisingly, it is possible to achieve {EQUI}'s performance without requiring jobs to change their levels of parallelization by using the optimal fixed level of parallelization, k*. We also show how to analytically derive the optimal k* as a function of the system load, the speedup curve, and the job size distribution.In the case where jobs may follow different speedup curves, finding a good scheduling policy is even more challenging. In particular, we find that policies like {EQUI} which performed well in the case of a single speedup function now perform poorly. We propose a very simple policy, {GREEDY}*, which performs near-optimally when compared to the numerically-derived optimal policy.},
	pages = {1--30},
	number = {2},
	journaltitle = {Proceedings of the {ACM} on Measurement and Analysis of Computing Systems},
	author = {Berg, Benjamin and Dorsman, Jan-Pieter and Harchol-Balter, Mor},
	date = {2017-12-19},
	eprinttype = {arxiv},
	eprint = {1707.07097},
	note = {Publisher: Association for Computing Machinery ({ACM})},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/RPM3XZVE/Sigmetrics18a.pdf:application/pdf},
}

@report{ongaro_search_nodate,
	title = {In Search of an Understandable Consensus Algorithm (Extended Version)},
	abstract = {Raft is a consensus algorithm for managing a replicated log. It produces a result equivalent to (multi-)Paxos, and it is as efficient as Paxos, but its structure is different from Paxos; this makes Raft more understandable than Paxos and also provides a better foundation for building practical systems. In order to enhance understandabil-ity, Raft separates the key elements of consensus, such as leader election, log replication, and safety, and it enforces a stronger degree of coherency to reduce the number of states that must be considered. Results from a user study demonstrate that Raft is easier for students to learn than Paxos. Raft also includes a new mechanism for changing the cluster membership, which uses overlapping majorities to guarantee safety.},
	author = {Ongaro, Diego and Ousterhout, John},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/PPFWQG95/raft.pdf:application/pdf},
}

@report{ongaro_consensus_2014,
	title = {{CONSENSUS}: {BRIDGING} {THEORY} {AND} {PRACTICE} A {DISSERTATION} {SUBMITTED} {TO} {THE} {DEPARTMENT} {OF} {COMPUTER} {SCIENCE} {AND} {THE} {COMMITTEE} {ON} {GRADUATE} {STUDIES} {OF} {STANFORD} {UNIVERSITY} {IN} {PARTIAL} {FULFILLMENT} {OF} {THE} {REQUIREMENTS} {FOR} {THE} {DEGREE} {OF} {DOCTOR} {OF} {PHILOSOPHY}},
	url = {http://purl.stanford.edu/qr033xr6097},
	author = {Ongaro, Diego},
	date = {2014},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/QD9RE57Y/concensus_bridging theory and practice.pdf:application/pdf},
}

@report{lamport_byzantine_1982,
	title = {The Byzantine Generals Problem},
	abstract = {Reliable computer systems must handle malfunctioning components that give conflicting information to different parts of the system. This situation can be expressed abstractly in terms of a group of generals of the Byzantine army camped with their troops around an enemy city. Communicating only by messenger, the generals must agree upon a common battle plan. However, one or more of them may be traitors who will try to confuse the others. The problem is to find an algorithm to ensure that the loyal generals will reach agreement. It is shown that, using only oral messages, this problem is solvable if and only if more than two-thirds of the generals are loyal; so a single traitor can confound two loyal generals. With unforgeable written messages, the problem is solvable for any number of generals and possible traitors. Applications of the solutions to reliable computer systems are then discussed.},
	author = {Lamport, Leslie and Shostak, Robert and Pease, Marshall},
	date = {1982},
	keywords = {★, C24 [Computer-Communication Networks]: Distributed Systems-network operating systems, D44 [Operating Systems]: Communications Management-network communication, D45 [Operating Systems]: Reliability-fault tolerance General Terms: Algorithms, Reliability Additional Key Words and Phrases: Interactive consistency /},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/SPWKM9ZS/byz.pdf:application/pdf},
}

@book{shasha_proceedings_2008,
	title = {Proceedings of the 2008 {ACM} {SIGMOD} International Conference on Management of Data : 2008, Vancouver, Canada, June 09-12, 2008},
	isbn = {978-1-60558-102-6},
	abstract = {Title from title screen (viewed July 17, 2009). Order number: 475082.},
	pagetotal = {1378},
	publisher = {Association for Computing Machinery},
	author = {Shasha, Dennis. and Wang, Jason T. L. and {Association for Computing Machinery.} and {Association for Computing Machinery. Special Interest Group on Management of Data.} and {ACM Digital Library.}},
	date = {2008},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/4575ZD2C/fekete-sigmod2008.pdf:application/pdf;PDF:/Users/alex/Documents/Zotoro/storage/JX8Q39KI/p539-moerkotte.pdf:application/pdf},
}

@article{noauthor_sagas_nodate,
	title = {sagas},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/9TD43RIS/sagas.pdf:application/pdf},
}

@article{duran-nebreda_dilution_2022,
	title = {Dilution of expertise in the rise and fall of collective innovation},
	volume = {9},
	issn = {2662-9992},
	doi = {10.1057/s41599-022-01380-5},
	abstract = {{\textless}p{\textgreater}Diversity drives both biological and artificial evolution. A prevalent assumption in cultural evolution is that the generation of novel features is an inherent property of a subset of the population (e.g., experts). In contrast, diversity—the fraction of objects in the corpus that are unique—exhibits complex collective dynamics such as oscillations that cannot be simply reduced to individual attributes. Here, we explore how a popular cultural domain can rapidly expand to the point where it exceeds the supply of subject-specific experts and the balance favours imitation over invention. At this point, we expect diversity to decrease and information redundancy to increase as ideas are increasingly copied rather than invented. We test our model predictions on three case studies: early personal computers and home consoles, social media posts, and cryptocurrencies. Each example exhibits a relatively abrupt departure from standard diffusion models during the exponential increase in the number of imitators. We attribute this transition to the “dilution of expertise.” Our model recreates observed patterns of diversity, complexity and artifact trait distributions, as well as the collective boom-and-bust dynamics of innovation.{\textless}/p{\textgreater}},
	pages = {365},
	number = {1},
	journaltitle = {Humanities and Social Sciences Communications},
	author = {Duran-Nebreda, Salva and O’Brien, Michael J. and Bentley, R. Alexander and Valverde, Sergi},
	date = {2022-10-12},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/PJ8YHS58/s41599-022-01380-5.pdf:application/pdf},
}

@report{wolfson_geometric_1997,
	title = {Geometric Hashing: An Overview},
	abstract = {O bject recognition is the ultimate goal of most computer vision research. An ideal object recognition system should be able to recognize objects in an image that are partially occluded or have undergone geometric transformations. Most systems will use a large database of models and apply model-based recognition. Say you want to give a robot the ability to recognize all objects and tools on a factory floor. If there are only a few hundred objects, you could design a database of these objects and store it in the robot's memory. When the robot receives a sensory image of its environment from a video camera or a range sensor, it should be able to quickly retrieve from memory objects that appear in the image. Although quite natural in human vision, this task in a robot requires the solution of several complicated problems: 1. The objects in the acquired scene appear rotated and translated relative to their initial database position, and the whole scene undergoes a sensor-dependent transformation, such as the projective transformation of a video camera. 2. The objects in the scene may partially occlude each other, and the scene may include additional objects not included in the database. 3. It is computationally inefficient to retrieve each individual object from the database and compare it against the observed scene in search of a match. For example, if the scene contains only round objects, it does not make sense to retrieve rectangular objects to match against it. We need a method that allows direct access to only the relevant information-such as an indexing-based approach. For example, if you are looking for words in long strings of text, you could use a table accessed by indices that are functions of individual words. The table contains the strings where the word appears and the location of the word in the strings. It would be easy then to locate a word by retrieving all of its appearances from the table. This kind of approach was originally proposed for geometric object recognition, making use of indices based on local geometric features that remained invariant to the object transformation. The features were local to handle partial occlusion, and their indexing function was invariant to the relevant transformation, because unlike words in text, geometric features have both location and orientation. For over a decade now, indexing-based approaches have been gaining ground as the method of choice for building working recognition systems that can Geometric hashing, a technique originally developed in computer vision for matching geometric features against a database of such features, finds use in a number of other areas. Matching is possible even when the recognizable database objects have undergone transformations or when only partial information is present. The technique is highly efficient and of low polynomial complexity. ♦ .},
	author = {Wolfson, Haim J},
	date = {1997},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/XW3VIKUM/paper_geohash.pdf:application/pdf},
}

@book{acm_special_interest_group_on_programming_languages_flumejava_2010,
	title = {{FlumeJava}: Easy, Efficient Data-Parallel Pipelines},
	isbn = {978-1-4503-0019-3},
	pagetotal = {497},
	publisher = {Association for Computing Machinery},
	author = {{ACM Special Interest Group on Programming Languages.} and {ACM Sigsoft.} and {Association for Computing Machinery.}},
	date = {2010},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/K7EFKB2C/flume.pdf:application/pdf},
}

@article{zhang_succinct_2019,
	title = {Succinct range filters},
	volume = {48},
	issn = {01635808},
	doi = {10.1145/3183713.3196931},
	abstract = {We present the Succinct Range Filter ({SuRF}), a fast and compact data structure for approximate membership tests. Unlike traditional Bloom filters, {SuRF} supports both single-key lookups and common range queries. {SuRF} is based on a new data structure called the Fast Succinct Trie ({FST}) that matches the point and range query performance of state-of-the-art order-preserving indexes, while consuming only 10 bits per trie node. The false positive rates in {SuRF} for both point and range queries are tunable to satisfy different application needs. We evaluate {SuRF} in {RocksDB} as a replacement for its Bloom filters to reduce I/O by filtering requests before they access on-disk data structures. Our experiments on a 100 {GB} dataset show that replacing {RocksDB}'s Bloom filters with {SuRFs} speeds up open-seek (without upper-bound) and closed-seek (with upper-bound) queries by up to 1.5× and 5× with a modest cost on the worst-case (all-missing) point query throughput due to slightly higher false positive rate.},
	pages = {78--85},
	number = {1},
	journaltitle = {{SIGMOD} Record},
	author = {Zhang, Huanchen and Lim, Hyeontaek and Leise, Viktor and Andersen, David G. and Kaminsky, Michael and Keeton, Kimberly and Pavlo, Andrew},
	date = {2019-03-01},
	note = {Publisher: Association for Computing Machinery},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/K3KEE56P/succint_range_filters.pdf:application/pdf},
}

@report{michael_simple_nodate,
	title = {Simple, Fast, and Practical Non-Blocking and Blocking Concurrent Queue Algorithms},
	abstract = {Drawing ideas from previous authors, we present a new non-blocking concurrent queue algorithm and a new two-lock queue algorithm in which one enqueue and one de-queue can proceed concurrently. Both algorithms are simple , fast, and practical; we were surprised not to find them in the literature. Experiments on a 12-node {SGI} Challenge multiprocessor indicate that the new non-blocking queue consistently outperforms the best known alternatives; it is the clear algorithm of choice for machines that provide a universal atomic primitive (e.g. compare and swap or load linked/store conditional). The two-lock concurrent queue outperforms a single lock when several processes are competing simultaneously for access; it appears to be the algorithm of choice for busy queues on machines with non-universal atomic primitives (e.g. test and set). Since much of the motivation for non-blocking algorithms is rooted in their immunity to large, unpredictable delays in process execution, we report experimental results both for systems with dedicated processors and for systems with several processes multiprogrammed on each processor.},
	author = {Michael, Maged M and Scott, Michael L},
	keywords = {compare and swap, concurrent queue, lock-free, multiprogramming, non-blocking},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/YZDL6DJ7/1996_PODC_queues.pdf:application/pdf},
}

@report{moerkotte_small_nodate,
	title = {Small Materialized Aggregates: A Light Weight Index Structure for Data Warehousing},
	url = {http://www.tpc.org},
	abstract = {Small Materialized Aggregates ({SMAs} for short) are considered a highly flexible and versatile alternative for materialized data cubes. The basic idea is to compute many aggregate values for small to medium-sized buckets of tu-ples. These aggregates are then used to speed up query processing. We present the general idea and present an application of {SMAs} to the {TPC}-D benchmark. We show that exploiting {SMAs} for {TPC}-D Query 1 results in a speed up of two orders of magnitude. Then, we investigate the problem of query processing in the presence of {SMAs}. Last, we briefly discuss some further tuning possibilities for {SMAs}.},
	author = {Moerkotte, Guido},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/76MUASDH/small_materialized_aggregates.pdf:application/pdf},
}

@report{crotty_are_nodate,
	title = {Are You Sure You Want to Use {MMAP} in Your Database Management System?; Are You Sure You Want to Use {MMAP} in Your Database Management System?},
	abstract = {Memory-mapped (mmap) file I/O is an {OS}-provided feature that maps the contents of a file on secondary storage into a program's address space. The program then accesses pages via pointers as if the file resided entirely in memory. The {OS} transparently loads pages only when the program references them and automatically evicts pages if memory fills up. mmap's perceived ease of use has seduced database management system ({DBMS}) developers for decades as a viable alternative to implementing a buffer pool. There are, however, severe correct-ness and performance issues with mmap that are not immediately apparent. Such problems make it difficult, if not impossible, to use mmap correctly and efficiently in a modern {DBMS}. In fact, several popular {DBMSs} initially used mmap to support larger-than-memory databases but soon encountered these hidden perils, forcing them to switch to managing file I/O themselves after significant engineering costs. In this way, mmap and {DBMSs} are like coffee and spicy food: an unfortunate combination that becomes obvious after the fact. Since developers keep trying to use mmap in new {DBMSs}, we wrote this paper to provide a warning to others that mmap is not a suitable replacement for a traditional buffer pool. We discuss the main shortcomings of mmap in detail, and our experimental analysis demonstrates clear performance limitations. Based on these findings , we conclude with a prescription for when {DBMS} developers might consider using mmap for file I/O.},
	author = {Crotty, Andrew and Leis, Viktor and Pavlo, Andrew},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/4MYVAKLH/cidr2022-p13-crotty.pdf:application/pdf},
}

@report{sears_blob_2006,
	title = {To {BLOB} or Not To {BLOB}: Large Object Storage in a Database or a Filesystem?},
	abstract = {Application designers must decide whether to store large objects ({BLOBs}) in a filesystem or in a database. Generally, this decision is based on factors such as application simplicity or manageability. Often, system performance affects these factors. Folklore tells us that databases efficiently handle large numbers of small objects, while filesystems are more efficient for large objects. Where is the break-even point? When is accessing a {BLOB} stored as a file cheaper than accessing a {BLOB} stored as a database record? Of course, this depends on the particular filesystem, database system, and workload in question. This study shows that when comparing the {NTFS} file system and {SQL} Server 2005 database system on a create, \{read, replace\}* delete workload, {BLOBs} smaller than 256KB are more efficiently handled by {SQL} Server, while {NTFS} is more efficient {BLOBS} larger than 1MB. Of course, this break-even point will vary among different database systems, filesystems, and workloads. By measuring the performance of a storage server workload typical of web applications which use get/put protocols such as {WebDAV} [{WebDAV}], we found that the break-even point depends on many factors. However, our experiments suggest that storage age, the ratio of bytes in deleted or replaced objects to bytes in live objects, is dominant. As storage age increases, fragmentation tends to increase. The filesystem we study has better fragmentation control than the database we used, suggesting the database system would benefit from incorporating ideas from filesystem architecture. Conversely, filesystem performance may be improved by using database techniques to handle small files. Surprisingly, for these studies, when average object size is held constant, the distribution of object sizes did not significantly affect performance. We also found that, in addition to low percentage free space, a low ratio of free space to average object size leads to fragmentation and performance degradation.},
	author = {Sears, Russell and Van Ingen, Catharine and Gray, Jim},
	date = {2006},
	keywords = {Databases, {BLOB}, Filesystems},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/T7H2BG8R/tr-2006-45.pdf:application/pdf},
}

@inproceedings{raju_pebblesdb_2017,
	title = {{PebblesDB}: Building Key-Value Stores using Fragmented Log-Structured Merge Trees},
	isbn = {978-1-4503-5085-3},
	doi = {10.1145/3132747.3132765},
	abstract = {Key-value stores such as {LevelDB} and {RocksDB} offer excellent write throughput, but suffer high write amplification. The write amplification problem is due to the Log-Structured Merge Trees data structure that underlies these key-value stores. To remedy this problem, this paper presents a novel data structure that is inspired by Skip Lists, termed Fragmented Log-Structured Merge Trees ({FLSM}). {FLSM} introduces the notion of guards to organize logs, and avoids rewriting data in the same level. We build {PebblesDB}, a high-performance key-value store, by modifying {HyperLevelDB} to use the {FLSM} data structure. We evaluate {PebblesDB} using micro-benchmarks and show that for write-intensive workloads, {PebblesDB} reduces write amplification by 2.4-3× compared to {RocksDB}, while increasing write throughput by 6.7×. We modify two widely-used {NoSQL} stores, {MongoDB} and {HyperDex}, to use {PebblesDB} as their underlying storage engine. Evaluating these applications using the {YCSB} benchmark shows that throughput is increased by 18-105\% when using {PebblesDB} (compared to their default storage engines) while write {IO} is decreased by 35-55\%.},
	pages = {497--514},
	booktitle = {{SOSP} 2017 - Proceedings of the 26th {ACM} Symposium on Operating Systems Principles},
	publisher = {Association for Computing Machinery, Inc},
	author = {Raju, Pandian and Chidambaram, Vijay and Kadekodi, Rohan and Abraham, Ittai},
	date = {2017-10-14},
	keywords = {Key-value stores, Log-structured merge trees, Write-optimized data structures},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/M6VFXNSN/sosp17-pebblesdb.pdf:application/pdf},
}

@article{dong_rocksdb_2021,
	title = {{RocksDB}: Evolution of Development Priorities in a Key-value Store Serving Large-scale Applications},
	volume = {17},
	issn = {1553-3077},
	doi = {10.1145/3483840},
	abstract = {This article is an eight-year retrospective on development priorities for {RocksDB}, a key-value store developed at Facebook that targets large-scale distributed systems and that is optimized for Solid State Drives ({SSDs}). We describe how the priorities evolved over time as a result of hardware trends and extensive experiences running {RocksDB} at scale in production at a number of organizations: from optimizing write amplification, to space amplification, to {CPU} utilization. We describe lessons from running large-scale applications, including that resource allocation needs to be managed across different {RocksDB} instances, that data formats need to remain backward- and forward-compatible to allow incremental software rollouts, and that appropriate support for database replication and backups are needed. Lessons from failure handling taught us that data corruption errors needed to be detected earlier and that data integrity protection mechanisms are needed at every layer of the system. We describe improvements to the key-value interface. We describe a number of efforts that in retrospect proved to be misguided. Finally, we describe a number of open problems that could benefit from future research.},
	pages = {1--32},
	number = {4},
	journaltitle = {{ACM} Transactions on Storage},
	author = {Dong, Siying and Kryczka, Andrew and Jin, Yanqin and Stumm, Michael},
	date = {2021-11-30},
	note = {Publisher: Association for Computing Machinery ({ACM})},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/HBITCFE6/3483840.pdf:application/pdf},
}

@inproceedings{dayan_dostoevsky_2018,
	title = {Dostoevsky: Better space-time trade-offs for {LSM}-tree based key-value stores via adaptive removal of superfluous merging},
	isbn = {978-1-4503-1743-6},
	doi = {10.1145/3183713.3196927},
	abstract = {We show that all mainstream {LSM}-tree based key-value stores in the literature and in industry suboptimally trade between the I/O cost of updates on one hand and the I/O cost of lookups and storage space on the other. The reason is that they perform equally expensive merge operations across all levels of {LSM}-tree to bound the number of runs that a lookup has to probe and to remove obsolete entries to reclaim storage space. With state-of-the-art designs, however, merge operations from all levels of {LSM}-tree but the largest (i.e., most merge operations) reduce point lookup cost, long range lookup cost, and storage space by a negligible amount while significantly adding to the amortized cost of updates. To address this problem, we introduce Lazy Leveling, a new design that removes merge operations from all levels of {LSM}-tree but the largest. Lazy Leveling improves the worst-case complexity of update cost while maintaining the same bounds on point lookup cost, long range lookup cost, and storage space. We further introduce Fluid {LSM}-tree, a generalization of the entire {LSM}-tree design space that can be parameterized to assume any existing design. Relative to Lazy Leveling, Fluid {LSM}-tree can optimize more for updates by merging less at the largest level, or it can optimize more for short range lookups by merging more at all other levels. We put everything together to design Dostoevsky, a key-value store that adaptively removes superfluous merging by navigating the Fluid {LSM}-tree design space based on the application workload and hardware. We implemented Dostoevsky on top of {RocksDB}, and we show that it strictly dominates state-of-the-art designs in terms of performance and storage space.},
	pages = {505--520},
	booktitle = {Proceedings of the {ACM} {SIGMOD} International Conference on Management of Data},
	publisher = {Association for Computing Machinery},
	author = {Dayan, Niv and Idreos, Stratos},
	date = {2018-05-27},
	note = {{ISSN}: 07308078},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/3XDCL8N2/dostoevskykv.pdf:application/pdf},
}

@article{dayan_optimal_2018,
	title = {Optimal bloom filters and adaptive merging for {LSM}-trees},
	volume = {43},
	issn = {15574644},
	doi = {10.1145/3276980},
	abstract = {In this article, we show that key-value stores backed by a log-structured merge-tree ({LSM}-tree) exhibit an intrinsic tradeoff between lookup cost, update cost, and main memory footprint, yet all existing designs expose a suboptimal and dificult to tune tradeoff among these metrics. We pinpoint the problem to the fact that modern key-value stores suboptimally co-tune the merge policy, the buffer size, and the Bloom filters' false-positive rates across the {LSM}-tree's different levels. We present Monkey, an {LSM}-tree based key-value store that strikes the optimal balance between the costs of updates and lookups with any given main memory budget. The core insight is that worst-case lookup cost is proportional to the sum of the false-positive rates of the Bloom filters across all levels of the {LSM}-tree. Contrary to state-of-the-art key-value stores that assign a fixed number of bits-per-element to all Bloom filters, Monkey allocates memory to filters across different levels so as to minimize the sum of their false-positive rates. We show analytically that Monkey reduces the asymptotic complexity of the worst-case lookup I/O cost, and we verify empirically using an implementation on top of {RocksDB} that Monkey reduces lookup latency by an increasing margin as the data volume grows (50-80\% for the data sizes we experimented with). Furthermore, we map the design space onto a closed-form model that enables adapting the merging frequency and memory allocation to strike the best tradeoff among lookup cost, update cost and main memory, depending on the workload (proportion of lookups and updates), the dataset (number and size of entries), and the underlying hardware (main memory available, disk vs. flash). We show how to use this model to answer what-if design questions about how changes in environmental parameters impact performance and how to adapt the design of the key-value store for optimal performance.},
	number = {4},
	journaltitle = {{ACM} Transactions on Database Systems},
	author = {Dayan, Niv and Athanassoulis, Manos and Idreos, Stratos},
	date = {2018-12-01},
	note = {Publisher: Association for Computing Machinery},
	keywords = {Key-value stores, Bloom filters, {LSM}-tree, {NoSQL}, System design},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/89H7I9YX/monkey-journal.pdf:application/pdf},
}

@inproceedings{raasveldt_duckdb_2019,
	title = {{DuckDB}: An embeddable analytical database},
	isbn = {978-1-4503-5643-5},
	doi = {10.1145/3299869.3320212},
	abstract = {The immense popularity of {SQLite} shows that there is a need for unobtrusive in-process data management solutions. However, there is no such system yet geared towards analytical workloads. We demonstrate {DuckDB}, a novel data management system designed to execute analytical {SQL} queries while embedded in another process. In our demonstration, we pit {DuckDB} against other data management solutions to showcase its performance in the embedded analytics scenario. {DuckDB} is available as Open Source software under a permissive license.},
	pages = {1981--1984},
	booktitle = {Proceedings of the {ACM} {SIGMOD} International Conference on Management of Data},
	publisher = {Association for Computing Machinery},
	author = {Raasveldt, Mark and Mühleisen, Hannes},
	date = {2019-06-25},
	note = {{ISSN}: 07308078},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/357XE83Q/2019-duckdbdemo.pdf:application/pdf},
}

@report{armbrust_lakehouse_nodate,
	title = {Lakehouse: A New Generation of Open Platforms that Unify Data Warehousing and Advanced Analytics},
	abstract = {This paper argues that the data warehouse architecture as we know it today will wither in the coming years and be replaced by a new architectural pattern, the Lakehouse, which will (i) be based on open direct-access data formats, such as Apache Parquet, (ii) have first-class support for machine learning and data science, and (iii) offer state-of-the-art performance. Lakehouses can help address several major challenges with data warehouses, including data staleness, reliability, total cost of ownership, data lock-in, and limited use-case support. We discuss how the industry is already moving toward Lakehouses and how this shift may affect work in data management. We also report results from a Lakehouse system using Parquet that is competitive with popular cloud data warehouses on {TPC}-{DS}.},
	author = {Armbrust, Michael and Ghodsi, Ali and Xin, Reynold and Zaharia, Matei and Berkeley, Uc},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/3L2R3VM2/armbrust-cidr21.pdf:application/pdf},
}

@report{babu_adaptive_nodate,
	title = {Adaptive Query Processing in the Looking Glass},
	abstract = {A great deal of work on adaptive query processing has been done over the last few years: Adaptive query processing has been used to detect and correct optimizer errors due to incorrect statistics or simplified cost metrics; it has been applied to long-running continuous queries over data streams whose characteristics vary over time; and routing-based adaptive query processing does away with the optimizer altogether. Despite this large body of interrelated work, no unifying comparison of adaptive query processing techniques or systems has been attempted; we tackle this problem. We identify three families of systems (plan-based, {CQ}-based, and routing-based), and compare them in detail with respect to the most important aspects of adaptive query processing: plan quality, statistics monitoring and re-optimization, plan migration, and scalability. We also suggest two new approaches to adap-tive query processing that address some of the shortcomings revealed by our in-depth analysis: (1) Proactive re-optimization, where the optimizer chooses query plans with the expectation of re-optimization; and (2) Plan logging, where op-timizer decisions under different conditions are logged over time, enabling plan reuse as well as analysis of relevant statistics and benefits of adap-tivity.},
	author = {Babu, Shivnath and Bizarro, Pedro},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/ZVZDF6QQ/babu-cidr2015.pdf:application/pdf},
}

@inproceedings{aberger_levelheaded_2018,
	title = {Levelheaded: a unified engine for business intelligence and linear algebra querying},
	isbn = {978-1-5386-5520-7},
	doi = {10.1109/ICDE.2018.00048},
	abstract = {Pipelines combining {SQL}-style business intelligence ({BI}) queries and linear algebra ({LA}) are becoming increasingly common in industry. As a result, there is a growing need to unify these workloads in a single framework. Unfortunately, existing solutions either sacrifice the inherent benefits of ex-clusively using a relational database (e.g. logical and physical independence) or incur orders of magnitude performance gaps compared to specialized engines (or both). In this work, we study applying a new type of query processing architecture to standard {BI} and {LA} benchmarks. To do this, we present a new in-memory query processing engine called {LevelHeaded}. {LevelHeaded} uses worst-case optimal joins as its core execution mechanism for both {BI} and {LA} queries. With {LevelHeaded}, we show how crucial optimizations for {BI} and {LA} queries can be captured in a worst-case optimal query architecture. Using these optimizations, {LevelHeaded} outperforms other relational database engines ({LogicBlox}, {MonetDB}, and {HyPer}) by orders of magnitude on standard {LA} benchmarks, while performing on average within 31\% of the best-of-breed {BI} ({HyPer}) and {LA} (Intel {MKL}) solutions on their own benchmarks. Our results show that such a single query processing architecture can be efficient on both {BI} and {LA} queries.},
	pages = {449--460},
	booktitle = {Proceedings - {IEEE} 34th International Conference on Data Engineering, {ICDE} 2018},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Aberger, Christopher and Lamb, Andrew and Olukotun, Kunle and Re, Christopher},
	date = {2018-10-24},
	keywords = {business intelligence querying, join processing, linear algebra querying, Worst case optimal join},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/Y8XTADR7/aberger-icde2018.pdf:application/pdf},
}

@report{balkesen_main-memory_nodate,
	title = {Main-Memory Hash Joins on Multi-Core {CPUs}: Tuning to the Underlying Hardware},
	abstract = {The architectural changes introduced with multi-core {CPUs} have triggered a redesign of main-memory join algorithms. In the last few years, two diverging views have appeared. One approach advocates careful tailoring of the algorithm to the architectural parameters (cache sizes, {TLB}, and memory bandwidth). The other approach argues that modern hardware is good enough at hiding cache and {TLB} miss latencies and, consequently, the careful tailoring can be omitted without sacrificing performance. In this paper we demonstrate through experimental analysis of different algorithms and architectures that hardware still matters. Join algorithms that are hardware conscious perform better than hardware-oblivious approaches. The analysis and comparisons in the paper show that many of the claims regarding the behavior of join algorithms that have appeared in literature are due to selection effects (relative table sizes, tuple sizes, the underlying architecture, using sorted data, etc.) and are not supported by experiments run under different parameters settings. Through the analysis, we shed light on how modern hardware affects the implementation of data operators and provide the fastest implementation of radix join to date, reaching close to 200 million tuples per second.},
	author = {Balkesen, Cagri and {\textbackslash}\#2, Jens Teubner and Alonso, Gustavo and Tamer¨ozsu, M and Tamer¨ozsu, Tamer¨},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/U3NPM69S/balkesen-icde2013.pdf:application/pdf},
}

@inproceedings{bandle_partition_2021,
	title = {To Partition, or Not to Partition, That is the Join Question in a Real System},
	doi = {10.1145/3448016.3452831},
	abstract = {An efficient implementation of a hash join has been a highly researched problem for decades. Recently, the radix join has been shown to have superior performance over the alternatives (e.g., the non-partitioned hash join), albeit on synthetic microbenchmarks. Therefore, it is unclear whether one can simply replace the hash join in an {RDBMS} or use the radix join as a performance booster for selected queries. If the latter, it is still unknown when one should rely on the radix join to improve performance. In this paper, we address these questions, show how to integrate the radix join in Umbra, a code-generating {DBMS}, and make it competitive for selective queries by introducing a Bloom-filter based semi-join reducer. We have evaluated how well it runs when used in queries from more representative workloads like {TPC}-H. Surprisingly, the radix join brings a noticeable improvement in only one out of all 59 joins in {TPC}-H. Thus, with an extensive range of microbenchmarks, we have isolated the effects of the most important workload factors and synthesized the range of values where partitioning the data for the radix join pays off. Our analysis shows that the benefit of data partitioning quickly diminishes as soon as we deviate from the optimal parameters, and even late materialization rarely helps in real workloads. We thus, conclude that integrating the radix join within a code-generating database rarely justifies the increase in code and optimizer complexity and advise against it for processing real-world workloads.},
	pages = {168--180},
	booktitle = {Proceedings of the {ACM} {SIGMOD} International Conference on Management of Data},
	publisher = {Association for Computing Machinery},
	author = {Bandle, Maximilian and Giceva, Jana and Neumann, Thomas},
	date = {2021},
	note = {{ISSN}: 07308078},
	keywords = {join processing, in-memory databases, modern hardware, partitioning, performance evaluation},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/KK3BVLUD/bandle-sigmod21.pdf:application/pdf},
}

@report{binnig_end_2150,
	title = {The End of Slow Networks: It's Time for a Redesign},
	abstract = {The next generation of high-performance networks with remote direct memory access ({RDMA}) capabilities requires a fundamental rethinking of the design of distributed in-memory {DBMSs}. These systems are commonly built under the assumption that the network is the primary bottleneck and should be avoided at all costs, but this assumption no longer holds. For instance, with {InfiniBand} {FDR} 4×, the bandwidth available to transfer data across the network is in the same ballpark as the bandwidth of one memory channel. Moreover, {RDMA} transfer latencies continue to rapidly improve as well. In this paper, we first argue that traditional distributed {DBMS} architectures cannot take full advantage of high-performance networks and suggest a new architecture to address this problem. Then, we discuss initial results from a prototype implementation of our proposed architecture for {OLTP} and {OLAP}, showing remarkable performance improvements over existing designs.},
	author = {Binnig, Carsten and Crotty, Andrew and Galakatos, Alex and Kraska, Tim and Zamanian, Erfan},
	date = {2150},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/XRVF7ADF/binnig-vldb2016.pdf:application/pdf},
}

@report{boncz_monetdbx100_nodate,
	title = {{MonetDB}/X100: Hyper-Pipelining Query Execution},
	abstract = {Database systems tend to achieve only low {IPC} (instructions-per-cycle) efficiency on modern {CPUs} in compute-intensive application areas like decision support, {OLAP} and multimedia retrieval. This paper starts with an in-depth investigation to the reason why this happens, focusing on the {TPC}-H benchmark. Our analysis of various relational systems and {MonetDB} leads us to a new set of guidelines for designing a query processor. The second part of the paper describes the architecture of our new X100 query engine for the {MonetDB} system that follows these guidelines. On the surface, it resembles a classical Volcano-style engine, but the crucial difference to base all execution on the concept of vector processing makes it highly {CPU} efficient. We evaluate the power of Mon-{etDB}/X100 on the 100GB version of {TPC}-H, showing its raw execution power to be between one and two orders of magnitude higher than previous technology.},
	author = {Boncz, Peter and Zukowski, Marcin and Nes, Niels},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/T2T9A2VF/boncz-cidr2005.pdf:application/pdf},
}

@report{neumann_complete_2017,
	title = {The Complete Story of Joins (in {HyPer})},
	abstract = {{SQL} has evolved into an (almost) fully orthogonal query language that allows (arbitrarily deeply) nested subqueries in nearly all parts of the query. In order to avoid recursive evaluation strategies which incur unbearable O(n 2) runtime we need an extended relational algebra to translate such subqueries into non-standard join operators. This paper concentrates on the non-standard join operators beyond the classical textbook inner joins, outer joins and (anti) semi joins. Their implementations in {HyPer} were covered in previous publications which we refer to. In this paper we cover the new join operators mark-join and single-join at both levels: At the logical level we show the translation and reordering possibilities in order to effectively optimize the resulting query plans. At the physical level we describe hash-based and block-nested loop implementations of these new joins. Based on our database system {HyPer}, we describe a blue print for the complete query translation and optimization pipeline. The practical need for the advanced join operators is proven by an analysis of the two well known {TPC}-H and {TPC}-{DS} benchmarks which revealed that all variants are actually used in these query sets.},
	pages = {31},
	author = {Neumann, Thomas and Leis, Viktor and Kemper, Alfons},
	date = {2017},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/JQQSHE9J/hyperjoins-btw2017.pdf:application/pdf},
}

@report{graefe_cascades_nodate,
	title = {The Cascades Framework for Query Optimization},
	abstract = {This paper describes a new extensible query optimization framework that resolves many of the shortcomings of the {EXODUS} and Volcano optimizer generators. In addition to extensibility, dynamic programming , and memorization based on and extended from the {EXODUS} and Volcano prototypes, this new optimizer provides (i) manipulation of operator arguments using rules or functions, (ii) operators that are both logical and physical for predicates etc., (iii) schema-specific rules for materialized views, (iv) rules to insert "enforcers" or "glue operators," (v) rule-specific guidance, permitting grouping of rules, (vi) basic facilities that will later permit parallel search, partially ordered cost measures, and dynamic plans, (vii) extensive tracing support, and (viii) a clean interface and implementation making full use of the abstraction mechanisms of C++. We describe and justify our design choices for each of these issues. The optimizer system described here is operational and will serve as the foundation for new query optimizers in Tandem's {NonStop} {SQL} product and in Microsoft's {SQL} Server product.},
	author = {Graefe, Goetz},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/YK54D6EI/graefe-ieee1995.pdf:application/pdf},
}

@report{chaudhuri_overview_nodate,
	title = {An Overview of Query Optimization in Relational Systems},
	author = {Chaudhuri, Surajit},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/BAF9D9LK/chaudhuri-pods1998.pdf:application/pdf},
}

@inproceedings{gupta_aggify_2020,
	title = {Aggify: Lifting the Curse of Cursor Loops using Custom Aggregates},
	isbn = {978-1-4503-6735-6},
	doi = {10.1145/3318464.3389736},
	abstract = {Loops that iterate over {SQL} query results are quite common, both in application programs that run outside the {DBMS}, as well as User Defined Functions ({UDFs}) and stored procedures that run within the {DBMS}. It can be argued that set-oriented operations are more efficient and should be preferred over iteration; but from real world use cases, it is clear that loops over query results are inevitable in many situations, and are preferred by many users. Such loops, known as cursor loops, come with huge trade-offs and overheads w.r.t. performance, resource consumption and concurrency. We present Aggify, a technique for optimizing loops over query results that overcomes these overheads. It achieves this by automatically generating custom aggregates that are equivalent in semantics to the loop. Thereby, Aggify completely eliminates the loop by rewriting the query to use this generated aggregate. This technique has several advantages such as: (i) pipelining of entire cursor loop operations instead of materialization, (ii) pushing down loop computation from the application layer into the {DBMS}, closer to the data, (iii) leveraging existing work on optimization of aggregate functions, resulting in efficient query plans. We describe the technique underlying Aggify, and present our experimental evaluation over benchmarks as well as real workloads that demonstrate the significant benefits of this technique.},
	pages = {559--573},
	booktitle = {Proceedings of the {ACM} {SIGMOD} International Conference on Management of Data},
	publisher = {Association for Computing Machinery},
	author = {Gupta, Surabhi and Purandare, Sanket and Ramachandra, Karthik},
	date = {2020-06-14},
	note = {{ISSN}: 07308078},
	keywords = {cursor loops, custom aggregates, query optimization},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/WT28SGY7/gupta-sigmod20.pdf:application/pdf},
}

@inproceedings{duta_functional-style_2020,
	title = {Functional-Style {SQL} {UDFs} with a Capital 'F'},
	isbn = {978-1-4503-6735-6},
	doi = {10.1145/3318464.3389707},
	abstract = {We advocate to express complex in-database computation using a functional style in which {SQL} {UDFs} use plain self-invocation to recurse. The resulting {UDFs} are concise and readable, but their run time performance on contemporary {RDBMSs} is sobering. This paper describes how to compile such functional-style {UDFs} into {SQL}:1999 recursive common table expressions. We build on function call graphs to build the compiler's core and to realize a series of optimizations (reference counting, memoization, exploitation of linear and tail recursion). The compiled {UDFs} evaluate efficiently, challenging the performance of manually tweaked (but often convoluted) {SQL} code. {SQL} {UDFs} can indeed be functional and fast.},
	pages = {1273--1287},
	booktitle = {Proceedings of the {ACM} {SIGMOD} International Conference on Management of Data},
	publisher = {Association for Computing Machinery},
	author = {Duta, Christian and Grust, Torsten},
	date = {2020-06-14},
	note = {{ISSN}: 07308078},
	keywords = {call graph, functional programming, memoization, recursion, {SQL}, user-defined functions},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/IV3JIGH6/duta-sigmod20.pdf:application/pdf},
}

@article{kuschewski_btrblocks_2023,
	title = {{BtrBlocks}: Efficient Columnar Compression for Data Lakes},
	volume = {1},
	doi = {10.1145/3589263},
	abstract = {Analytics is moving to the cloud and data is moving into data lakes. These reside on object storage services like S3 and enable seamless data sharing and system interoperability. To support this, many systems build on open storage formats like Apache Parquet. However, these formats are not optimized for remotely-accessed data lakes and today's high-throughput networks. Inefficient decompression makes scans {CPU}-bound and thus increases query time and cost. With this work we present {BtrBlocks}, an open columnar storage format designed for data lakes. {BtrBlocks} uses a set of lightweight encoding schemes, achieving fast and efficient decompression and high compression ratios.},
	pages = {1--26},
	number = {2},
	journaltitle = {Proceedings of the {ACM} on Management of Data},
	author = {Kuschewski, Maximilian and Sauerwein, David and Alhomssi, Adnan and Leis, Viktor},
	date = {2023-06-13},
	note = {Publisher: Association for Computing Machinery ({ACM})},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/54S8FFVY/kuschewski-sigmod23.pdf:application/pdf},
}

@report{kohn_adaptive_nodate,
	title = {Adaptive Execution of Compiled Queries},
	abstract = {Compiling queries to machine code is a very efficient way for executing queries. One often overlooked problem with compilation is the time it takes to generate machine code. Even with fast compilation frameworks like {LLVM}, generating machine code for complex queries often takes hundreds of milliseconds. Such durations can be a major disadvantage for workloads that execute many complex, but quick queries. To solve this problem, we propose an adaptive execution framework, which dynamically switches from interpretation to compilation. We also propose a fast bytecode interpreter for {LLVM}, which can execute queries without costly translation to machine code and dramatically reduces the query latency. Adaptive execution is fine-grained, and can execute code paths of the same query using different execution modes. Our evaluation shows that this approach achieves optimal performance in a wide variety of settings-low latency for small data sets and maximum throughput for large data sizes.},
	author = {Kohn, André and Leis, Viktor and Neumann, Thomas},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/VGTGRU5H/kohn-icde2018.pdf:application/pdf},
}

@book{ieee_staff_2010_2010,
	title = {2010 {IEEE} 26th International Conference on Data Engineering and Workshops},
	isbn = {978-1-4244-5446-4},
	publisher = {{IEEE}},
	author = {{IEEE} Staff, .},
	date = {2010},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/TJ4MV2DL/krikellas-icde2010.pdf:application/pdf},
}

@book{ross_proceedings_2013,
	title = {Proceedings of the 2013 {ACM} {SIGMOD} International Conference on Management of Data},
	isbn = {978-1-4503-2037-5},
	abstract = {Title from The {ACM} Digital Library.},
	pagetotal = {1296},
	publisher = {{ACM}},
	author = {Ross, Kenneth.},
	date = {2013},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/UPXXSFHA/li-sigmod2013.pdf:application/pdf;PDF:/Users/alex/Documents/Zotoro/storage/E6XPC3GJ/p1231-raducanu.pdf:application/pdf},
}

@report{neumann_unnesting_nodate,
	title = {Unnesting Arbitrary Queries},
	abstract = {{SQL}-99 allows for nested subqueries at nearly all places within aq uery. From au ser'sp oint of view, nested queries can greatly simplify the formulation of complexq ueries. However, nested queries that are correlated with the outer queries frequently lead to dependent joins with nested loops evaluations and thus poor performance. Existing systems therefore use anumber of heuristics to unnest these queries, i.e., de-correlate them. These unnesting techniques can greatly speed up query processing, buta re usually limited to certain classes of queries. To the best of our knowledge no existing system can de-correlate queries in the general case. We present ageneric approach for unnesting arbitrary queries. As aresult, the de-correlated queries allow for much simpler and much more efficient query evaluation.},
	author = {Neumann, Thomas and Kemper, Alfons},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/JNDNWYI9/neumann-btw2015.pdf:application/pdf},
}

@inproceedings{lang_make_2020,
	title = {Make the most out of your {SIMD} investments: counter control flow divergence in compiled query pipelines},
	volume = {29},
	doi = {10.1007/s00778-019-00547-y},
	abstract = {Increasing single instruction multiple data ({SIMD}) capabilities in modern hardware allows for the compilation of data-parallel query pipelines. This means {GPU}-alike challenges arise: control flow divergence causes the underutilization of vector-processing units. In this paper, we present efficient algorithms for the {AVX}-512 architecture to address this issue. These algorithms allow for the fine-grained assignment of new tuples to idle {SIMD} lanes. Furthermore, we present strategies for their integration with compiled query pipelines so that tuples are never evicted from registers. We evaluate our approach with three query types: (i) a table scan query based on {TPC}-H Query 1, that performs up to 34\% faster when addressing underutilization, (ii) a hashjoin query, where we observe up to 25\% higher performance, and (iii) an approximate geospatial join query, which shows performance improvements of up to 30\%.},
	pages = {757--774},
	booktitle = {{VLDB} Journal},
	publisher = {Springer},
	author = {Lang, Harald and Passing, Linnea and Kipf, Andreas and Boncz, Peter and Neumann, Thomas and Kemper, Alfons},
	date = {2020-05-01},
	note = {Issue: 2-3
{ISSN}: 0949877X},
	keywords = {{AVX}-512, Control flow divergence, Database systems, Query compilation, Query execution, {SIMD}, Vectorization},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/VP8QDZBY/lang-vldbj2020.pdf:application/pdf},
}

@inproceedings{li_accelerating_2016,
	title = {Accelerating relational databases by leveraging remote memory and {RDMA}},
	volume = {26-June-2016},
	isbn = {978-1-4503-3531-7},
	doi = {10.1145/2882903.2882949},
	abstract = {Memory is a crucial resource in relational databases ({RDBMSs}). When there is insufficient memory, {RDBMSs} are forced to use slower media such as {SSDs} or {HDDs}, which can significantly degrade workload performance. Cloud database services are deployed in data centers where network adapters supporting remote direct memory access ({RDMA}) at low latency and high bandwidth are becoming prevalent. We study the novel problem of how a Symmetric Multi-Processing ({SMP}) {RDBMS}, whose memory demands exceed locally-available memory, can leverage available remote memory in the cluster accessed via {RDMA} to improve query performance. We expose available memory on remote servers using a lightweight file {API} that allows an {SMP} {RDBMS} to leverage the benefits of remote memory with modest changes. We identify and implement several novel scenarios to demonstrate these benefits, and address design challenges that are crucial for efficient implementation. We implemented the scenarios in Microsoft {SQL} Server engine and present the first end-to-end study to demonstrate benefits of remote memory for a variety of micro-benchmarks and industry-standard benchmarks. Compared to using disks when memory is insufficient, we improve the throughput and latency of queries with short reads and writes by 3× to 10×, while improving the latency of multiple {TPC}-H and {TPC}-{DS} queries by 2× to 100×.},
	pages = {355--370},
	booktitle = {Proceedings of the {ACM} {SIGMOD} International Conference on Management of Data},
	publisher = {Association for Computing Machinery},
	author = {Li, Feng and Das, Sudipto and Syamala, Manoj and Narasayya, Vivek R.},
	date = {2016-06-26},
	note = {{ISSN}: 07308078},
	keywords = {Buffer pool extension, Opportunistic caching, {RDMA}, Relational databases, Remote memory, Semantic caching},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/MHPKGB9U/li-sigmod2016.pdf:application/pdf},
}

@inproceedings{ngom_filter_2021,
	title = {Filter representation in vectorized query execution},
	isbn = {978-1-4503-8556-5},
	doi = {10.1145/3465998.3466009},
	abstract = {Advances in memory technology have made it feasible for database management systems ({DBMS}) to store their working data set in main memory. This trend shifts the bottleneck for query execution from disk accesses to {CPU} efficiency. One technique to improve {CPU} efficiency is batch-oriented processing, or vectorization, as it reduces interpretation overhead. For each vector (batch) of tuples, the {DBMS} must track the set of valid (visible) tuples that survive all previous processing steps. To that end, existing systems employ one of two data structures, or filter representations: selection vectors or bitmaps. In this work, we analyze each approach's strengths and weaknesses and offer recommendations on how to implement vectorized operations. Through a wide range of micro-benchmarks, we determine that the optimal strategy is a function of many factors: the cost of iterating through tuples, the cost of the operation itself, and how amenable it is to {SIMD} vectorization. Our analysis shows that bitmaps perform better for operations that can be vectorized using {SIMD} instructions and that selection vectors perform better on all other operations due to cheaper iteration logic.},
	booktitle = {Proceedings of the 17th International Workshop on Data Management on New Hardware, {DaMoN} 2021},
	publisher = {Association for Computing Machinery, Inc},
	author = {Ngom, Amadou and Menon, Prashanth and Butrovich, Matthew and Ma, Lin and Lim, Wan Shen and Mowry, Todd C. and Pavlo, Andrew},
	date = {2021-06-20},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/6VPET25P/ngom-damon2021.pdf:application/pdf},
}

@report{ngo_skew_nodate,
	title = {Skew Strikes Back: New Developments in the Theory of Join Algorithms˚{HungAlgorithms}˚},
	abstract = {Evaluating the relational join is one of the central al-gorithmic and most well-studied problems in database systems. A staggering number of variants have been considered including Block-Nested loop join, Hash-Join, Grace, Sort-merge (see Grafe [17] for a survey, and [4, 7, 24] for discussions of more modern issues). Commercial database engines use finely tuned join heuristics that take into account a wide variety of factors including the selectivity of various predicates, memory, {IO}, etc. This study of join queries notwithstanding, the textbook description of join processing is suboptimal. This survey describes recent results on join algorithms that have provable worst-case optimality runtime guarantees. We survey recent work and provide a simpler and unified description of these algorithms that we hope is useful for theory-minded readers, algorithm designers, and systems implementors. Much of this progress can be understood by thinking about a simple join evaluation problem that we illustrate with the so-called triangle query, a query that has become increasingly popular in the last decade with the advent of social networks, biological motifs, and graph databases [36, 37] Suppose that one is given a graph with N edges, how many distinct triangles can there be in the graph? A first bound is to say that there are at most N edges, and hence at most {OpN} 3 q triangles. A bit more thought suggests that every triangle is indexed by any two of its sides and hence there at most {OpN} 2 q triangles. However, the correct, tight, and non-trivial asymptotic is {OpN} 3\{2 q.},
	author = {Ngo, Algorithms˚hung Q and Ré, Christopher and Rudra, Atri and Barcelo, Pablo},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/S4RY4PX8/ngo-sigmodrec13.pdf:application/pdf},
}

@report{cusack_yellowbrick_nodate,
	title = {Yellowbrick: An Elastic Data Warehouse on Kubernetes},
	abstract = {The Yellowbrick Data Warehouse delivers efficient, scalable and resilient data warehousing in public clouds and in private data centers. The database management system is composed of a set of Kubernetes-orchestrated microservices. Kubernetes provides the single-source-of-truth for system configuration and state, and manages all data warehouse lifecycle operations, including the creation, expansion, contraction and destruction of elastic compute resources and shared services. The common runtime provided by Kubernetes enabled us to port to three different cloud providers in under a year. We created a {SQL} interface to Kubernetes to hide the details of the underlying microservices implementation from the end user. We also developed our own reliable network protocol based on the Data Plane Development Kit ({DPDK}) for efficient data exchange between nodes in the public cloud. In this paper, we provide an overview of Yellowbrick and its microservices approach to delivering elasticity, scalability and separation of compute and storage. We also describe the optimizations we have implemented in the operating system and in our software to drive efficiency and performance, supported by benchmark results. We conclude with lessons learned and discuss future developments.},
	author = {Cusack, Mark and Adamson, John and Brinicombe, Mark and Carson, Neil and Kejser, Thomas and Peterson, Jim and Vasudev, Arvind and Westerfeld, Kurt and Wipfel, Robert},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/8A2HI4LD/p2-cusack.pdf:application/pdf},
}

@report{franz_dear_nodate,
	title = {Dear User-Defined Functions,  Inlining isn't working out so great for us.  Let's try batching to make our relationship work.  Sincerely, {SQL}},
	abstract = {{SQL}'s user-defined functions ({UDFs}) allow developers to express complex computation using procedural logic. But {UDFs} have been the bane of database management systems ({DBMSs}) for decades because they inhibit optimization opportunities, potentially slowing down queries significantly. In response, batching and inlining techniques have been proposed to enable effective query optimization of {UDF} calls within {SQL}. Inlining is now available in a major commercial {DBMS}. But the trade-offs between both approaches on modern {DBMSs} remain unclear. We evaluate and compare {UDF} batching and inlining on enterprise and open-source {DBMSs} using a state-of-the-art {UDF}-centric workload. We observe the surprising result that although inlin-ing is better on simple {UDFs}, batching outperforms inlining by up to 93.4× for more complex {UDFs} because it makes it easier for a {DBMS}'s query optimizer to decorrelate subqueries. We propose a hybrid approach that chooses batching or inlining to achieve the best performance.},
	author = {Franz, Kai and Arch, Samuel and Hirn, Denis and Grust, Torsten and Mowry, Todd C and Pavlo, Andrew},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/YBHCSIJP/p13-franz.pdf:application/pdf},
}

@report{duta_compiling_nodate,
	title = {Compiling {PL}/{SQL} Away},
	abstract = {"{PL}/{SQL} functions are slow," is common developer wisdom that derives from the tension between set-oriented {SQL} evaluation and statement-by-statement {PL}/{SQL} interpretation. We pursue the radical approach of compiling {PL}/{SQL} away, turning interpreted functions into regular subqueries that can then be efficiently evaluated together with their embracing {SQL} query, avoiding any {PL}/{SQL} ↔ {SQL} context switches. Input {PL}/{SQL} functions may exhibit arbitrary control flow. Iteration, in particular, is compiled into {SQL}-level recursion. {RDBMSs} across the board reward this compilation effort with significant run time savings that render established developer lore questionable.},
	author = {Duta, Christian and Hirn, Denis and Grust, Torsten},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/4PGJZMCX/p1-duta-cidr20.pdf:application/pdf},
}

@report{raasveldt_data_nodate,
	title = {Data Management for Data Science Towards Embedded Analytics},
	abstract = {The rise of Data Science has caused an influx of new users in need of data management solutions. However, instead of utilizing existing {RDBMS} solutions they are opting to use a stack of independent solutions for data storage and processing glued together by scripting languages. This is not because they do not need the functionality that an integrated {RDBMS} provides, but rather because existing {RDBMS} implementations do not cater to their use case. To solve these issues, we propose a new class of data management systems: embedded analytical systems. These systems are tightly integrated with analytical tools, and provide fast and efficient access to the data stored within them. In this work, we describe the unique challenges and opportunities w.r.t workloads, resilience and cooperation that are faced by this new class of systems and the steps we have taken towards addressing them in the {DuckDB} system.},
	author = {Raasveldt, Mark and Mühleisen, Hannes},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/FX3UCYHC/p23-raasveldt-cidr20.pdf:application/pdf},
}

@report{chattopadhyay_shared_nodate,
	title = {Shared Foundations: Modernizing Meta's Data Lakehouse},
	abstract = {Data processing systems have evolved significantly over the last decade, driven by large trends in hardware and software, the exponential growth of data, and new and changing use cases. At Meta (and elsewhere), the various data systems composing the data lakehouse had historically evolved organically and independently, leading to data stack fragmentation, and resulting in work duplication , subpar system performance, and inconsistent user experience. This paper describes how we transformed the legacy data lake-house stack at Meta to adapt to the new realities through a large cross-organizational effort called Shared Foundations. This program promotes a compositional approach based on the principles of reusable components, deduplicated systems, and common and consistent {APIs}. The Shared Foundations effort has resulted in a more modern data architecture at Meta-one that offers better performance , richer features, higher engineering velocity, and a more consistent user experience, setting up the data lakehouse stack at Meta for faster innovation in the future.},
	author = {Chattopadhyay, Biswapesh and Pedreira, Pedro and Agarwal, Sameer and Vakharia, Suketu and Li, Peng and Liu, Weiran and Narayanan, Sundaram},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/IVISWDDR/p77-chattopadhyay.pdf:application/pdf},
}

@report{atwal_motherduck_nodate,
	title = {{MotherDuck}: {DuckDB} in the cloud and in the client},
	url = {https://bit.ly/duckdb-blog-holistic-aggregates},
	abstract = {We describe and demo {MotherDuck}: a new service that connects {DuckDB} to the cloud. {MotherDuck} provides the concept of hybrid query processing: the ability to execute queries partly on the client and partly in the cloud. We cover the motivation for {MotherDuck} and some of its use cases; and outline its system architecture, which heavily uses the extension mechanisms of {DuckDB}. {MotherDuck} allows existing {DuckDB} users who use a laptop, like data scientists, to start using cloud computing without changing their queries: this can provide better performance as well as scala-bility to larger datasets. It also provides them the ability to share {DuckDB} databases with others through the cloud for collaboration. Hybrid query processing opens the door to new data-intensive applications, such as low-latency analytical web apps, with {DuckDB}-wasm as the client running inside a browser. It also leads on to research questions, some of which we describe in the paper.},
	author = {Atwal, R J and Boncz, Peter and Boyd, Ryan and Courtney, Antony and Döhmen, Till and Gerlinghoff, Florian and Huang, Jeff and Hwang, Joseph and Hyde, Raphael and Felder, Elena and Lacouture, Jacob and Lemaout, Yves and Leskes, Boaz and Liu, Yao and Monahan, Alex and Perkins, Dan and Tereshko, Tino and Tigani, Jordan and Ursa, Nick and Wang, Stephanie and Welsch, Yannick},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/R3HR95LZ/p46-atwal.pdf:application/pdf},
}

@report{jain_analyzing_nodate,
	title = {Analyzing and Comparing Lakehouse Storage Systems},
	url = {https://github.com/lhbench/lhbench.},
	abstract = {Lakehouse storage systems that implement {ACID} transactions and other management features over data lake storage, such as Delta Lake, Apache Hudi and Apache Iceberg, have rapidly grown in popularity, replacing traditional data lakes at many organizations. These open storage systems with rich management features promise to simplify management of large datasets, accelerate {SQL} work-loads, and offer fast, direct file access for other workloads, such as machine learning. However, the research community has not explored the tradeoffs in designing lakehouse systems in detail. In this paper, we analyze the designs of the three most popular lake-house storage systems-Delta Lake, Hudi and Iceberg-and compare their performance and features among varying axes based on these designs. We also release a simple benchmark, {LHBench}, that researchers can use to compare other designs. {LHBench} is available at https://github.com/lhbench/lhbench.},
	author = {Jain, Paras and Kraft, Peter and Power, Conor and Das, Tathagata and Stoica, Ion and Zaharia, Matei},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/YJ4RBKB4/p92-jain.pdf:application/pdf},
}

@report{leis_tum_how_2150,
	title = {How Good Are Query Optimizers, Really?},
	url = {http://www-db.in.tum.de/},
	abstract = {Finding a good join order is crucial for query performance. In this paper, we introduce the Join Order Benchmark ({JOB}) and experimentally revisit the main components in the classic query opti-mizer architecture using a complex, real-world data set and realistic multi-join queries. We investigate the quality of industrial-strength cardinality estimators and find that all estimators routinely produce large errors. We further show that while estimates are essential for finding a good join order, query performance is unsatisfactory if the query engine relies too heavily on these estimates. Using another set of experiments that measure the impact of the cost model, we find that it has much less influence on query performance than the cardinality estimates. Finally, we investigate plan enumera-tion techniques comparing exhaustive dynamic programming with heuristic algorithms and find that exhaustive enumeration improves performance despite the sub-optimal cardinality estimates.},
	author = {Leis {TUM}, Viktor and Gubichev {TUM}, Andrey and Mirchev {TUM}, Atanas and Boncz {CWI} pboncz, Peter and Alfons Kemper {TUM}, cwinl and Neumann {TUM}, Thomas},
	date = {2150},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/6Y3H5QJI/p204-leis.pdf:application/pdf},
}

@inproceedings{dageville_snowflake_2016,
	title = {The snowflake elastic data warehouse},
	volume = {26-June-2016},
	isbn = {978-1-4503-3531-7},
	doi = {10.1145/2882903.2903741},
	abstract = {We live in the golden age of distributed computing. Public cloud platforms now offer virtually unlimited compute and storage resources on demand. At the same time, the Software-as-a-Service ({SaaS}) model brings enterprise-class systems to users who previously could not afford such systems due to their cost and complexity. Alas, traditional data warehousing systems are struggling to fit into this new environment. For one thing, they have been designed for fixed resources and are thus unable to leverage the cloud's elasticity. For another thing, their dependence on complex {ETL} pipelines and physical tuning is at odds with the flexibility and freshness requirements of the cloud's new types of semi-structured data and rapidly evolving workloads. We decided a fundamental redesign was in order. Our mission was to build an enterprise-ready data warehousing solution for the cloud. The result is the Snoflake Elastic Data Warehouse, or "Snowake" for short. Snowake is a multi-tenant, transactional, secure, highly scalable and elastic system with full {SQL} support and built-in extensions for semi-structured and schema-less data. The system is offered as a pay-as-you-go service in the Amazon cloud. Users up-load their data to the cloud and can immediately manage and query it using familiar tools and interfaces. Implementation began in late 2012 and Snowake has been generally available since June 2015. Today, Snowake is used in production by a growing number of small and large organizations alike. The system runs several million queries per day over multiple petabytes of data. In this paper, we describe the design of Snowake and its novel multi-cluster, shared-data architecture. The paper highlights some of the key features of Snowake: extreme elasticity and availability, semi-structured and schema-less data, time travel, and end-to-end security. It concludes with lessons learned and an outlook on ongoing work.},
	pages = {215--226},
	booktitle = {Proceedings of the {ACM} {SIGMOD} International Conference on Management of Data},
	publisher = {Association for Computing Machinery},
	author = {Dageville, Benoit and Cruanes, Thierry and Zukowski, Marcin and Antonov, Vadim and Avanes, Artin and Bock, Jon and Claybaugh, Jonathan and Engovatov, Daniel and Hentschel, Martin and Huang, Jiansheng and Lee, Allison W. and Motivala, Ashish and Munir, Abdul Q. and Pelley, Steven and Povinec, Peter and Rahn, Greg and Triantafyllis, Spyridon and Unterbrunner, Philipp},
	date = {2016-06-26},
	note = {{ISSN}: 07308078},
	keywords = {Data warehousing, Database as a service, Multi-cluster shared data architecture},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/VGL5IWDG/p215-dageville-snowflake.pdf:application/pdf},
}

@inproceedings{zeng_empirical_2023,
	title = {An Empirical Evaluation of Columnar Storage Formats},
	volume = {17},
	doi = {10.14778/3626292.3626298},
	abstract = {Columnar storage is a core component of a modern data analytics system. Although many database management systems ({DBMSs}) have proprietary storage formats, most provide extensive support to open-source storage formats such as Parquet and {ORC} to facilitate cross-platform data sharing. But these formats were developed over a decade ago, in the early 2010s, for the Hadoop ecosystem. Since then, both the hardware and workload landscapes have changed. In this paper, we revisit the most widely adopted open-source columnar storage formats (Parquet and {ORC}) with a deep dive into their internals. We designed a benchmark to stress-test the formats’ performance and space efficiency under different workload configurations. From our comprehensive evaluation of Parquet and {ORC}, we identify design decisions advantageous with modern hardware and real-world data distributions. These include using dictionary encoding by default, favoring decoding speed over compression ratio for integer encoding algorithms, making block compression optional, and embedding finer-grained auxiliary data structures. We also point out the inefficiencies in the format designs when handling common machine learning workloads and using {GPUs} for decoding. Our analysis identified important considerations that may guide future formats to better fit modern technology trends.},
	pages = {148--161},
	booktitle = {Proceedings of the {VLDB} Endowment},
	publisher = {{VLDB} Endowment},
	author = {Zeng, Xinyu and Hui, Yulong and Shen, Jiahong and Pavlo, Andrew and {McKinney}, Wes and Zhang Huanchen@Tsinghua.Edu.Cn, Huanchen},
	date = {2023},
	eprinttype = {arxiv},
	eprint = {2304.05028},
	note = {Issue: 2
{ISSN}: 21508097},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/P4HLTAWM/p148-zeng.pdf:application/pdf},
}

@book{noauthor_proceedings_2013,
	title = {Proceedings of the 2011 {ACM} {SIGMOD} International Conference on Management of data},
	isbn = {978-1-4503-0661-4},
	publisher = {{ACM} Digital Library},
	date = {2013},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/XP6GUSQZ/p37-blanas.pdf:application/pdf},
}

@inproceedings{sun_end--end_2020,
	title = {An end-to-end learning-based cost estimator},
	volume = {13},
	doi = {10.14778/3368289.3368296},
	abstract = {Cost and cardinality estimation is vital to query optimizer, which can guide the query plan selection. However traditional empirical cost and cardinality estimation techniques cannot provide high-quality estimation, because they may not effectively capture the correlation between multiple tables. Recently the database community shows that the learning-based cardinality estimation is better than the empirical methods. However, existing learning-based methods have several limitations. Firstly, they focus on estimating the cardinality, but cannot estimate the cost. Secondly, they are either too heavy or hard to represent complicated structures, e.g., complex predicates. To address these challenges, we propose an effective endto- end learning-based cost estimation framework based on a tree-structured model, which can estimate both cost and cardinality simultaneously. We propose effective feature extraction and encoding techniques, which consider both queries and physical operations in feature extraction. We embed these features into our tree-structured model. We propose an effective method to encode string values, which can improve the generalization ability for predicate matching. As it is prohibitively expensive to enumerate all string values, we design a patten-based method, which selects patterns to cover string values and utilizes the patterns to embed string values. We conducted experiments on real-world datasets and experimental results showed that our method outperformed baselines.},
	pages = {307--319},
	booktitle = {Proceedings of the {VLDB} Endowment},
	publisher = {{VLDB} Endowment},
	author = {Sun, Ji and Li, Guoliang},
	date = {2020},
	eprinttype = {arxiv},
	eprint = {1906.02560},
	note = {Issue: 3
{ISSN}: 21508097},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/EMNRBRG6/p307-sun.pdf:application/pdf},
}

@inproceedings{begoli_apache_2018,
	title = {Apache calcite: A foundational framework for optimized query processing over heterogeneous data sources},
	isbn = {978-1-4503-1743-6},
	doi = {10.1145/3183713.3190662},
	abstract = {Apache Calcite is a foundational software framework that provides query processing, optimization, and query language support to many popular open-source data processing systems such as Apache Hive, Apache Storm, Apache Flink, Druid, and {MapD}. The goal of this paper is to formally introduce Calcite to the broader research community, briefly present its history, and describe its architecture, features, functionality, and patterns for adoption. Calcite's architecture consists of a modular and extensible query optimizer with hundreds of built-in optimization rules, a query processor capable of processing a variety of query languages, an adapter architecture designed for extensibility, and support for heterogeneous data models and stores (relational, semi-structured, streaming, and geospatial). This flexible, embeddable, and extensible architecture is what makes Calcite an attractive choice for adoption in big-data frameworks. It is an active project that continues to introduce support for the new types of data sources, query languages, and approaches to query processing and optimization.},
	pages = {221--230},
	booktitle = {Proceedings of the {ACM} {SIGMOD} International Conference on Management of Data},
	publisher = {Association for Computing Machinery},
	author = {Begoli, Edmon and Camacho-Rodríguez, Jesús and Hyde, Julian and Mior, Michael J. and Lemire, Daniel},
	date = {2018-05-27},
	eprinttype = {arxiv},
	eprint = {1802.10233},
	note = {{ISSN}: 07308078},
	keywords = {Apache calcite, Data management, Modular query optimization, Query algebra, Relational semantics, Storage adapters},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/LWK2GW5I/p221-begoli.pdf:application/pdf},
}

@inproceedings{yang_deep_2020,
	title = {Deep unsupervised cardinality estimation},
	volume = {13},
	doi = {10.14778/3368289.3368294},
	abstract = {Cardinality estimation has long been grounded in statistical tools for density estimation. To capture the rich multivariate distributions of relational tables, we propose the use of a new type of high-capacity statistical model: deep autoregressive models. However, direct application of these models leads to a limited estimator that is prohibitively expensive to evaluate for range or wildcard predicates. To produce a truly usable estimator, we develop a Monte Carlo integration scheme on top of autoregressive models that can efficiently handle range queries with dozens of dimensions or more. Like classical synopses, our estimator summarizes the data without supervision. Unlike previous solutions, we approximate the joint data distribution without any independence assumptions. Evaluated on real-world datasets and compared against real systems and dominant families of techniques, our estimator achieves single-digit multiplicative error at tail, an up to 90× accuracy improvement over the second best method, and is space- and runtime-efficient.},
	pages = {279--292},
	booktitle = {Proceedings of the {VLDB} Endowment},
	publisher = {{VLDB} Endowment},
	author = {Yang, Zongheng and Liang, Eric and Kamsetty, Amog and Wu, Chenggang and Duan, Yan and Chen, Xi and Abbeel, Pieter and Hellerstein, Joseph M. and Krishnan, Sanjay and Stoica, Ion},
	date = {2020},
	eprinttype = {arxiv},
	eprint = {1905.04278},
	note = {Issue: 3
{ISSN}: 21508097},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/LI92J6AN/p279-yang.pdf:application/pdf},
}

@inproceedings{soliman_orca_2014,
	title = {Orca: A modular query optimizer architecture for big data},
	isbn = {978-1-4503-2376-5},
	doi = {10.1145/2588555.2595637},
	abstract = {The performance of analytical query processing in data management systems depends primarily on the capabilities of the system's query optimizer. Increased data volumes and heightened interest in processing complex analytical queries have prompted Pivotal to build a new query optimizer. In this paper we present the architecture of Orca, the new query optimizer for all Pivotal data management products, including Pivotal Greenplum Database and Pivotal {HAWQ}. Orca is a comprehensive development uniting state-of-the-art query optimization technology with own original research resulting in a modular and portable optimizer architecture. In addition to describing the overall architecture, we highlight several unique features and present performance comparisons against other systems. © 2014 {ACM}.},
	pages = {337--348},
	booktitle = {Proceedings of the {ACM} {SIGMOD} International Conference on Management of Data},
	publisher = {Association for Computing Machinery},
	author = {Soliman, Mohamed A. and Antova, Lyublena and Raghavan, Venkatesh and El-Helw, Amr and Gu, Zhongxian and Shen, Entong and Caragea, George C. and Garcia-Alvarado, Carlos and Rahman, Foyzur and Petropoulos, Michalis and Waasz, Florian and Narayananx, Sivaramakrishnan and Krikellasy, Konstantinos and Baldwin, Rhonda},
	date = {2014},
	note = {{ISSN}: 07308078},
	keywords = {Cost model, {MPP}, Parallel processing, Query optimization},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/YYXHWDJK/p337-soliman.pdf:application/pdf},
}

@report{neumann_efficiently_2150,
	title = {Efficiently Compiling Efficient Query Plans for Modern Hardware},
	abstract = {As main memory grows, query performance is more and more determined by the raw {CPU} costs of query processing itself. The classical iterator style query processing technique is very simple and flexible, but shows poor performance on modern {CPUs} due to lack of locality and frequent instruction mis-predictions. Several techniques like batch oriented processing or vectorized tuple processing have been proposed in the past to improve this situation, but even these techniques are frequently out-performed by handwritten execution plans. In this work we present a novel compilation strategy that translates a query into compact and efficient machine code using the {LLVM} compiler framework. By aiming at good code and data locality and predictable branch layout the resulting code frequently rivals the performance of handwritten C++ code. We integrated these techniques into the {HyPer} main memory database system and show that this results in excellent query performance while requiring only modest compilation time.},
	author = {Neumann, Thomas},
	date = {2150},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/CBXN8QWN/p539-neumann.pdf:application/pdf},
}

@article{armbrust_delta_2020,
	title = {Delta Lake: High-Performance {ACID} Table Storage over Cloud Object Stores},
	volume = {13},
	issn = {21508097},
	doi = {10.14778/3415478.3415560},
	abstract = {Cloud object stores such as Amazon S3 are some of the largest and most cost-effective storage systems on the planet, making them an attractive target to store large data warehouses and data lakes. Unfortunately, their implementation as key-value stores makes it difficult to achieve {ACID} transactions and high performance: metadata operations such as listing objects are expensive, and consistency guarantees are limited. In this paper, we present Delta Lake, an open source {ACID} table storage layer over cloud object stores initially developed at Databricks. Delta Lake uses a transaction log that is compacted into Apache Parquet format to provide {ACID} properties, time travel, and significantly faster metadata operations for large tabular datasets (e.g., the ability to quickly search billions of table partitions for those relevant to a query). It also leverages this design to provide high-level features such as automatic data layout optimization, upserts, caching, and audit logs. Delta Lake tables can be accessed from Apache Spark, Hive, Presto, Redshift and other systems. Delta Lake is deployed at thousands of Databricks customers that process exabytes of data per day, with the largest instances managing exabyte-scale datasets and billions of objects.},
	pages = {3411--3424},
	number = {12},
	journaltitle = {Proceedings of the {VLDB} Endowment},
	author = {Armbrust, Michael and Das, Tathagata and Sun, Liwen and Yavuz, Burak and Zhu, Shixiong and Murthy, Mukul and Torres, Joseph and van Hovell, Herman and Ionescu, Adrian and Łuszczak, Alicja and Świtakowski, Michał and Szafrański, Michał and Li, Xiao and Ueshin, Takuya and Mokhtar, Mostafa and Boncz, Peter and Ghodsi, Ali and Paranjpye, Sameer and Senster, Pieter and Xin, Reynold and Zaharia, Matei},
	date = {2020},
	note = {Publisher: {VLDB} Endowment},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/3UWNF8FN/p975-armbrust.pdf:application/pdf},
}

@report{zhu_looking_2150,
	title = {Looking Ahead Makes Query Plans Robust Making the Initial Case with In-Memory Star Schema Data Warehouse Workloads},
	abstract = {Query optimizers and query execution engines cooperate to deliver high performance on complex analytic queries. Typically , the optimizer searches through the plan space and sends a selected plan to the execution engine. However, optimizers may at times miss the optimal plan, with sometimes disastrous impact on performance. In this paper, we develop the notion of robustness of a query evaluation strategy with respect to a space of query plans. We also propose a novel query execution strategy called Lookahead Information Passing ({LIP}) that is robust with respect to the space of (fully pipeline-able) left-deep query plan trees for in-memory star schema data warehouses. {LIP} ensures that execution times for the best and the worst case plans are far closer than without {LIP}. In fact, under certain assumptions of independent and uniform distributions, any plan in that space is theoretically guaranteed to execute in near-optimal time. {LIP} ensures that the execution time for every plan in the space is nearly-optimal. In this paper, we also evaluate these claims using workloads that include skew and correlation. With {LIP} we make an initial foray into a novel way of thinking about robustness from the perspective of query evaluation, where we develop strategies (like {LIP}) that collapse plan sub-spaces in the overall global plan space.},
	author = {Zhu, Jianqiao and Potti, Navneet and Saurabh, Saket and Patel, Jignesh M},
	date = {2150},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/59QQ3IVA/p889-zhu.pdf:application/pdf},
}

@inproceedings{chen_two-level_2017,
	title = {Two-level sampling for Join size estimation},
	volume = {Part F127746},
	isbn = {978-1-4503-4197-4},
	doi = {10.1145/3035918.3035921},
	abstract = {Join size estimation is a critical step in query optimization, and has been extensively studied in the literature. Among the many techniques, sampling based approaches are particularly appealing, due to their ability to handle arbitrary selection predicates. In this paper, we propose a new sampling algorithm for join size estimation, called two-level sampling, which combines the advantages of three previous sampling methods while making further improvements. Both analytical and empirical comparisons show that the new algorithm outperforms all the previous algorithms on a variety of joins, including primary key-foreign key joins, many-to-many joins, and multi-table joins. The new sampling algorithm is also very easy to implement, requiring just one pass over the data. It only relies on some basic statistical information about the data, such as the 4-norms and the heavy hitters.},
	pages = {759--774},
	booktitle = {Proceedings of the {ACM} {SIGMOD} International Conference on Management of Data},
	publisher = {Association for Computing Machinery},
	author = {Chen, Yu and Yi, Ke},
	date = {2017-05-09},
	note = {{ISSN}: 07308078},
	keywords = {Joins, Sampling},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/7HSZ3ILL/p759-chen.pdf:application/pdf},
}

@report{afrati_storing_2150,
	title = {Storing and Querying Tree-Structured Records in Dremel},
	abstract = {In Dremel, data is stored as nested relations. The schema for a relation is a tree, all of whose nodes are attributes, and whose leaf attributes hold values. We explore filter and aggregate queries that are given in the Dremel dialect of {SQL}. Complications arise because of repeated attributes, i.e., attributes that are allowed to have more than one value. We focus on the common class of Dremel queries that are processed on column-stored data in a way that results in query processing time that is linear on the size of the relevant data, i.e., data in the columns that participate in the query. We formally define the data model, the query language and the algorithms for query processing in column-stored data. The concepts of repetition context and semi-flattening are introduced here and play a central role in understanding this class of queries and their algorithms.},
	author = {Afrati, Foto N and Google, Dan Delorey and Google, Mosha Pasumansky and Ullman, Jeffrey D},
	date = {2150},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/ZN2ZHFZK/p1131-afrati.pdf:application/pdf},
}

@report{raasveldt_dont_2150,
	title = {Don't Hold My Data Hostage-A Case For Client Protocol Redesign},
	abstract = {Transferring a large amount of data from a database to a client program is a surprisingly expensive operation. The time this requires can easily dominate the query execution time for large result sets. This represents a significant hurdle for external data analysis, for example when using statistical software. In this paper, we explore and analyse the result set serialization design space. We present experimental results from a large chunk of the database market and show the inefficiencies of current approaches. We then propose a columnar serialization method that improves transmission performance by an order of magnitude.},
	author = {Raasveldt, Mark},
	date = {2150},
	keywords = {Client Protocols, Data Export, Databases},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/NEQIUSN2/p1022-muehleisen.pdf:application/pdf},
}

@inproceedings{neumann_adaptive_2018,
	title = {Adaptive optimization of very large join queries},
	isbn = {978-1-4503-1743-6},
	doi = {10.1145/3183713.3183733},
	abstract = {The use of business intelligence tools and other means to generate queries has led to great variety in the size of join queries. While most queries are reasonably small, join queries with up to a hundred relations are not that exotic anymore, and the distribution of query sizes has an incredible long tail. The largest real-world query that we are aware of accesses more than 4,000 relations. This large spread makes query optimization very challenging. Join ordering is known to be {NP}-hard, which means that we cannot hope to solve such large problems exactly. On the other hand most queries are much smaller, and there is no reason to sacrifice optimality there. This paper introduces an adaptive optimization framework that is able to solve most common join queries exactly, while simultaneously scaling to queries with thousands of joins. A key component there is a novel search space linearization technique that leads to near-optimal execution plans for large classes of queries. In addition, we describe implementation techniques that are necessary to scale join ordering algorithms to these extremely large queries. Extensive experiments with over 10 different approaches show that the new adaptive approach proposed here performs excellent over a huge spectrum of query sizes, and produces optimal or near-optimal solutions for most common queries.},
	pages = {677--692},
	booktitle = {Proceedings of the {ACM} {SIGMOD} International Conference on Management of Data},
	publisher = {Association for Computing Machinery},
	author = {Neumann, Thomas and Radke, Bernhard},
	date = {2018-05-27},
	note = {{ISSN}: 07308078},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/KCAVVMLM/p677-neumann.pdf:application/pdf},
}

@inproceedings{gruber_bringing_2023,
	title = {Bringing Compiling Databases to {RISC} Architectures},
	volume = {16},
	doi = {10.14778/3583140.3583142},
	abstract = {Current hardware development greatly influences the design decisions of modern database systems. For many modern performance-focused database systems, query compilation emerged as an integral part and different approaches for code generation evolved, making use of standard compilers, general-purpose compiler libraries, or domain-specific code generators. However, development primarily focused on the dominating x86-64 server architecture; but neglected current hardware developments towards other {CPU} architectures like {ARM} and other {RISC} architectures. Therefore, we explore the design space of code generation in database systems considering a variety of state-of-the-art compilation approaches with a set of qualitative and quantitative metrics. Based on our findings, we have developed a new code generator called {FireARM} for {AArch}64-based systems in our database system, Umbra. We identify general as well as architecture-specific challenges for custom code generation in databases and provide potential solutions to abstract or handle them. Furthermore, we present an extensive evaluation of different compilation approaches in Umbra on a wide variety of x86-64 and {ARM} machines. In particular, we compare quantitative performance characteristics such as compilation latency and query throughput. Our results show that using standard languages and compiler infrastructures reduces the barrier to employing query compilation and allows for high performance on big data sets, while domain-specific code generators can achieve a significantly lower compilation overhead and allow for better targeting of new architectures.},
	pages = {1222--1234},
	booktitle = {Proceedings of the {VLDB} Endowment},
	publisher = {{VLDB} Endowment},
	author = {Gruber, Ferdinand and Bandle, Maximilian and Engelke, Alexis and Neumann, Thomas and Giceva, Jana},
	date = {2023},
	note = {Issue: 6
{ISSN}: 21508097},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/8WBMQ84S/p1222-gruber.pdf:application/pdf},
}

@inproceedings{leis_morsel-driven_2014,
	title = {Morsel-driven parallelism: A {NUMA}-aware query evaluation framework for the many-core age},
	isbn = {978-1-4503-2376-5},
	doi = {10.1145/2588555.2610507},
	abstract = {With modern computer architecture evolving, two problems conspire against the state-of-the-art approaches in parallel query execution: (i) to take advantage of many-cores, all query work must be distributed evenly among (soon) hundreds of threads in order to achieve good speedup, yet (ii) dividing the work evenly is difficult even with accurate data statistics due to the complexity of modern out-of-order cores. As a result, the existing approaches for "plandriven" parallelism run into load balancing and context-switching bottlenecks, and therefore no longer scale. A third problem faced by many-core architectures is the decentralization of memory controllers, which leads to Non-Uniform Memory Access ({NUMA}). In response, we present the "morsel-driven" query execution framework, where scheduling becomes a fine-grained run-time task that is {NUMA}-aware. Morsel-driven query processing takes small fragments of input data ("morsels") and schedules these to worker threads that run entire operator pipelines until the next pipeline breaker. The degree of parallelism is not baked into the plan but can elastically change during query execution, so the dispatcher can react to execution speed of different morsels but also adjust resources dynamically in response to newly arriving queries in the workload. Further, the dispatcher is aware of data locality of the {NUMA}-local morsels and operator state, such that the great majority of executions takes place on {NUMA}-local memory. Our evaluation on the {TPC}-H and {SSB} benchmarks shows extremely high absolute performance and an average speedup of over 30 with 32 cores.},
	pages = {743--754},
	booktitle = {Proceedings of the {ACM} {SIGMOD} International Conference on Management of Data},
	publisher = {Association for Computing Machinery},
	author = {Leis, Viktor and Boncz, Peter and Kemper, Alfons and Neumann, Thomas},
	date = {2014},
	note = {{ISSN}: 07308078},
	keywords = {Morsel-driven parallelism, {NUMA}-awareness},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/GN2CGINK/p743-leis.pdf:application/pdf},
}

@inproceedings{ramachandra_froid_2018,
	title = {Froid: Optimization of imperative programs in a relational database},
	volume = {11},
	doi = {10.1145/3164135.3164140},
	abstract = {For decades, {RDBMSs} have supported declarative {SQL} as well as imperative functions and procedures as ways for users to express data processing tasks. While the evaluation of declarative {SQL} has received a lot of attention resulting in highly sophisticated techniques, the evaluation of imperative programs has remained nai¨ve and highly inefficient. Imperative programs offer several benefits over {SQL} and hence are often preferred and widely used. But unfortunately, their abysmal performance discourages, and even prohibits their use in many situations. We address this important problem that has hitherto received little attention. We present Froid, an extensible framework for optimizing imperative programs in relational databases. Froid's novel approach automatically transforms entire User Defined Functions ({UDFs}) into relational algebraic expressions, and embeds them into the calling {SQL} query. This form is now amenable to cost-based optimization and results in efficient, set-oriented, parallel plans as opposed to inefficient, iterative, serial execution of {UDFs}. Froid's approach additionally brings the benefits of many compiler optimizations to {UDFs} with no additional implementation effort. We describe the design of Froid and present our experimental evaluation that demonstrates performance improvements of up to multiple orders of magnitude on real workloads.},
	pages = {432--444},
	booktitle = {Proceedings of the {VLDB} Endowment},
	publisher = {{VLDB} Endowment},
	author = {Ramachandra, Karthik and Park, Kwanghyun and Emani, K. Venkatesh and Halverson, Alan and Galindo-Legaria, Ce´sar and Cunningham, Conor},
	date = {2018},
	eprinttype = {arxiv},
	eprint = {1712.00498},
	note = {Issue: 4
{ISSN}: 21508097},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/8TZ7I9JQ/p432-ramachandra.pdf:application/pdf},
}

@inproceedings{ding_plan_2018,
	title = {Plan stitch: Harnessing the best of many plans},
	volume = {11},
	doi = {10.14778/3231751.3231761},
	abstract = {Query performance regression due to the query optimizer selecting a bad query execution plan is a major pain point in production workloads. Commercial {DBMSs} today can automatically detect and correct such query plan regressions by storing previouslyexecuted plans and reverting to a previous plan which is still valid and has the least execution cost. Such reversion-based plan correction has relatively low risk of plan regression since the decision is based on observed execution costs. However, this approach ignores potentially valuable information of efficient subplans collected from other previously-executed plans. In this paper, we propose a novel technique, Plan Stitch, that automatically and opportunistically combines efficient subplans of previously-executed plans into a valid new plan, which can be cheaper than any individual previously-executed plan. We implement Plan Stitch on top of Microsoft {SQL} Server. Our experiments on {TPC}-{DS} benchmark and three real-world customer workloads show that plans obtained via Plan Stitch can reduce execution cost significantly, with a reduction of up to two orders of magnitude in execution cost when compared to reverting to the cheapest previously-executed plan.},
	pages = {1123--1136},
	booktitle = {Proceedings of the {VLDB} Endowment},
	publisher = {Association for Computing Machinery},
	author = {Ding, Bailu and Das, Sudipto and Wu, Wentao and Chaudhuri, Surajit and Narasayya, Vivek},
	date = {2018},
	note = {Issue: 10
{ISSN}: 21508097},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/5BMXP59S/p1123-ding.pdf:application/pdf},
}

@inproceedings{kersten_everything_2018,
	title = {Everything you always wanted to know about compiled and vectorized queries but were afraid to ask},
	volume = {11},
	doi = {10.14778/3275366.3275370},
	abstract = {The query engines of most modern database systems are either based on vectorization or data-centric code generation. These two state-of-the-art query processing paradigms are fundamentally different in terms of system structure and query execution code. Both paradigms were used to build fast systems. However, until today it is not clear which paradigm yields faster query execution, as many implementation-specific choices obstruct a direct comparison of architectures. In this paper, we experimentally compare the two models by implementing both within the same test system. This allows us to use for both models the same query processing algorithms, the same data structures, and the same parallelization framework to ultimately create an apples-to-apples comparison. We find that both are efficient, but have different strengths and weaknesses. Vectorization is better at hiding cache miss latency, whereas data-centric compilation requires fewer {CPU} instructions, which benefits cacheresident workloads. Besides raw, single-threaded performance, we also investigate {SIMD} as well as multi-core parallelization and different hardware architectures. Finally, we analyze qualitative differences as a guide for system architects.},
	pages = {2209--2222},
	booktitle = {Proceedings of the {VLDB} Endowment},
	publisher = {{VLDB} Endowment},
	author = {Kersten, Timo and Leis, Viktor and Kemper, Alfons and Neumann, Thomas and Pavlo, Andrew and Boncz, Peter},
	date = {2018},
	note = {Issue: 13
{ISSN}: 21508097},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/SHLIJYIV/p2209-kersten.pdf:application/pdf},
}

@article{freitag_adopting_2020,
	title = {Adopting worst-case optimal joins in relational database systems},
	volume = {13},
	issn = {21508097},
	doi = {10.14778/3407790.3407797},
	abstract = {Worst-case optimal join algorithms are attractive from a theoretical point of view, as they offer asymptotically better runtime than binary joins on certain types of queries. In particular, they avoid enumerating large intermediate results by processing multiple input relations in a single multiway join. However, existing implementations incur a sizable overhead in practice, primarily since they rely on suitable ordered index structures on their input. Systems that support worst-case optimal joins often focus on a specific problem domain, such as read-only graph analytic queries, where extensive precomputation allows them to mask these costs. In this paper, we present a comprehensive implementation approach for worst-case optimal joins that is practical within general-purpose relational database management systems supporting both hybrid transactional and analytical workloads. The key component of our approach is a novel hash-based worst-case optimal join algorithm that relies only on data structures that can be built efficiently during query execution. Furthermore, we implement a hybrid query optimizer that intelligently and transparently combines both binary and multi-way joins within the same query plan. We demonstrate that our approach far outperforms existing systems when worst-case optimal joins are beneficial while sacrificing no performance when they are not.},
	pages = {1891--1904},
	number = {11},
	journaltitle = {Proceedings of the {VLDB} Endowment},
	author = {Freitag, Michael and Bandle, Maximilian and Schmidt, Tobias and Kemper, Alfons and Neumann, Thomas},
	date = {2020-07-01},
	note = {Publisher: {VLDB} Endowment},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/ZW755TSW/p1891-freitag.pdf:application/pdf},
}

@report{psaroudakis_scaling_2150,
	title = {Scaling Up Concurrent Main-Memory Column-Store Scans: Towards Adaptive {NUMA}-aware Data and Task Placement},
	abstract = {Main-memory column-stores are called to efficiently use modern non-uniform memory access ({NUMA}) architectures to service concurrent clients on big data. The efficient usage of {NUMA} architectures depends on the data placement and scheduling strategy of the column-store. Most column-stores choose a static strategy that involves partitioning all data across the {NUMA} architecture, and employing a stealing-based task scheduler. In this paper, we implement different strategies for data placement and task scheduling for the case of concurrent scans. We compare these strategies with an extensive sensitivity analysis. Our most significant findings include that unnecessary partitioning can hurt through-put by up to 70\%, and that stealing memory-intensive tasks can hurt throughput by up to 58\%. Based on our analysis, we envision a design that adapts the data placement and task scheduling strategy to the workload.},
	author = {Psaroudakis, Iraklis and Scheuer, Tobias and May, Norman and Sellami, Abdelkader and Ailamaki, Anastasia},
	date = {2150},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/LVUWI2AT/p1442-psaroudakis.pdf:application/pdf},
}

@inproceedings{pedreira_composable_2023,
	title = {The Composable Data Management System Manifesto},
	volume = {16},
	doi = {10.14778/3603581.3603604},
	abstract = {The requirement for specialization in data management systems has evolved faster than our software development practices. After decades of organic growth, this situation has created a siloed landscape composed of hundreds of products developed and maintained as monoliths, with limited reuse between systems. This fragmentation has resulted in developers often reinventing the wheel, increased maintenance costs, and slowed down innovation. It has also affected the end users, who are often required to learn the idiosyncrasies of dozens of incompatible {SQL} and non-{SQL} {API} dialects, and settle for systems with incomplete functionality and inconsistent semantics. In this vision paper, considering the recent popularity of open source projects aimed at standardizing different aspects of the data stack, we advocate for a paradigm shift in how data management systems are designed. We believe that by decomposing these into a modular stack of reusable components, development can be streamlined while creating a more consistent experience for users. Towards that goal, we describe the state-of-the-art, principal open source technologies, and highlight open questions and areas where additional research is needed. We hope this work will foster collaboration, motivate further research, and promote a more composable future for data management.},
	pages = {2679--2685},
	booktitle = {Proceedings of the {VLDB} Endowment},
	publisher = {{VLDB} Endowment},
	author = {Pedreira, Pedro and Erling, Orri and Karanasos, Konstantinos and Schneider, Scott and {McKinney}, Wes and Valluri, Satya R. and Zait, Mohamed and Nadeau, Jacques},
	date = {2023},
	note = {Issue: 10
{ISSN}: 21508097},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/VVC5NYXP/p2679-pedreira.pdf:application/pdf},
}

@report{vengerov_join_2150,
	title = {Join Size Estimation Subject to Filter Conditions},
	abstract = {In this paper, we present a new algorithm for estimating the size of equality join of multiple database tables. The proposed algorithm, Correlated Sampling, constructs a small space synopsis for each table, which can then be used to provide a quick estimate of the join size of this table with other tables subject to dynamically specified predicate filter conditions, possibly specified over multiple columns (attributes) of each table. This algorithm makes a single pass over the data and is thus suitable for streaming scenarios. We compare this algorithm analytically to two other previously known sampling approaches (independent Bernoulli Sampling and End-Biased Sampling) and to a novel sketch-based approach. We also compare these four algorithms experimentally and show that results fully correspond to our analytical predictions based on derived expressions for the estimator variances, with Correlated Sampling giving the best estimates in a large range of situations.},
	author = {Vengerov, David and Menck, Andre Cavalheiro and Zait, Mohamed and Chakkappen, Sunil P},
	date = {2150},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/FG4NB4PQ/p1530-vengerov.pdf:application/pdf},
}

@inproceedings{schuh_experimental_2016,
	title = {An experimental comparison of thirteen relational equi-joins in main memory},
	volume = {26-June-2016},
	isbn = {978-1-4503-3531-7},
	doi = {10.1145/2882903.2882917},
	abstract = {Relational equi-joins are at the heart of almost every query plan. They have been studied, improved, and reexamined on a regular basis since the existence of the database community. In the past four years several new join algorithms have been proposed and experimentally evaluated. Some of those papers contradict each other in their experimental findings. This makes it surprisingly hard to answer a very simple question: what is the fastest join algorithm in 2015? In this paper we will try to develop an answer. We start with an end-to-end black box comparison of the most important methods. Afterwards, we inspect the internals of these algorithms in a white box comparison. We derive improved variants of stateof-the-art join algorithms by applying optimizations like softwarewrite combine buffers, various hash table implementations, as well as {NUMA}-awareness in terms of data placement and scheduling. We also inspect various radix partitioning strategies. Eventually, we are in the position to perform a comprehensive comparison of thirteen different join algorithms. We factor in scaling effects in terms of size of the input datasets, the number of threads, different page sizes, and data distributions. Furthermore, we analyze the impact of various joins on an (unchanged) {TPC}-H query. Finally, we conclude with a list of major lessons learned from our study and a guideline for practitioners implementing massive main-memory joins. As is the case with almost all algorithms in databases, we will learn that there is no single best join algorithm. Each algorithm has its strength and weaknesses and shines in different areas of the parameter space.},
	pages = {1961--1976},
	booktitle = {Proceedings of the {ACM} {SIGMOD} International Conference on Management of Data},
	publisher = {Association for Computing Machinery},
	author = {Schuh, Stefan and Chen, Xiao and Dittrich, Jens},
	date = {2016-06-26},
	note = {{ISSN}: 07308078},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/5EK8T35P/schuh-sigmod2016-2.pdf:application/pdf},
}

@inproceedings{afroozeh_fast_2023,
	title = {The Fast Lanes Compression Layout: Decoding {\textgreater}100 Billion Integers per Second with Scalar Code},
	volume = {16},
	doi = {10.14778/3598581.3598587},
	abstract = {The open-source Fast Lanes project aims to improve big data formats, such as Parquet, {ORC} and columnar database formats, in multiple ways. In this paper, we significantly accelerate decoding of all common Light-Weight Compression ({LWC}) schemes: {DICT}, {FOR}, {DELTA} and {RLE} through better data-parallelism. We do soby re-designing the compression layout using two main ideas: (i)generalizing the value interleaving technique in the basic operation of bit-(un)packing by targeting a virtual 1024-bits {SIMD} register, (ii)reordering the tuples in all columns of a table in the same Unified Transposed Layout that puts tuple chunks in a common 104261537 žorder (explained in the paper); allowing for maximum independent work for all possible basic {SIMD} lane widths: 8, 16, 32, and 64 bits. We address the software development, maintenance and future proofness challenges of increasing hardware diversity, by defininga virtual 1024-bits instruction set that consists of simple operators supported by all {SIMD} dialects; and also, importantly, by scalar code. The interleaved and tuple-reordered layout actually makesscalar decoding faster, extracting more data-parallelism from today’swide-issue {CPUs}. Importantly, the scalar version can be fullyauto-vectorized by modern compilers, eliminating technical debtin software caused by platform-specific {SIMD} in trinsics. Micro-benchmarks on Intel, {AMD}, Apple and {AWS} {CPUs} show that Fast Lanes accelerates decoding by factors (decoding {\textgreater} 40 valuesper {CPU} cycle). Fast Lanes can make queries faster, as compressing the data reduces bandwidth needs, while decoding is almost free.},
	pages = {2132--2144},
	booktitle = {Proceedings of the {VLDB} Endowment},
	publisher = {{VLDB} Endowment},
	author = {Afroozeh, Azim and Boncz, Peter},
	date = {2023},
	note = {Issue: 9
{ISSN}: 21508097},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/7XNRPVVC/p2132-afroozeh.pdf:application/pdf},
}

@report{richter_seven-dimensional_2150,
	title = {A Seven-Dimensional Analysis of Hashing Methods and its Implications on Query Processing},
	abstract = {Hashing is a solved problem. It allows us to get constant time access for lookups. Hashing is also simple. It is safe to use an arbitrary method as a black box and expect good performance, and optimizations to hashing can only improve it by a negligible delta. Why are all of the previous statements plain wrong? That is what this paper is about. In this paper we thoroughly study hashing for integer keys and carefully analyze the most common hashing methods in a five-dimensional requirements space: () data-distribution, () load factor, () dataset size, () read/write-ratio, and () un/successful-ratio. Each point in that design space may potentially suggest a different hashing scheme, and additionally also a different hash function. We show that a right or wrong decision in picking the right hashing scheme and hash function combination may lead to significant difference in performance. To substantiate this claim, we carefully analyze two additional dimensions: () five representative hashing schemes (which includes an improved variant of Robin Hood hashing), () four important classes of hash functions widely used today. That is, we consider 20 different combinations in total. Finally, we also provide a glimpse about the effect of table memory layout and the use of {SIMD} instructions. Our study clearly indicates that picking the right combination may have considerable impact on insert and lookup performance, as well as memory footprint. A major conclusion of our work is that hashing should be considered a white box before blindly using it in applications, such as query processing. Finally, we also provide a strong guideline about when to use which hashing method.},
	author = {Richter, Stefan and Alvarez, Victor and Dittrich, Jens},
	date = {2150},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/IVQZAIBD/richter-vldb2015.pdf:application/pdf},
}

@inproceedings{pedreira_velox_2022,
	title = {Velox: Meta’s Unified Execution Engine},
	volume = {15},
	doi = {10.14778/3554821.3554829},
	abstract = {The ad-hoc development of new specialized computation engines targeted to very specific data workloads has created a siloed data landscape. Commonly, these engines share little to nothing with each other and are hard to maintain, evolve, and optimize, and ultimately provide an inconsistent experience to data users. In order to address these issues, Meta has created Velox, a novel open source C++ database acceleration library. Velox provides reusable, extensible, high-performance, and dialect-agnostic data processing components for building execution engines, and enhancing data management systems. The library heavily relies on vectorization and adaptivity, and is designed from the ground up to support efficient computation over complex data types due to their ubiquity in modern workloads. Velox is currently integrated or being integrated with more than a dozen data systems at Meta, including analytical query engines such as Presto and Spark, stream processing platforms, message buses and data warehouse ingestion infrastructure, machine learning systems for feature engineering and data preprocessing ({PyTorch}), and more. It provides benefits in terms of (a) efficiency wins by democratizing optimizations previously only found in individual engines, (b) increased consistency for data users, and (c) engineering efficiency by promoting reusability.},
	pages = {3372--3384},
	booktitle = {Proceedings of the {VLDB} Endowment},
	publisher = {{VLDB} Endowment},
	author = {Pedreira, Pedro and Erling, Orri and Basmanova, Masha and Wilfong, Kevin and Sakka, Laith and Pai, Krishna and He, Wei and Chattopadhyay, Biswapesh},
	date = {2022},
	note = {Issue: 12
{ISSN}: 21508097},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/NNVLSVRS/p3372-pedreira.pdf:application/pdf},
}

@report{stillger_leo-db2s_nodate,
	title = {{LEO}-{DB}2's {LEarning} Optimizer},
	abstract = {Most modern {DBMS} optimizers rely upon a cost model to choose the best query execution plan ({QEP}) for any given query. Cost estimates are heavily dependent upon the optimizer's estimates for the number of rows that will result at each step of the {QEP} for complex queries involving many predicates and/or operations. These estimates rely upon statistics on the database and modeling assumptions that may or may not be true for a given database. In this paper we introduce {LEO}, {DB}2's {LEarning} Optimizer, as a comprehensive way to repair incorrect statistics and cardinality estimates of a query execution plan. By monitoring previously executed queries, {LEO} compares the optimizer's estimates with actuals at each step in a {QEP}, and computes adjustments to cost estimates and statistics that may be used during future query optimizations. This analysis can be done either on-line or off-line on a separate system, and either incrementally or in batches. In this way, {LEO} introduces a feedback loop to query optimization that enhances the available information on the database where the most queries have occurred, allowing the optimizer to actually learn from its past mistakes. Our technique is general and can be applied to any operation in a {QEP}, including joins, derived results after several predicates have been applied, and even to {DISTINCT} and {GROUP}-{BY} operators. As shown by performance measurements on a 10 {GB} {TPC}-H data set, the runtime overhead of {LEO}'s monitoring is insignificant, whereas the potential benefit to response time from more accurate cardinality and cost estimates can be orders of magnitude.},
	author = {Stillger, Michael and Lohman, Guy and Markl, Volker and Kandil, Mokhtar},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/MAFI9I4V/stillger-vldb2001.pdf:application/pdf},
}

@inproceedings{polychroniou_rethinking_2015,
	title = {Rethinking {SIMD} vectorization for in-memory databases},
	volume = {2015-May},
	isbn = {978-1-4503-2758-9},
	doi = {10.1145/2723372.2747645},
	abstract = {Analytical databases are continuously adapting to the underlying hardware in order to saturate all sources of parallelism. At the same time, hardware evolves in multiple directions to explore different trade-offs. The {MIC} architecture, one such example, strays from the mainstream {CPU} design by packing a larger number of simpler cores per chip, relying on {SIMD} instructions to fill the performance gap. Databases have been attempting to utilize the {SIMD} capabilities of {CPUs}. However, mainstream {CPUs} have only recently adopted wider {SIMD} registers and more advanced instructions, since they do not rely primarily on {SIMD} for efficiency. In this paper, we present novel vectorized designs and implementations of database operators, based on advanced {SIMD} operations, such as gathers and scatters. We study selections, hash tables, and partitioning; and combine them to build sorting and joins. Our evaluation on the {MIC}-based Xeon Phi co-processor as well as the latest mainstream {CPUs} shows that our vectorization designs are up to an order of magnitude faster than the state-of-the-art scalar and vector approaches. Also, we highlight the impact of efficient vectorization on the algorithmic design of in-memory database operators, as well as the architectural design and power efficiency of hardware, by making simple cores comparably fast to complex cores. This work is applicable to {CPUs} and co-processors with advanced {SIMD} capabilities, using either many simple cores or fewer complex cores.},
	pages = {1493--1508},
	booktitle = {Proceedings of the {ACM} {SIGMOD} International Conference on Management of Data},
	publisher = {Association for Computing Machinery},
	author = {Polychroniou, Orestis and Raghavan, Arun and Rossy, Kenneth A.},
	date = {2015-05-27},
	note = {{ISSN}: 07308078},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/TVGKMI9C/p1493-polychroniou.pdf:application/pdf},
}

@inproceedings{gupta_amazon_2015,
	title = {Amazon redshift and the case for simpler data warehouses},
	volume = {2015-May},
	isbn = {978-1-4503-2758-9},
	doi = {10.1145/2723372.2742795},
	abstract = {Amazon Redshift is a fast, fully managed, petabyte-scale data warehouse solution that makes it simple and cost-effective to efficiently analyze large volumes of data using existing business intelligence tools. Since launching in February 2013, it has been Amazon Web Service's ({AWS}) fastest growing service, with many thousands of customers and many petabytes of data under management. Amazon Redshift's pace of adoption has been a surprise to many participants in the data warehousing community. While Amazon Redshift was priced disruptively at launch, available for as little as \$1000/{TB}/year, there are many open-source data warehousing technologies and many commercial data warehousing engines that provide free editions for development or under some usage limit. While Amazon Redshift provides a modern {MPP}, columnar, scale-out architecture, so too do many other data warehousing engines. And, while Amazon Redshift is available in the {AWS} cloud, one can build data warehouses using {EC}2 instances and the database engine of one's choice with either local or networkattached storage. In this paper, we discuss an oft-overlooked differentiating characteristic of Amazon Redshift - simplicity. Our goal with Amazon Redshift was not to compete with other data warehousing engines, but to compete with non-consumption. We believe the vast majority of data is collected but not analyzed. We believe, while most database vendors target larger enterprises, there is little correlation in today's economy between data set size and company size. And, we believe the models used to procure and consume analytics technology need to support experimentation and evaluation. Amazon Redshift was designed to bring data warehousing to a mass market by making it easy to buy, easy to tune and easy to manage while also being fast and cost-effective.},
	pages = {1917--1923},
	booktitle = {Proceedings of the {ACM} {SIGMOD} International Conference on Management of Data},
	publisher = {Association for Computing Machinery},
	author = {Gupta, Anurag and Agarwal, Deepak and Tan, Derek and Kulesza, Jakub and Pathak, Rahul and Stefani, Stefano and Srinivasan, Vidhya},
	date = {2015-05-27},
	note = {{ISSN}: 07308078},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/I6PEQCVS/p1917-gupta.pdf:application/pdf},
}

@inproceedings{shaikhha_how_2016,
	title = {How to architect a query compiler},
	volume = {26-June-2016},
	isbn = {978-1-4503-3531-7},
	doi = {10.1145/2882903.2915244},
	abstract = {This paper studies architecting query compilers. The state of the art in query compiler construction is lagging behind that in the compilers field. We attempt to remedy this by exploring the key causes of technical challenges in need of well founded solutions, and by gathering the most relevant ideas and approaches from the {PL} and compilers communities for easy digestion by database researchers. All query compilers known to us are more or less monolithic template expanders that do the bulk of the compilation task in one large leap. Such systems are hard to build and maintain. We propose to use a stack of multiple {DSLs} on different levels of abstraction with lowering in multiple steps to make query compilers easier to build and extend, ultimately allowing us to create more convincing and sustainable compiler-based data management systems. We attempt to derive our advice for creating such {DSL} stacks from widely acceptable principles. We have also re-created a well-known query compiler following these ideas and report on this effort.},
	pages = {1907--1922},
	booktitle = {Proceedings of the {ACM} {SIGMOD} International Conference on Management of Data},
	publisher = {Association for Computing Machinery},
	author = {Shaikhha, Amir and Klonatos, Yannis and Parreaux, Lionel and Brown, Lewis and Dashti, Mohammad and Koch, Christoph},
	date = {2016-06-26},
	note = {{ISSN}: 07308078},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/EPHHFNGL/shaikhha-sigmod2016.pdf:application/pdf},
}

@inproceedings{gupta_procedural_2021,
	title = {Procedural extensions of sql: Understanding their usage in the wild},
	volume = {14},
	doi = {10.14778/3457390.3457402},
	abstract = {Procedural extensions of {SQL} have been in existence for many decades now. However, little is known about their magnitude of usage and their complexity in real-world workloads. Procedural code executing in a {RDBMS} is known to have inefficiencies and limitations; as a result there have been several efforts to address this problem. However, the lack of understanding of their use in real workloads makes it challenging to (a) motivate new work in this area, (b) identify research challenges and opportunities, and (c) demonstrate impact of novel work. We aim to address these challenges with our work. In this paper, we present the results of our in-depth analysis of thousands of stored procedures, user-defined functions and triggers taken from several real workloads. We introduce {SQL}-{ProcBench}, a benchmark for procedural workloads in {RDBMSs}. {SQL}-{ProcBench} has been created using the insights derived from our analysis, and thus represents real workloads. Using {SQL}-{ProcBench}, we present an experimental evaluation on several database engines to understand and identify research challenges and opportunities. We emphasize the need to work on these interesting and relevant problems, and encourage researchers to contribute to this area.},
	pages = {1378--1391},
	booktitle = {Proceedings of the {VLDB} Endowment},
	publisher = {{VLDB} Endowment},
	author = {Gupta, Surabhi and Ramachandra, Karthik},
	date = {2021},
	note = {Issue: 8
{ISSN}: 21508097},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/2I82XEP9/p1378-ramachandra.pdf:application/pdf},
}

@article{melnik_dremel_2020,
	title = {Dremel: A Decade of Interactive {SQL} Analysis at Web Scale},
	volume = {13},
	issn = {21508097},
	doi = {10.14778/3415478.3415568},
	abstract = {Google’s Dremel was one of the first systems that combined a set of architectural principles that have become a common practice in to-day’s cloud-native analytics tools, including disaggregated storage and compute, in situ analysis, and columnar storage for semistruc-tured data. In this paper, we discuss how these ideas evolved in the past decade and became the foundation for Google {BigQuery}.},
	pages = {3461--3472},
	number = {12},
	journaltitle = {Proceedings of the {VLDB} Endowment},
	author = {Melnik, Sergey and Gubarev, Andrey and Long, Jing Jing and Romer, Geoffrey and Shivakumar, Shiva and Tolton, Matt and Ahmadi, Hossein and Delorey, Dan and Min, Slava and Pasumansky, Mosha and Shute, Jeff},
	date = {2020},
	note = {Publisher: {VLDB} Endowment},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/8RU52SHH/p3461-melnik.pdf:application/pdf},
}

@inproceedings{marcus_neo_2018,
	title = {Neo: A Learned query optimizer},
	volume = {12},
	doi = {10.14778/3342263.3342644},
	abstract = {Query optimization is one of the most challenging problems in database systems. Despite the progress made over the past decades, query optimizers remain extremely complex components that require a great deal of hand-tuning for specific workloads and datasets. Motivated by this shortcoming and inspired by recent advances in applying machine learning to data management challenges, we introduce Neo (Neural Optimizer), a novel learning-based query optimizer that relies on deep neural networks to generate query executions plans. Neo bootstraps its query optimization model from existing optimizers and continues to learn from incoming queries, building upon its successes and learning from its failures. Furthermore, Neo naturally adapts to underlying data patterns and is robust to estimation errors. Experimental results demonstrate that Neo, even when bootstrapped from a simple optimizer like {PostgreSQL}, can learn a model that offers similar performance to state-of-the-art commercial optimizers, and in some cases even surpass them.},
	pages = {1705--1718},
	booktitle = {Proceedings of the {VLDB} Endowment},
	publisher = {{VLDB} Endowment},
	author = {Marcus, Ryan and Negi, Parimarjan and Mao, Hongzi and Zhang, Chi and Alizadeh, Mohammad and Kraska, Tim and Papaemmanouil, Olga and Tatbul, Nesime},
	date = {2018},
	eprinttype = {arxiv},
	eprint = {1904.03711},
	note = {Issue: 11
{ISSN}: 21508097},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/GPMCZXM7/p1705-marcus.pdf:application/pdf},
}

@book{noauthor_2013_2013,
	title = {2013 {IEEE} International Conference on Data Engineering ({ICDE} 2013},
	isbn = {978-1-4673-4910-9},
	publisher = {{IEEE}},
	date = {2013},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/S3K7IPNW/shrinivas-icde2013.pdf:application/pdf},
}

@inproceedings{wang_connectorx_2022,
	title = {{ConnectorX}: Accelerating Data Loading From Databases to Dataframes},
	volume = {15},
	doi = {10.14778/3551793.3551847},
	abstract = {Data is often stored in a database management system ({DBMS}) but dataframe libraries are widely used among data scientists. An important but challenging problem is how to bridge the gap between databases and dataframes. To solve this problem, we present {ConnectorX}, a client library that enables fast and memory-efficient data loading from various databases to different dataframes . We first investigate why the loading process is slow and consumes large memory. We surprisingly find that the main overhead comes from the client-side rather than query execution or data transfer. We integrate several existing and new techniques to reduce the overhead and carefully design the system architecture and interface to make {ConnectorX} easy to extend to various databases and dataframes. Moreover, we propose server-side result partitioning that can be adopted by {DBMSs} in order to better support exporting data to data science tools. We conduct extensive experiments to evaluate {ConnectorX} and compare it with popular libraries. The results show that {ConnectorX} significantly outperforms existing solutions. {ConnectorX} is open sourced at: https://github.com/sfu-db/connector-x.},
	pages = {2994--3003},
	booktitle = {Proceedings of the {VLDB} Endowment},
	publisher = {{VLDB} Endowment},
	author = {Wang, Xiaoying and Wu, Weiyuan and Wu, Jinze and Chen, Yizhou and Zrymiak, Nick and Qu, Changbo and Flokas, Lampros and Chow, George and Wang, Jiannan and Wang, Tianzheng and Wu, Eugene and Zhou, Qingqing},
	date = {2022},
	note = {Issue: 11
{ISSN}: 21508097},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/A5HJP2GF/p2994-wang.pdf:application/pdf},
}

@inproceedings{armenatzoglou_amazon_2022,
	title = {Amazon Redshift Re-invented},
	isbn = {978-1-4503-9249-5},
	doi = {10.1145/3514221.3526045},
	abstract = {In 2013, {AmazonWeb} Services revolutionized the data warehousing industry by launching Amazon Redshift, the first fully-managed, petabyte-scale, enterprise-grade cloud data warehouse. Amazon Redshift made it simple and cost-effective to efficiently analyze large volumes of data using existing business intelligence tools. This cloud service was a significant leap from the traditional on-premise data warehousing solutions, which were expensive, not elastic, and required significant expertise to tune and operate. Customers embraced Amazon Redshift and it became the fastest growing service in {AWS}. Today, tens of thousands of customers use Redshift in {AWS}'s global infrastructure to process exabytes of data daily. In the last few years, the use cases for Amazon Redshift have evolved and in response, the service has delivered and continues to deliver a series of innovations that delight customers. Through architectural enhancements, Amazon Redshift has maintained its industry-leading performance. Redshift improved storage and compute scalability with innovations such as tiered storage, multicluster auto-scaling, cross-cluster data sharing and the {AQUA} query acceleration layer. Autonomics have made Amazon Redshift easier to use. Amazon Redshift Serverless is the culmination of autonomics effort, which allows customers to run and scale analytics without the need to set up and manage data warehouse infrastructure. Finally, Amazon Redshift extends beyond traditional data warehousing workloads, by integrating with the broad {AWS} ecosystem with features such as querying the data lake with Spectrum, semistructured data ingestion and querying with {PartiQL}, streaming ingestion from Kinesis and {MSK}, Redshift {ML}, federated queries to Aurora and {RDS} operational databases, and federated materialized views.},
	pages = {2205--2217},
	booktitle = {Proceedings of the {ACM} {SIGMOD} International Conference on Management of Data},
	publisher = {Association for Computing Machinery},
	author = {Armenatzoglou, Nikos and Basu, Sanuj and Bhanoori, Naga and Cai, Mengchu and Chainani, Naresh and Chinta, Kiran and Govindaraju, Venkatraman and Green, Todd J. and Gupta, Monish and Hillig, Sebastian and Hotinger, Eric and Leshinksy, Yan and Liang, Jintian and {McCreedy}, Michael and Nagel, Fabian and Pandis, Ippokratis and Parchas, Panos and Pathak, Rahul and Polychroniou, Orestis and Rahman, Foyzur and Saxena, Gaurav and Soundararajan, Gokul and Subramanian, Sriram and Terry, Doug},
	date = {2022-06-10},
	note = {{ISSN}: 07308078},
	keywords = {analytics, autonomics, cloud data warehouse, data lake, elasticity, integration, {OLAP}, redshift, serverless},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/HBW93UPU/redshift-sigmod2022.pdf:application/pdf},
}

@inproceedings{liu_deep_2023,
	title = {A Deep Dive into Common Open Formats for Analytical {DBMSs}},
	volume = {16},
	doi = {10.14778/3611479.3611507},
	abstract = {This paper evaluates the suitability of Apache Arrow, Parquet, and {ORC} as formats for subsumption in an analytical {DBMS}. We systematically identify and explore the high-level features that are important to support efficient querying in modern {OLAP} {DBMSs} and evaluate the ability of each format to support these features. We find that each format has trade-offs that make it more or less suitable for use as a format in a {DBMS} and identify opportunities to more holistically co-design a unified in-memory and on-disk data representation. Our hope is that this study can be used as a guide for system developers designing and using these formats, as well as provide the community with directions to pursue for improving these common open formats.},
	pages = {3044--3056},
	booktitle = {Proceedings of the {VLDB} Endowment},
	publisher = {{VLDB} Endowment},
	author = {Liu, Chunwei and Pavlenko, Anna and Interlandi, Matteo and Haynes, Brandon},
	date = {2023},
	note = {Issue: 11
{ISSN}: 21508097},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/CVFJ2EYW/p3044-liu.pdf:application/pdf},
}

@inproceedings{behm_photon_2022,
	title = {Photon: A Fast Query Engine for Lakehouse Systems},
	isbn = {978-1-4503-9249-5},
	doi = {10.1145/3514221.3526054},
	abstract = {Many organizations are shifting to a data management paradigm called the "Lakehouse,"which implements the functionality of structured data warehouses on top of unstructured data lakes. This presents new challenges for query execution engines. The engine needs to provide good performance on the raw uncurated datasets that are ubiquitous in data lakes, and excellent performance on structured data stored in popular columnar file formats like Apache Parquet. Toward these goals, we present Photon, a vectorized query engine for Lakehouse environments that we developed at Databricks. Photon can outperform existing warehouses on {SQL} workloads and also supports the Apache Spark {API}. We discuss the design choices we made in Photon (e.g., vectorization vs. code generation) and describe its integration with our existing {SQL} and Apache Spark runtimes, its task model, and its memory manager. Photon has accelerated some customer workloads by over 10x and has recently allowed Databricks to set a new audited performance record for the official 100TB {TPC}-{DS} benchmark.},
	pages = {2326--2339},
	booktitle = {Proceedings of the {ACM} {SIGMOD} International Conference on Management of Data},
	publisher = {Association for Computing Machinery},
	author = {Behm, Alexander and Palkar, Shoumik and Agarwal, Utkarsh and Armstrong, Timothy and Cashman, David and Dave, Ankur and Greenstein, Todd and Hovsepian, Shant and Johnson, Ryan and Sai Krishnan, Arvind and Leventis, Paul and Luszczak, Ala and Menon, Prashanth and Mokhtar, Mostafa and Pang, Gene and Paranjpye, Sameer and Rahn, Greg and Samwel, Bart and Van Bussel, Tom and Van Hovell, Herman and Xue, Maryann and Xin, Reynold and Zaharia, Matei},
	date = {2022-06-10},
	note = {{ISSN}: 07308078},
	keywords = {main memory engines, query processing, vectorization},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/YRYBQPQF/sigmod_photon.pdf:application/pdf},
}

@inproceedings{winter_-demand_2022,
	title = {On-Demand State Separation for Cloud Data Warehousing},
	volume = {15},
	doi = {10.14778/3551793.3551845},
	abstract = {Moving data analysis and processing to the cloud is no longer reserved for a few companies with petabytes of data. Instead, the flexibility of on-demand resources is attracting an increasing number of customers with small to medium-sized workloads. These workloads do not occupy entire clusters but can run on single worker machines. However, picking the right worker for the job is challenging. Abstracting from worker machines, e.g., using stateless architectures, introduces overheads impacting performance. Solutions without stateless architectures resort to query restarts in the event of an adverse worker matching, wasting already achieved progress. In this paper, we propose migrating queries between workers by introducing on-demand state separation. Using state separation only when required enables maximum flexibility and performance while keeping already achieved progress. To derive the requirements for state separation, we first analyze the query state of medium-sized workloads on the example of {TPC}-{DS} {SF}100. Using this, we analyze the cost and describe the constraints necessary for state separation on such a workload. Furthermore, we describe the design and implementation of on-demand state separation in a compiling database system. Finally, using this implementation, we show the feasibility of our approach on {TPC}-{DS} and give a detailed analysis of the cost of query migration and state separation.},
	pages = {2966--2979},
	booktitle = {Proceedings of the {VLDB} Endowment},
	publisher = {{VLDB} Endowment},
	author = {Winter, Christian and Giceva, Jana and Neumann, Thomas and Kemper, Alfons},
	date = {2022},
	note = {Issue: 11
{ISSN}: 21508097},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/2Z692XLK/p2966-winter.pdf:application/pdf},
}

@inproceedings{butrovich_tigger_2023,
	title = {Tigger: A Database Proxy That Bounces With User-Bypass},
	volume = {16},
	doi = {10.14778/3611479.3611530},
	abstract = {Developers often deploy database-specific network proxies whereby applications connect transparently to the proxy instead of directly connecting to the database management system ({DBMS}). This indirection improves system performance through connection pooling, load balancing, and other {DBMS}-specific optimizations. Instead of simply forwarding packets, these proxies implement {DBMS} protocol logic (i.e., at the application layer) to achieve this behavior. Consequently, existing proxies are user-space applications that process requests as they arrive on network sockets and forward them to the appropriate destinations. This approach incurs inefficiencies as the kernel repeatedly copies buffers between user-space and kernel-space, and the associated system calls add {CPU} overhead. This paper presents user-bypass, a technique to eliminate these overheads by leveraging modern operating system features that support custom code execution. User-bypass pushes application logic into kernel-space via Linux’s {eBPF} infrastructure. To demonstrate its benefits, we implemented Tigger, a {PostgreSQL}-compatible {DBMS} proxy using user-bypass to eliminate the overheads of traditional proxy design. We compare Tigger’s performance against other state-of-the-art proxies widely used in real-world deployments. Our experiments show that Tigger outperforms other proxies — in one scenario achieving both the lowest transaction latencies (up to 29\% reduction) and lowest {CPU} utilization (up to 42\% reduction). The results show that user-bypass implementations like Tigger are well-suited to {DBMS} proxies’ unique requirements.},
	pages = {3335--3348},
	booktitle = {Proceedings of the {VLDB} Endowment},
	publisher = {{VLDB} Endowment},
	author = {Butrovich, Matthew and Ramanathan, Karthik and Rollinson, John and Lim, Wan Shen and Zhang, William and Sherry, Justine and Pavlo, Andrew},
	date = {2023},
	note = {Issue: 11
{ISSN}: 21508097},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/DRRTRLTE/p3335-butrovich.pdf:application/pdf},
}

@inproceedings{wagner_self-tuning_2021,
	title = {Self-Tuning Query Scheduling for Analytical Workloads},
	doi = {10.1145/3448016.3457260},
	abstract = {Most database systems delegate scheduling decisions to the operating system. While such an approach simplifies the overall database design, it also entails problems. Adaptive resource allocation becomes hard in the face of concurrent queries. Furthermore, incorporating domain knowledge to improve query scheduling is difficult. To mitigate these problems, many modern systems employ forms of task-based parallelism. The execution of a single query is broken up into small, independent chunks of work (tasks). Now, fine-grained scheduling decisions based on these tasks are the responsibility of the database system. Despite being commonplace, little work has focused on the opportunities arising from this execution model. In this paper, we show how task-based scheduling in database systems opens up new areas for optimization. We present a novel lock-free, self-tuning stride scheduler that optimizes query latencies for analytical workloads. By adaptively managing query priorities and task granularity, we provide high scheduling elasticity. By incorporating domain knowledge into the scheduling decisions, our system is able to cope with workloads that other systems struggle with. Even at high load, we retain near optimal latencies for short running queries. Compared to traditional database systems, our design often improves tail latencies by more than 10x.},
	pages = {1879--1891},
	booktitle = {Proceedings of the {ACM} {SIGMOD} International Conference on Management of Data},
	publisher = {Association for Computing Machinery},
	author = {Wagner, Benjamin and Kohn, André and Neumann, Thomas},
	date = {2021},
	note = {{ISSN}: 07308078},
	keywords = {database systems, parallelism, query scheduling, self-tuning},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/KCVXQQ9K/wagner-sigmod21.pdf:application/pdf},
}

@book{noauthor_proceedings_2019,
	title = {Proceedings of the 17th {USENIX} Symposium on Networked Systems Design and Implementation ({NSDI} '20) : Santa Clara, {CA}, {USA}, February 25 - 27, 2020},
	isbn = {978-1-939133-13-7},
	publisher = {{USENIX} Association},
	date = {2019},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/BKYUHC7F/vuppalapati-nsdi22.pdf:application/pdf},
}

@report{sethi_presto_nodate,
	title = {Presto: {SQL} on Everything},
	url = {https://aws.amazon.com/athena},
	abstract = {Presto is an open source distributed query engine that supports much of the {SQL} analytics workload at Facebook. Presto is designed to be adaptive, flexible, and extensible. It supports a wide variety of use cases with diverse characteristics. These range from user-facing reporting applications with sub-second latency requirements to multi-hour {ETL} jobs that aggregate or join terabytes of data. Presto's Connector {API} allows plugins to provide a high performance I/O interface to dozens of data sources, including Hadoop data warehouses, {RDBMSs}, {NoSQL} systems, and stream processing systems. In this paper, we outline a selection of use cases that Presto supports at Facebook. We then describe its architecture and implementation, and call out features and performance optimizations that enable it to support these use cases. Finally, we present performance results that demonstrate the impact of our main design decisions.},
	author = {Sethi, Raghav and Traverso, Martin and Sundstrom, Dain and Phillips, David and Xie, Wenlei and Sun, Yutian and Yigitbasi, Nezih and Jin, Haozhun and Hwang, Eric and Shingte, Nileema and Berner, Christopher},
	keywords = {big data, data warehouse, Index Terms-{SQL}, query engine},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/NNMFM35F/240861303_1946229012222045_8738935750973889667_n.pdf:application/pdf},
}

@report{twigg_stratified_nodate,
	title = {Stratified B-trees and versioning dictionaries},
	abstract = {External-memory versioned dictionaries are fundamental to file systems, databases and many other algorithms. The ubiquitous data structure is the copy-on-write ({CoW}) B-tree. Unfortunately, it doesn't inherit the B-tree's optimality properties; it has poor space utilization , cannot offer fast updates, and relies on random {IO} to scale. We describe the 'stratified B-tree', which is the first versioned dictionary offering fast updates and an optimal tradeoff between space, query and update costs.},
	author = {Twigg, Andy and Byde, Andrew and Miło, Grzegorz and Moreton, Tim and Wilkes, John and Wilkie, Tom},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/C2CATWAS/2011-hotstorage.pdf:application/pdf},
}

@report{kuszmaul_comparison_2014,
	title = {A Comparison of Fractal Trees to Log-Structured Merge ({LSM}) Trees},
	author = {Kuszmaul, Bradley C},
	date = {2014},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/BD8565ZY/lsm-vs-fractal.pdf:application/pdf},
}

@report{drepper_what_2007,
	title = {What Every Programmer Should Know About Memory},
	abstract = {As {CPU} cores become both faster and more numerous, the limiting factor for most programs is now, and will be for some time, memory access. Hardware designers have come up with ever more sophisticated memory handling and acceleration techniques-such as {CPU} caches-but these cannot work optimally without some help from the programmer. Unfortunately, neither the structure nor the cost of using the memory subsystem of a computer or the caches on {CPUs} is well understood by most programmers. This paper explains the structure of memory subsystems in use on modern commodity hardware, illustrating why {CPU} caches were developed, how they work, and what programs should do to achieve optimal performance by utilizing them.},
	author = {Drepper, Ulrich},
	date = {2007},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/6SWRITY9/cpumemory.pdf:application/pdf},
}

@article{mishra_survey_2024,
	title = {A survey of {LSM}-Tree based Indexes, Data Systems and {KV}-stores},
	url = {http://arxiv.org/abs/2402.10460},
	abstract = {Modern databases typically makes use of the Log Structured Merge-Tree for organizing data in indexes, which is a kind of disk-based data structure. It was proposed to efficiently handle frequent update queries (also called update intensive workloads) databases. In recent years, {LSM}-Tree has gained popularity and has been adopted by a number of {NoSql} databases, and key-value stores. Since {LSM}-Tree was first proposed, researchers and the database community started efforts to improve different components of {LSM}-Tree. In recent years, Non-volatile Memory, also called Persistent Memory, has also gained significant popularity. This is a class of memory that is non-volatile and byte-addressable at the same time, and hence also termed Storage Class Memory. Apart from that, storage class memory exhibits the combination of the best characteristics of both memory and storage. An overview of the current state of the art in {LSM}-Tree-based indexes, data systems, and Key-Value stores is provided in this paper.},
	author = {Mishra, Supriya},
	date = {2024-02-16},
	eprinttype = {arxiv},
	eprint = {2402.10460},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/QMMI8RAR/2402.10460v2.pdf:application/pdf},
}

@book{noauthor_proceedings_2016,
	title = {Proceedings of the 14th {USENIX} Conference on File and Storage Technologies : February 22 - 25, 2016, Santa Clara, California},
	isbn = {978-1-931971-28-7},
	publisher = {{USENIX} Association},
	date = {2016},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/XAM6UXZX/fast16-papers-lu.pdf:application/pdf},
}

@report{li_secure_nodate,
	title = {Secure Untrusted Data Repository ({SUNDR})},
	abstract = {{SUNDR} is a network file system designed to store data securely on untrusted servers. {SUNDR} lets clients detect any attempts at unauthorized file modification by malicious server operators or users. {SUNDR}'s protocol achieves a property called fork consistency, which guarantees that clients can detect any integrity or consistency failures as long as they see each other's file modifications. An implementation is described that performs comparably with {NFS} (sometimes better and sometimes worse), while offering significantly stronger security.},
	author = {Li, Jinyuan and Krohn, Maxwell and Mazì, David and Shasha, Dennis},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/9SBLPT4N/li-sundr.pdf:application/pdf},
}

@book{elhemali_amazon_nodate,
	title = {Amazon {DynamoDB}: A Scalable, Predictably Performant, and Fully Managed {NoSQL} Database Service},
	isbn = {978-1-939133-29-8},
	url = {https://www.usenix.org/conference/atc22/presentation/vig},
	abstract = {Amazon {DynamoDB} is a {NoSQL} cloud database service that provides consistent performance at any scale. Hundreds of thousands of customers rely on {DynamoDB} for its fundamental properties: consistent performance, availability, durability, and a fully managed serverless experience. In 2021, during the 66-hour Amazon Prime Day shopping event, Amazon systems-including Alexa, the Amazon.com sites, and Amazon fulfillment centers, made trillions of {API} calls to {DynamoDB}, peak-ing at 89.2 million requests per second, while experiencing high availability with single-digit millisecond performance. Since the launch of {DynamoDB} in 2012, its design and implementation have evolved in response to our experiences operating it. The system has successfully dealt with issues related to fairness, traffic imbalance across partitions, monitoring , and automated system operations without impacting availability or performance. Reliability is essential, as even the slightest disruption can significantly impact customers. This paper presents our experience operating {DynamoDB} at a massive scale and how the architecture continues to evolve to meet the ever-increasing demands of customer workloads.},
	author = {Elhemali, Mostafa and Gallagher, Niall and Gordon, Nicholas and Idziorek, Joseph and Krog, Richard and Lazier, Colin and Mo, Erben and Mritunjai, Akhilesh and Perianayagam, Somu and Rath, Tim and Sivasubramanian, Swami and Sorenson, James Christopher and Sosothikul, Sroaj and Terry, Doug and Vig, Akshat},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/C4S572R6/atc22-dynamodb.pdf:application/pdf},
}

@book{brooker_-demand_nodate,
	title = {On-demand Container Loading in {AWS} Lambda},
	isbn = {978-1-939133-35-9},
	url = {https://www.usenix.org/conference/atc23/presentation/brooker},
	abstract = {{AWS} Lambda is a serverless event-driven compute service, part of a category of cloud compute offerings sometimes called Function-as-a-service ({FaaS}). When we first released {AWS} Lambda, functions were limited to 250MB of code and dependencies, packaged as a simple compressed archive. In 2020, we released support for deploying container images as large as 10GiB as Lambda functions, allowing customers to bring much larger code bases and sets of dependencies to Lambda. Supporting larger packages, while still meeting Lambda's goals of rapid scale (adding up to 15,000 new containers per second for a single customer, and much more in aggregate), high request rate (millions of requests per second), high scale (millions of unique workloads), and low start-up times (as low as 50ms) presented a significant challenge. We describe the storage and caching system we built, optimized for delivering container images on-demand, and our experiences designing, building, and operating it at scale. We focus on challenges around security, efficiency, latency, and cost, and how we addressed these challenges in a system that combines caching, deduplication, convergent encryption, erasure coding, and block-level demand loading. Since building this system, it has reliably processed hundreds of trillions of Lambda invocations for over a million {AWS} customers, and has shown excellent resilience to load and infrastructure failures.},
	author = {Brooker, Marc and Danilov, Mike and Greenwood, Chris and Piwonka, Phil},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/6V2HXKGD/atc23-brooker.pdf:application/pdf},
}

@inproceedings{jia_boki_2021,
	title = {Boki: Stateful Serverless Computing with Shared Logs},
	isbn = {978-1-4503-8709-5},
	doi = {10.1145/3477132.3483541},
	abstract = {Boki is a new serverless runtime that exports a shared log {API} to serverless functions. Boki shared logs enable stateful serverless applications to manage their state with durability, consistency, and fault tolerance. Boki shared logs achieve high throughput and low latency. The key enabler is the metalog, a novel mechanism that allows Boki to address ordering, consistency and fault tolerance independently. The metalog orders shared log records with high throughput and it provides read consistency while allowing service providers to optimize the write and read path of the shared log in different ways. To demonstrate the value of shared logs for stateful serverless applications, we build Boki support libraries that implement fault-tolerant workflows, durable object storage, and message queues. Our evaluation shows that shared logs can speed up important serverless workloads by up to 4.7x.},
	pages = {691--707},
	booktitle = {{SOSP} 2021 - Proceedings of the 28th {ACM} Symposium on Operating Systems Principles},
	publisher = {Association for Computing Machinery, Inc},
	author = {Jia, Zhipeng and Witchel, Emmett},
	date = {2021-10-26},
	keywords = {consistency, function-as-a-service, Serverless computing, shared log},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/WEPDNMKS/jia21sosp-boki.pdf:application/pdf},
}

@report{castro_practical_1999,
	title = {Practical Byzantine Fault Tolerance},
	abstract = {This paper describes a new replication algorithm that is able to tolerate Byzantine faults. We believe that Byzantine-fault-tolerant algorithms will be increasingly important in the future because malicious attacks and software errors are increasingly common and can cause faulty nodes to exhibit arbitrary behavior. Whereas previous algorithms assumed a synchronous system or were too slow to be used in practice, the algorithm described in this paper is practical: it works in asynchronous environments like the Internet and incorporates several important optimizations that improve the response time of previous algorithms by more than an order of magnitude. We implemented a Byzantine-fault-tolerant {NFS} service using our algorithm and measured its performance. The results show that our service is only 3\% slower than a standard unreplicated {NFS}.},
	author = {Castro, Miguel and Liskov, Barbara},
	date = {1999},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/DSEEUEE7/castro-practicalbft.pdf:application/pdf},
}

@book{xie_this_nodate,
	title = {This paper is included in the Proceedings of the 17th {USENIX} Symposium on Operating Systems Design and Implementation. Chardonnay: Fast and General Datacenter Transactions for On-Disk Databases Chardonnay: Fast and General Datacenter Transactions for On-Disk Databases},
	isbn = {978-1-939133-34-2},
	url = {https://www.usenix.org/conference/osdi23/presentation/eldeeb},
	abstract = {Distributed on-disk database systems could either use an expensive commit protocol like two-phase commit (2PC) to guarantee atomicity, and suffer from slow distributed transactions, or forgo 2PC, which lead to weaker semantics , limitations to the programming model, or constrained scalability, making the system less general. We argue this compromise is no longer necessary within modern datacenters. Low latency 2PC (∼150 µs on Azure for 2PC over Paxos) can be achieved using low-latency storage for the relatively small transaction logs, fast {RPCs}, and careful protocol design. With fast 2PC, the data contention bottleneck for many transactions shifts from 2PC to reading the data itself from the relatively slow storage while holding transaction locks. We present Chardonnay, a scalable, on-disk, multi-versioned transactional key-value store optimized for single datacenter deployments with fast 2PC. Chardon-nay has a general interface supporting point reads, scans, and writes within multi-step strictly serializable {ACID} transactions. The key mechanism underlying Chardon-nay's design is strongly consistent snapshot reads on commodity hardware, using a novel lock-free read protocol. Chardonnay uses this protocol to cheaply determine the read-write sets of queries, enabling Chardonnay to transparently prefetch data needed for a transaction prior to the execution of the transaction and the acquisition of locks. This enables Chardonnay to achieve fast transactions by minimizing contention, and avoids aborts due to deadlocks by ordering lock requests.},
	author = {Xie, Xincheng and Bernstein, Philip A and Eldeeb, Tamer and Yang, Junfeng},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/6JD6J7GE/osdi23-eldeeb.pdf:application/pdf},
}

@report{wang_ownership_nodate,
	title = {Ownership: A Distributed Futures System for Fine-Grained Tasks},
	abstract = {The distributed futures interface is an increasingly popular choice for building distributed applications that manipulate large amounts of data. Distributed futures are an extension of {RPC} that combines futures and distributed memory: a distributed future is a reference whose eventual value may be stored on a remote node. An application can then express distributed computation without having to specify when or where execution should occur and data should be moved. Recent distributed futures applications require the ability to execute fine-grained computations, i.e., tasks that run on the order of milliseconds. Compared to coarse-grained tasks, fine-grained tasks are difficult to execute with acceptable system overheads. In this paper, we present a distributed futures system for fine-grained tasks that provides fault tolerance without sacrificing performance. Our solution is based on a novel concept called ownership, which assigns each object a leader for system operations. We show that this decentralized architecture can achieve horizontal scaling, 1ms latency per task, and fast failure handling.},
	author = {Wang, Stephanie and Liang, Eric and Oakes, Edward and Hindman, Ben and Luan, Frank and Cheng, Audrey},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/2EP6PHHL/ray.pdf:application/pdf},
}

@inproceedings{dragojevic_no_2015,
	title = {No compromises: Distributed transactions with consistency, availability, and performance},
	isbn = {978-1-4503-3834-9},
	doi = {10.1145/2815400.2815425},
	abstract = {Transactions with strong consistency and high availability simplify building and reasoning about distributed systems. However, previous implementations performed poorly. This forced system designers to avoid transactions completely, to weaken consistency guarantees, or to provide singlemachine transactions that require programmers to partition their data. In this paper, we show that there is no need to compromise in modern data centers. We show that a main memory distributed computing platform called {FaRM} can provide distributed transactions with strict serializability, high performance, durability, and high availability. {FaRM} achieves a peak throughput of 140 million {TATP} transactions per second on 90 machines with a 4.9 {TB} database, and it recovers from a failure in less than 50 ms. Key to achieving these results was the design of new transaction, replication, and recovery protocols from first principles to leverage commodity networks with {RDMA} and a new, inexpensive approach to providing non-volatile {DRAM}.},
	pages = {54--70},
	booktitle = {{SOSP} 2015 - Proceedings of the 25th {ACM} Symposium on Operating Systems Principles},
	publisher = {Association for Computing Machinery, Inc},
	author = {Dragojević, Aleksandar and Narayanan, Dushyanth and Nightingale, Edmund B. and Renzelmann, Matthew and Shamis, Alex and Badam, Anirudh and Castro, Miguel},
	date = {2015-10-04},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/JN7YS6AQ/farm-2015.pdf:application/pdf},
}

@article{sharma_grove_2023,
	title = {Grove: a Separation-Logic Library for Verifying Distributed Systems (Extended Version)},
	url = {http://arxiv.org/abs/2309.03046},
	doi = {10.1145/3600006.3613172},
	abstract = {Grove is a concurrent separation logic library for verifying distributed systems. Grove is the first to handle time-based leases, including their interaction with reconfiguration, crash recovery, thread-level concurrency, and unreliable networks. This paper uses Grove to verify several distributed system components written in Go, including {GroveKV}, a realistic distributed multi-threaded key-value store. {GroveKV} supports reconfiguration, primary/backup replication, and crash recovery, and uses leases to execute read-only requests on any replica. {GroveKV} achieves high performance (67-73\% of Redis on a single core), scales with more cores and more backup replicas (achieving about 2x the throughput when going from 1 to 3 servers), and can safely execute reads while reconfiguring.},
	author = {Sharma, Upamanyu and Jung, Ralf and Tassarotti, Joseph and Kaashoek, M. Frans and Zeldovich, Nickolai},
	date = {2023-09-06},
	eprinttype = {arxiv},
	eprint = {2309.03046},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/N8ESUWDP/grove.pdf:application/pdf},
}

@report{meiklejohn_resilient_2024,
	title = {Resilient Microservice Applications, by Design, and without the Chaos},
	author = {Meiklejohn, Christopher S and Alvaro, Peter},
	date = {2024},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/QRWDUH73/cmeiklej_phd_s3d_2024.pdf:application/pdf},
}

@article{radford_learning_2021,
	title = {Learning Transferable Visual Models From Natural Language Supervision},
	url = {http://arxiv.org/abs/2103.00020},
	abstract = {State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form of supervision limits their generality and usability since additional labeled data is needed to specify any other visual concept. Learning directly from raw text about images is a promising alternative which leverages a much broader source of supervision. We demonstrate that the simple pre-training task of predicting which caption goes with which image is an efficient and scalable way to learn {SOTA} image representations from scratch on a dataset of 400 million (image, text) pairs collected from the internet. After pre-training, natural language is used to reference learned visual concepts (or describe new ones) enabling zero-shot transfer of the model to downstream tasks. We study the performance of this approach by benchmarking on over 30 different existing computer vision datasets, spanning tasks such as {OCR}, action recognition in videos, geo-localization, and many types of fine-grained object classification. The model transfers non-trivially to most tasks and is often competitive with a fully supervised baseline without the need for any dataset specific training. For instance, we match the accuracy of the original {ResNet}-50 on {ImageNet} zero-shot without needing to use any of the 1.28 million training examples it was trained on. We release our code and pre-trained model weights at https://github.com/{OpenAI}/{CLIP}.},
	author = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
	date = {2021-02-26},
	eprinttype = {arxiv},
	eprint = {2103.00020},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/BRARW9UI/2103.00020v1.pdf:application/pdf},
}

@report{malkov_efficient_nodate,
	title = {Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs},
	abstract = {We present a new approach for the approximate K-nearest neighbor search based on navigable small world graphs with controllable hierarchy (Hierarchical {NSW}, {HNSW}). The proposed solution is fully graph-based, without any need for additional search structures, which are typically used at the coarse search stage of the most proximity graph techniques. Hierarchical {NSW} incrementally builds a multi-layer structure consisting from hierarchical set of proximity graphs (layers) for nested subsets of the stored elements. The maximum layer in which an element is present is selected randomly with an exponentially decaying probability distribution. This allows producing graphs similar to the previously studied Navigable Small World ({NSW}) structures while additionally having the links separated by their characteristic distance scales. Starting search from the upper layer together with utilizing the scale separation boosts the performance compared to {NSW} and allows a logarithmic complexity scaling. Additional employment of a heuristic for selecting proximity graph neighbors significantly increases performance at high recall and in case of highly clustered data. Performance evaluation has demonstrated that the proposed general metric space search index is able to strongly outperform previous opensource state-of-the-art vector-only approaches. Similarity of the algorithm to the skip list structure allows straightforward balanced distributed implementation.},
	author = {Malkov, Yu A and Yashunin, D A},
	keywords = {Approximate search, Artificial Intelligence, Big data, Data Structures, Graphs and networks, Index Terms-Graph and tree search strategies, Information Search and Retrieval, Information Storage and Retrieval, Information Technology and Systems, Nearest neighbor search, Search process, Similarity search},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/CDTL72FP/1603.09320v4.pdf:application/pdf},
}

@article{graefe_modern_2010,
	title = {Modern B-tree techniques},
	volume = {3},
	issn = {19317883},
	doi = {10.1561/1900000028},
	abstract = {Invented about 40 years ago and called ubiquitous less than 10 years later, B-tree indexes have been used in a wide variety of computing systems from handheld devices to mainframes and server farms. Over the years, many techniques have been added to the basic design in order to improve efficiency or to add functionality. Examples include separation of updates to structure or contents, utility operations such as non-logged yet transactional index creation, and robust query processing such as graceful degradation during index-to-index navigation. This survey reviews the basics of B-trees and of B-tree indexes in databases, transactional techniques and query processing techniques related to B-trees, B-tree utilities essential for database operations, and many optimizations and improvements. It is intended both as a survey and as a reference, enabling researchers to compare index innovations with advanced B-tree techniques and enabling professionals to select features, functions, and tradeoffs most appropriate for their data management challenges. © 2011 G. Graefe.},
	pages = {203--402},
	number = {4},
	journaltitle = {Foundations and Trends in Databases},
	author = {Graefe, Goetz},
	date = {2010},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/F55BIX26/btreesurvey-graefe.pdf:application/pdf},
}

@report{oneil_log-structured_nodate,
	title = {The Log-Structured Merge-Tree ({LSM}-Tree)},
	abstract = {High-performance transaction system applications typically insert rows in a History table to provide an activity trace; at the same time the transaction system generates log records for purposes of system recovery. Both types of generated information can benefit from efficient indexing. An example in a well-known setting is the {TPC}-A benchmark application, modified to support efficient queries on the History for account activity for specific accounts. This requires an index by account-id on the fast-growing History table. Unfortunately, standard disk-based index structures such as the B-tree will effectively double the I/O cost of the transaction to maintain an index such as this in real time, increasing the total system cost up to fifty percent. Clearly a method for maintaining a real-time index at low cost is desirable. The Log-Structured Merge-tree ({LSM}-tree) is a disk-based data structure designed to provide low-cost indexing for a file experiencing a high rate of record inserts (and deletes) over an extended period. The {LSM}-tree uses an algorithm that defers and batches index changes, cascading the changes from a memory-based component through one or more disk components in an efficient manner reminiscent of merge sort. During this process all index values are continuously accessible to retrievals (aside from very short locking periods), either through the memory component or one of the disk components. The algorithm has greatly reduced disk arm movements compared to a traditional access methods such as B-trees, and will improve cost-performance in domains where disk arm costs for inserts with traditional access methods overwhelm storage media costs. The {LSM}-tree approach also generalizes to operations other than insert and delete. However, indexed finds requiring immediate response will lose I/O efficiency in some cases, so the {LSM}-tree is most useful in applications where index inserts are more common than finds that retrieve the entries. This seems to be a common property for History tables and log files, for example. The conclusions of Section 6 compare the hybrid use of memory and disk components in the {LSM}-tree access method with the commonly understood advantage of the hybrid method to buffer disk pages in memory.},
	author = {O'neil, Patrick and Cheng, Edward and Gawlick, Dieter and O'neil, Elizabeth},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/9MCVZS8Z/lsmtree.pdf:application/pdf},
}

@inproceedings{lee_waltz_2023,
	title = {{WALTZ}: Leveraging Zone Append to Tighten the Tail Latency of {LSM} Tree on {ZNS} {SSD}},
	volume = {16},
	doi = {10.14778/3611479.3611495},
	abstract = {We propose {WALTZ}, an {LSM} tree-based key-value store on the emerging Zoned Namespace ({ZNS}) {SSD}. The key contribution of {WALTZ} is to leverage the zone append command, which is a recent addition to {ZNS} {SSD} specifications, to provide tight tail latency. The long tail latency problem caused by the merging process of multiple parallel writes, called batch-group writes, is effectively addressed by the internal synchronization mechanism of {ZNS} {SSD}. To provide fast failover when the active zone becomes full for a write-ahead log ({WAL}) file during parallel append, {WALTZ} introduces a mechanism for {WAL} zone replacement and reservation. Finally, lazy metadata management allows a put query to be processed fast without requiring any other synchronizations to enable lock-free execution of individual append commands. For evaluation we use both mi-crobenchmarks (db\_bench) with varying read/write ratios and key skewnesses, and realistic social-graph workloads ({MixGraph} from Facebook). Our evaluation demonstrates geomean reduction of tail latency by 2.19× and 2.45× for db\_bench and {MixGraph}, respectively, with a maximum reduction of 3.02× and 4.73×. As a side effect of eliminating the overhead of batch-group writes, {WALTZ} also improves the query throughput ({QPS}) by up to 11.7\%.},
	pages = {2884--2896},
	booktitle = {Proceedings of the {VLDB} Endowment},
	publisher = {{VLDB} Endowment},
	author = {Lee, Jongsung and Kim, Donguk and Lee, Jae W.},
	date = {2023},
	note = {Issue: 11
{ISSN}: 21508097},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/ABAFA83P/p2884-lee.pdf:application/pdf},
}

@article{huang_splitzns_2023,
	title = {{SplitZNS}: Towards an Efficient {LSM}-Tree on Zoned Namespace {SSDs}},
	volume = {20},
	issn = {15443973},
	doi = {10.1145/3608476},
	abstract = {The Zoned Namespace ({ZNS}) Solid State Drive ({SSD}) is a nascent form of storage device that offers novel prospects for the Log Structured Merge Tree ({LSM}-tree). {ZNS} exposes erase blocks in {SSD} as append-only zones, enabling the {LSM}-tree to gain awareness of the physical layout of data. Nevertheless, {LSM}-tree on {ZNS} {SSDs} necessitates Garbage Collection ({GC}) owing to the mismatch between the gigantic zones and relatively small Sorted String Tables ({SSTables}). Through extensive experiments, we observe that a smaller zone size can reduce data migration in {GC} at the cost of a significant performance decline owing to inadequate parallelism exploitation. In this article, we present {SplitZNS}, which introduces small zones by tweaking the zone-to-chip mapping to maximize {GC} efficiency for {LSM}-tree on {ZNS} {SSDs}. Following the multi-level peculiarity of {LSM}-tree and the inherent parallel architecture of {ZNS} {SSDs}, we propose a number of techniques to leverage and accelerate small zones to alleviate the performance impact due to underutilized parallelism. (1) First, we use small zones selectively to prevent exacerbating write slowdowns and stalls due to their suboptimal performance. (2) Second, to enhance parallelism utilization, we propose {SubZone} Ring, which employs a per-chip {FIFO} buffer to imitate a large zone writing style; (3) Read Prefetcher, which prefetches data concurrently through multiple chips during compactions; (4) and Read Scheduler, which assigns query requests the highest priority. We build a prototype integrated with {SplitZNS} to validate its efficiency and efficacy. Experimental results demonstrate that {SplitZNS} achieves up to 2.77× performance and reduces data migration considerably compared to the lifetime-based data placement.1},
	number = {3},
	journaltitle = {{ACM} Transactions on Architecture and Code Optimization},
	author = {Huang, Dong and Feng, Dan and Liu, Qiankun and Ding, Bo and Zhao, Wei and Wei, Xueliang and Tong, Wei},
	date = {2023-08-07},
	note = {Publisher: Association for Computing Machinery},
	keywords = {{LSM}-tree, garbage collection, Zoned Namespace},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/366S8DUK/3608476.pdf:application/pdf},
}

@inproceedings{dang_noblsm_2022,
	title = {{NobLSM}: An {LSM}-tree with Non-blocking Writes for {SSDs}},
	isbn = {978-1-4503-9142-9},
	doi = {10.1145/3489517.3530470},
	abstract = {Solid-state drives ({SSDs}) are gaining popularity. Meanwhile, key-value stores built on log-structured merge-tree ({LSM}-tree) are widely deployed for data management. {LSM}-tree frequently calls syncs to persist newly-generated files for crash consistency. The blocking syncs are costly for performance. We revisit the necessity of syncs for {LSM}-tree. We find that Ext4 journaling embraces asynchronous commits to implicitly persist files. Hence, we design {NobLSM} that makes {LSM}-tree and Ext4 cooperate to substitute most syncs with non-blocking asynchronous commits, without losing consistency. Experiments show that {NobLSM} significantly outperforms state-of-the-art {LSM}-trees with higher throughput on an ordinary {SSD}.},
	pages = {403--408},
	booktitle = {Proceedings - Design Automation Conference},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Dang, Haoran and Ye, Chongnan and Hu, Yanpeng and Wang, Chundong},
	date = {2022-07-10},
	note = {{ISSN}: 0738100X},
	keywords = {{LSM}-tree, asynchronous commit, fsync, key-value store},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/DWLGSPG4/3489517.3530470.pdf:application/pdf},
}

@article{li_efficient_2022,
	title = {Efficient {LSM}-Tree Key-Value Data Management on Hybrid {SSD}/{HDD} Zoned Storage},
	url = {http://arxiv.org/abs/2205.11753},
	abstract = {Zoned storage devices, such as zoned namespace ({ZNS}) solid-state drives ({SSDs}) and host-managed shingled magnetic recording ({HM}-{SMR}) hard-disk drives ({HDDs}), expose interfaces for host-level applications to support fine-grained, high-performance storage management. Combining {ZNS} {SSDs} and {HM}-{SMR} {HDDs} into a unified hybrid storage system is a natural direction to scale zoned storage at low cost, yet how to effectively incorporate zoned storage awareness into hybrid storage is a non-trivial issue. We make a case for key-value ({KV}) stores based on log-structured merge trees ({LSM}-trees) as host-level applications, and present {HHZS}, a middleware system that bridges an {LSM}-tree {KV} store with hybrid zoned storage devices based on hints. {HHZS} leverages hints issued by the flushing, compaction, and caching operations of the {LSM}-tree {KV} store to manage {KV} objects in placement, migration, and caching in hybrid {ZNS} {SSD} and {HM}-{SMR} {HDD} zoned storage. Experiments show that our {HHZS} prototype, when running on real {ZNS} {SSD} and {HM}-{SMR} {HDD} devices, achieves the highest throughput compared with all baselines under various settings.},
	author = {Li, Jinhong and Wang, Qiuping and Lee, Patrick P. C.},
	date = {2022-05-23},
	eprinttype = {arxiv},
	eprint = {2205.11753},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/54ARAASQ/2205.11753v1.pdf:application/pdf},
}

@article{didona_toward_2020,
	title = {Toward a Better Understanding and Evaluation of Tree Structures on Flash {SSDs}},
	url = {http://arxiv.org/abs/2006.04658},
	abstract = {Solid-state drives ({SSDs}) are extensively used to deploy persistent data stores, as they provide low latency random access, high write throughput, high data density, and low cost. Tree-based data structures are widely used to build persistent data stores, and indeed they lie at the backbone of many of the data management systems used in production and research today. In this paper, we show that benchmarking a persistent tree-based data structure on an {SSD} is a complex process, which may easily incur subtle pitfalls that can lead to an inaccurate performance assessment. At a high-level, these pitfalls stem from the interaction of complex software running on complex hardware. On one hand, tree structures implement internal operations that have nontrivial effects on performance. On the other hand, {SSDs} employ firmware logic to deal with the idiosyncrasies of the underlying flash memory, which are well known to lead to complex performance dynamics. We identify seven benchmarking pitfalls using {RocksDB} and {WiredTiger}, two widespread implementations of an {LSM}-Tree and a B+Tree, respectively. We show that such pitfalls can lead to incorrect measurements of key performance indicators, hinder the reproducibility and the representativeness of the results, and lead to suboptimal deployments in production environments. We also provide guidelines on how to avoid these pitfalls to obtain more reliable performance measurements, and to perform more thorough and fair comparison among different design points.},
	author = {Didona, Diego and Ioannou, Nikolas and Stoica, Radu and Kourtis, Kornilios},
	date = {2020-06-08},
	eprinttype = {arxiv},
	eprint = {2006.04658},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/Q6DTKAPE/2006.04658v1.pdf:application/pdf},
}

@article{sun_co-kv_2018,
	title = {Co-{KV}: A Collaborative Key-Value Store Using Near-Data Processing to Improve Compaction for the {LSM}-tree},
	url = {http://arxiv.org/abs/1807.04151},
	abstract = {Log-structured merge tree ({LSM}-tree) based key-value stores are widely employed in large-scale storage systems. In the compaction of the key-value store, {SSTables} are merged with overlapping key ranges and sorted for data queries. This, however, incurs write amplification and thus degrades system performance, especially under update-intensive workloads. Current optimization focuses mostly on the reduction of the overload of compaction in the host, but rarely makes full use of computation in the device. To address these issues, we propose Co-{KV}, a Collaborative Key-Value store between the host and a near-data processing ( i.e., {NDP}) model based {SSD} to improve compaction. Co-{KV} offers three benefits: (1) reducing write amplification by a compaction offloading scheme between host and device; (2) relieving the overload of compaction in the host and leveraging computation in the {SSD} based on the {NDP} model; and (3) improving the performance of {LSM}-tree based key-value stores under update-intensive workloads. Extensive db\_bench experiment show that Co-{KV} largely achieves a 2.0x overall throughput improvement, and a write amplification reduction by up to 36.0\% over the state-of-the-art {LevelDB}. Under {YCSB} workloads, Co-{KV} increases the throughput by 1.7x - 2.4x while decreases the write amplification and average latency by up to 30.0\% and 43.0\%, respectively.},
	author = {Sun, Hui and Liu, Wei and Huang, Jianzhong and Shi, Weisong},
	date = {2018-07-11},
	eprinttype = {arxiv},
	eprint = {1807.04151},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/NUKNMRET/1807.04151v1.pdf:application/pdf},
}

@inproceedings{wang_efficient_2014,
	title = {An efficient design and implementation of {LSM}-tree based key-value store on open-channel {SSD}},
	isbn = {978-1-4503-2704-6},
	doi = {10.1145/2592798.2592804},
	abstract = {Various key-value ({KV}) stores are widely employed for data management to support Internet services as they offer higher efficiency, scalability, and availability than relational database systems. The log-structured merge tree ({LSM}-tree) based {KV} stores have attracted growing attention because they can eliminate random writes and maintain acceptable read performance. Recently, as the price per unit capacity of {NAND} flash decreases, solid state disks ({SSDs}) have been extensively adopted in enterprise-scale data centers to provide high I/O bandwidth and low access latency. However, it is inefficient to naively combine {LSM}-tree-based {KV} stores with {SSDs}, as the high parallelism enabled within the {SSD} cannot be fully exploited. Current {LSM}-tree-based {KV} stores are designed without assuming {SSD}'s multi-channel architecture. To address this inadequacy, we propose {LOCS}, a system equipped with a customized {SSD} design, which exposes its internal flash channels to applications, to work with the {LSM}-tree-based {KV} store, specifically {LevelDB} in this work. We extend {LevelDB} to explicitly leverage the multiple channels of an {SSD} to exploit its abundant parallelism. In. Copyright © 2007 by the Association for Computing Machinery, Inc.},
	booktitle = {Proceedings of the 9th European Conference on Computer Systems, {EuroSys} 2014},
	publisher = {Association for Computing Machinery},
	author = {Wang, Peng and Sun, Guangyu and Jiang, Song and Ouyang, Jian and Lin, Shiding and Zhang, Chen and Cong, Jason},
	date = {2014},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/TJP6PGEY/eurosys2014_final44.pdf:application/pdf},
}

@inproceedings{mei_lsm-tree_2017,
	title = {{LSM}-tree managed storage for large-scale key-value store},
	isbn = {978-1-4503-5028-0},
	doi = {10.1145/3127479.3127486},
	abstract = {Key-value stores are increasingly adopting {LSM}-trees as their enabling data structure in the backend storage, and persisting their clustered data through a file system. A file system is expected to not only provide file/directory abstraction to organize data but also retain the key benefits of {LSMtrees}, namely, sequential and aggregated I/O patterns on the physical device. Unfortunately, our in-depth experimental analysis reveals that some of these benefits of {LSM}-trees can be completely negated by the underlying file level indexes from the perspectives of both data layout and I/O processing. As a result, the write performance of {LSM}-trees is kept at a level far below that promised by the sequential bandwidth offered by the storage devices. In this paper, we address this problem and propose {LDS}, an {LSM}-tree based Direct Storage system that manages the storage space and provides simplified consistency control by exploiting the copy-on-write nature of the {LSM}-tree structure, so as to fully reap the benefits of {LSM}-trees. Running {LSM}-trees on {LDS} as a baseline for comparison, we evaluate {LSM}-trees on three representative file systems ({EXT}4, F2FS, {BTRFS}) with {HDDs} and {SSDs} respectively, to study the performance potentials of {LSM}-trees. Evaluation results show that the write throughputs of {LSM}-trees can be improved by from 1.8× to 3× on {HDDs}, and from 1.3× to 2.5× on {SSDs}, by employing the {LSM}-tree friendly data layout of {LDS}.},
	pages = {142--156},
	booktitle = {{SoCC} 2017 - Proceedings of the 2017 Symposium on Cloud Computing},
	publisher = {Association for Computing Machinery, Inc},
	author = {Mei, Fei and Cao, Qiang and Jiang, Hong and Tian, Lei},
	date = {2017-09-24},
	keywords = {{LSM}-tree, Application managed storage, File system performance, Key-value store},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/3FVCKGFB/3127479.3127486.pdf:application/pdf},
}

@article{zhao_autumn_2023,
	title = {Autumn: A Scalable Read Optimized {LSM}-tree based Key-Value Stores with Fast Point and Range Read Speed},
	url = {http://arxiv.org/abs/2305.05074},
	abstract = {The Log Structured Merge Trees ({LSM}-tree) based key-value stores are widely used in many storage systems to support a variety of operations such as updates, point reads, and range reads. Traditionally, {LSM}-tree's merge policy organizes data into multiple levels of exponentially increasing capacity to support high-speed writes. However, we contend that the traditional merge policies are not optimized for reads. In this work, we present Autumn, a scalable and read optimized {LSM}-tree based key-value stores with minimal point and range read cost. The key idea in improving the read performance is to dynamically adjust the capacity ratio between two adjacent levels as more data are stored. As a result, smaller levels gradually increase their capacities and merge more often. In particular, the point and range read cost improves from the previous best known \$O({logN})\$ complexity to \$O({\textbackslash}sqrt\{{logN}\})\$ in Autumn by applying the novel Garnering merge policy. While Garnering merge policy optimizes for both point reads and range reads, it maintains high performance for updates. Moreover, to further improve the update costs, Autumn uses a small amount of bounded space of {DRAM} to pin/keep the first level of {LSM}-tree. We implemented Autumn on top of {LevelDB} and experimentally showcases the gain in performance for real world workloads.},
	author = {Zhao, Fuheng and Miller, Zach and Reznikov, Leron and Agrawal, Divyakant and Abbadi, Amr El},
	date = {2023-05-08},
	eprinttype = {arxiv},
	eprint = {2305.05074},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/47IZ26B2/2305.05074v2.pdf:application/pdf},
}

@report{qin_loglog-beta_nodate,
	title = {{LogLog}-Beta and More: A New Algorithm for Cardinality Estimation Based on {LogLog} Counting},
	abstract = {​-The information presented in this paper defines {LogLog}-Beta ({LogLog}-β). {LogLog}-β is a new algorithm for estimating cardinalities based on {LogLog} counting. The new algorithm uses only one formula and needs no additional bias corrections for the entire range of cardinalities, therefore, it is more efficient and simpler to implement. Our simulations show that the accuracy provided by the new algorithm is as good as or better than the accuracy provided by either of {HyperLogLog} or {HyperLogLog}++. In addition to {LogLog}-β we also provide another one-formula estimator for cardinalities based on order statistics, a modification of an algorithm described in Lumbroso's work.},
	author = {Qin, Jason and Kim, Denys and Tung, Yumei},
	keywords = {Approximation algorithms, Data Mining, Index Terms​-Data analysis},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/6U28IKPL/1612.02284v3.pdf:application/pdf},
}

@report{flajolet_hyperloglog_2007,
	title = {{HyperLogLog}: the analysis of a near-optimal cardinality estimation algorithm},
	abstract = {This extended abstract describes and analyses a near-optimal probabilistic algorithm, {HYPERLOGLOG}, dedicated to estimating the number of distinct elements (the cardinality) of very large data ensembles. Using an auxiliary memory of m units (typically, "short bytes"), {HYPERLOGLOG} performs a single pass over the data and produces an estimate of the cardinality such that the relative accuracy (the standard error) is typically about 1.04/ √ m. This improves on the best previously known cardinality estimator, {LOGLOG}, whose accuracy can be matched by consuming only 64\% of the original memory. For instance, the new algorithm makes it possible to estimate cardinalities well beyond 10 9 with a typical accuracy of 2\% while using a memory of only 1.5 kilobytes. The algorithm parallelizes optimally and adapts to the sliding window model.},
	pages = {7},
	author = {Flajolet, Philippe and Fusy, Éric and Gandouet, Olivier and Meunier, Frédéric},
	date = {2007},
	note = {Publication Title: {AofA}},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/ZQP3YGWJ/FlFuGaMe07.pdf:application/pdf},
}

@report{durand_loglog_nodate,
	title = {Loglog Counting of Large Cardinalities},
	abstract = {Using an auxiliary memory smaller than the size of this abstract , the {LogLog} algorithm makes it possible to estimate in a single pass and within a few percents the number of different words in the whole of Shakespeare's works. In general the {LogLog} algorithm makes use of m "small bytes" of auxiliary memory in order to estimate in a single pass the number of distinct elements (the "cardinality") in a file, and it does so with an accuracy that is of the order of 1/ √ m. The "small bytes" to be used in order to count cardinalities till Nmax comprise about log log Nmax bits, so that cardinalities well in the range of billions can be determined using one or two kilobytes of memory only. The basic version of the {LogLog} algorithm is validated by a complete analysis. An optimized version, super-{LogLog}, is also engineered and tested on real-life data. The algorithm parallelizes optimally.},
	author = {Durand, Marianne and Flajolet, Philippe},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/CCTHS3ZI/DuFl03-LNCS.pdf:application/pdf},
}

@inproceedings{heule_hyperloglog_2013,
	location = {Genoa Italy},
	title = {{HyperLogLog} in practice: algorithmic engineering of a state of the art cardinality estimation algorithm},
	isbn = {978-1-4503-1597-5},
	url = {https://dl.acm.org/doi/10.1145/2452376.2452456},
	doi = {10.1145/2452376.2452456},
	shorttitle = {{HyperLogLog} in practice},
	abstract = {Cardinality estimation has a wide range of applications and is of particular importance in database systems. Various algorithms have been proposed in the past, and the {HyperLogLog} algorithm is one of them. In this paper, we present a series of improvements to this algorithm that reduce its memory requirements and signiﬁcantly increase its accuracy for an important range of cardinalities. We have implemented our proposed algorithm for a system at Google and evaluated it empirically, comparing it to the original {HyperLogLog} algorithm. Like {HyperLogLog}, our improved algorithm parallelizes perfectly and computes the cardinality estimate in a single pass.},
	eventtitle = {{EDBT}/{ICDT} '13: Joint 2013 {EDBT}/{ICDT} Conferences},
	pages = {683--692},
	booktitle = {Proceedings of the 16th International Conference on Extending Database Technology},
	publisher = {{ACM}},
	author = {Heule, Stefan and Nunkesser, Marc and Hall, Alexander},
	urldate = {2024-11-17},
	date = {2013-03-18},
	langid = {english},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/Q44PWEWQ/Heule et al. - 2013 - HyperLogLog in practice algorithmic engineering of a state of the art cardinality estimation algori.pdf:application/pdf},
}

@article{ertl_ultraloglog_2024,
	title = {{UltraLogLog}: A Practical and More Space-Efficient Alternative to {HyperLogLog} for Approximate Distinct Counting},
	volume = {17},
	issn = {2150-8097},
	url = {http://arxiv.org/abs/2308.16862},
	doi = {10.14778/3654621.3654632},
	shorttitle = {{UltraLogLog}},
	abstract = {Since its invention {HyperLogLog} has become the standard algorithm for approximate distinct counting. Due to its space efficiency and suitability for distributed systems, it is widely used and also implemented in numerous databases. This work presents {UltraLogLog}, which shares the same practical properties as {HyperLogLog}. It is commutative, idempotent, mergeable, and has a fast guaranteed constant-time insert operation. At the same time, it requires 28\% less space to encode the same amount of distinct count information, which can be extracted using the maximum likelihood method. Alternatively, a simpler and faster estimator is proposed, which still achieves a space reduction of 24\%, but at an estimation speed comparable to that of {HyperLogLog}. In a non-distributed setting where martingale estimation can be used, {UltraLogLog} is able to reduce space by 17\%. Moreover, its smaller entropy and its 8-bit registers lead to better compaction when using standard compression algorithms. All this is verified by experimental results that are in perfect agreement with the theoretical analysis which also outlines potential for even more space-efficient data structures. A production-ready Java implementation of {UltraLogLog} has been released as part of the open-source Hash4j library.},
	pages = {1655--1668},
	number = {7},
	journaltitle = {Proceedings of the {VLDB} Endowment},
	shortjournal = {Proc. {VLDB} Endow.},
	author = {Ertl, Otmar},
	urldate = {2024-11-17},
	date = {2024-03},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2308.16862 [cs]},
	keywords = {Computer Science - Data Structures and Algorithms, Computer Science - Databases},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/BFUCL6H7/Ertl - 2024 - UltraLogLog A Practical and More Space-Efficient Alternative to HyperLogLog for Approximate Distinc.pdf:application/pdf},
}

@misc{ertl_new_2017,
	title = {New cardinality estimation algorithms for {HyperLogLog} sketches},
	url = {http://arxiv.org/abs/1702.01284},
	abstract = {This paper presents new methods to estimate the cardinalities of data sets recorded by {HyperLogLog} sketches. A theoretically motivated extension to the original estimator is presented that eliminates the bias for small and large cardinalities. Based on the maximum likelihood principle a second unbiased method is derived together with a robust and efficient numerical algorithm to calculate the estimate. The maximum likelihood approach can also be applied to more than a single {HyperLogLog} sketch. In particular, it is shown that it gives more precise cardinality estimates for union, intersection, or relative complements of two sets that are both represented by {HyperLogLog} sketches compared to the conventional technique using the inclusion-exclusion principle. All the new methods are demonstrated and verified by extensive simulations.},
	number = {{arXiv}:1702.01284},
	publisher = {{arXiv}},
	author = {Ertl, Otmar},
	urldate = {2024-11-17},
	date = {2017-02-23},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1702.01284 [cs]},
	keywords = {Computer Science - Data Structures and Algorithms},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/79F9KACM/Ertl - 2017 - New cardinality estimation algorithms for HyperLogLog sketches.pdf:application/pdf},
}

@article{ertl_setsketch_2021,
	title = {{SetSketch}: Filling the Gap between {MinHash} and {HyperLogLog}},
	volume = {14},
	issn = {2150-8097},
	url = {http://arxiv.org/abs/2101.00314},
	doi = {10.14778/3476249.3476276},
	shorttitle = {{SetSketch}},
	abstract = {{MinHash} and {HyperLogLog} are sketching algorithms that have become indispensable for set summaries in big data applications. While {HyperLogLog} allows counting different elements with very little space, {MinHash} is suitable for the fast comparison of sets as it allows estimating the Jaccard similarity and other joint quantities. This work presents a new data structure called {SetSketch} that is able to continuously fill the gap between both use cases. Its commutative and idempotent insert operation and its mergeable state make it suitable for distributed environments. Fast, robust, and easy-toimplement estimators for cardinality and joint quantities, as well as the ability to use {SetSketch} for similarity search, enable versatile applications. The presented joint estimator can also be applied to other data structures such as {MinHash}, {HyperLogLog}, or {HyperMinHash}, where it even performs better than the corresponding state-of-the-art estimators in many cases.},
	pages = {2244--2257},
	number = {11},
	journaltitle = {Proceedings of the {VLDB} Endowment},
	shortjournal = {Proc. {VLDB} Endow.},
	author = {Ertl, Otmar},
	urldate = {2024-11-17},
	date = {2021-07},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2101.00314 [cs]},
	keywords = {Computer Science - Data Structures and Algorithms, Computer Science - Databases},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/CCUXW26I/Ertl - 2021 - SetSketch Filling the Gap between MinHash and HyperLogLog.pdf:application/pdf},
}

@inproceedings{paterson_hyperloglog_2022,
	location = {Genoa, Italy},
	title = {{HyperLogLog}: Exponentially Bad in Adversarial Settings},
	rights = {https://doi.org/10.15223/policy-009},
	isbn = {978-1-66541-614-6},
	url = {https://ieeexplore.ieee.org/document/9797350/},
	doi = {10.1109/EuroSP53844.2022.00018},
	shorttitle = {{HyperLogLog}},
	abstract = {Computing the count of distinct elements in large data sets is a common task but naive approaches are memory-expensive. The {HyperLogLog} ({HLL}) algorithm (Flajolet et al., 2007) estimates a data set’s cardinality while using significantly less memory than a naive approach, at the cost of some accuracy. This trade-off makes the {HLL} algorithm very attractive for a wide range of applications such as database management and network monitoring, where an exact count may not be needed. The {HLL} algorithm and variants of it are implemented in systems such as Redis and Google Big Query. Recently, the {HLL} algorithm has started to be proposed for use in scenarios where the inputs may be adversarially generated, for example counting social network users or detection of network scanning attacks. This prompts an examination of the performance of the {HLL} algorithm in the face of adversarial inputs. We show that in such a setting, the {HLL} algorithm’s estimate of cardinality can be exponentially bad: when an adversary has access to the internals of the {HLL} algorithm and has some flexibility in choosing what inputs will be recorded, it can manipulate the cardinality estimate to be exponentially smaller than the true cardinality. We study both the original {HLL} algorithm and a more modern version of it (Ertl, 2017) that is used in Redis. We present experimental results confirming our theoretical analysis. Finally, we consider attack prevention: we show how to modify {HLL} in a simple way that provably prevents cardinality estimate manipulation attacks.},
	eventtitle = {2022 {IEEE} 7th European Symposium on Security and Privacy ({EuroS}\&P)},
	pages = {154--170},
	booktitle = {2022 {IEEE} 7th European Symposium on Security and Privacy ({EuroS}\&P)},
	publisher = {{IEEE}},
	author = {Paterson, Kenneth G. and Raynal, Mathilde},
	urldate = {2024-11-17},
	date = {2022-06},
	langid = {english},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/ZKIJYDDW/Paterson and Raynal - 2022 - HyperLogLog Exponentially Bad in Adversarial Settings.pdf:application/pdf},
}

@article{chabchoub_sliding_nodate,
	title = {Sliding {HyperLogLog}: Estimating cardinality in a data stream},
	author = {Chabchoub, Yousra and Hébrail, Georges},
	langid = {english},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/VUPNCMZK/Chabchoub and Hébrail - Sliding HyperLogLog Estimating cardinality in a data stream.pdf:application/pdf},
}

@misc{ohayon_extendedhyperloglog_2021,
	title = {{ExtendedHyperLogLog}: Analysis of a new Cardinality Estimator},
	url = {http://arxiv.org/abs/2106.06525},
	shorttitle = {{ExtendedHyperLogLog}},
	abstract = {We discuss the problem of counting distinct elements in a stream. A stream is usually considered as a sequence of elements that come one at a time. An exact solution to the problem requires memory space of the size of the stream. For many applications this solution is infeasible due to very large streams. The solution in that case, is to use a probabilistic data structure (also called sketch), from which we can estimate with high accuracy the cardinality of the stream. We present a new algorithm, {ExtendedHyperLogLog} ({EHLL}), which is based on the state-of-the-art algorithm, {HyperLogLog} ({HLL}). In order to achieve the same accuracy as {HLL}, {EHLL} uses 16\% less memory. In recent years, a martingale approach has bean developed. In the martingale setting we receive better accuracy at the price of not being able to merge sketches. {EHLL} also works in the martingale setting. Martingale {EHLL} achieves the same accuracy as Martingale {HLL} using 12\% less memory.},
	number = {{arXiv}:2106.06525},
	publisher = {{arXiv}},
	author = {Ohayon, Tal},
	urldate = {2024-11-17},
	date = {2021-06-17},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2106.06525 [cs]},
	keywords = {Computer Science - Data Structures and Algorithms},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/8KYRSR5Z/Ohayon - 2021 - ExtendedHyperLogLog Analysis of a new Cardinality Estimator.pdf:application/pdf},
}

@misc{pettie_simpler_2022,
	title = {Simpler and Better Cardinality Estimators for {HyperLogLog} and {PCSA}},
	url = {http://arxiv.org/abs/2208.10578},
	abstract = {Cardinality Estimation (aka Distinct Elements) is a classic problem in sketching with many industrial applications. Although sketching algorithms are fairly simple, analyzing the cardinality estimators is notoriously diﬃcult, and even today the state-of-the-art sketches such as {HyperLogLog} and (compressed) {PCSA} are not covered in graduate level Big Data courses.},
	number = {{arXiv}:2208.10578},
	publisher = {{arXiv}},
	author = {Pettie, Seth and Wang, Dingyu},
	urldate = {2024-11-17},
	date = {2022-08-22},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2208.10578 [cs]},
	keywords = {Computer Science - Data Structures and Algorithms},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/6LTFPNN3/Pettie and Wang - 2022 - Simpler and Better Cardinality Estimators for HyperLogLog and PCSA.pdf:application/pdf},
}

@misc{karppa_hyperlogloglog_2022,
	title = {{HyperLogLogLog}: Cardinality Estimation With One Log More},
	url = {http://arxiv.org/abs/2205.11327},
	shorttitle = {{HyperLogLogLog}},
	abstract = {We present {HyperLogLogLog}, a practical compression of the {HyperLogLog} sketch that compresses the sketch from 𝑂 (𝑚 log log 𝑛) bits down to 𝑚 log2 log2 log2 𝑚 + 𝑂 (𝑚 + log log 𝑛) bits for estimating the number of distinct elements 𝑛 using 𝑚 registers. The algorithm works as a drop-in replacement that preserves all estimation properties of the {HyperLogLog} sketch, it is possible to convert back and forth between the compressed and uncompressed representations, and the compressed sketch maintains mergeability in the compressed domain. The compressed sketch can be updated in amortized constant time, assuming 𝑛 is sufficiently larger than 𝑚. We provide a C++ implementation of the sketch, and show by experimental evaluation against well-known implementations by Google and Apache that our implementation provides small sketches while maintaining competitive update and merge times. Concretely, we observed approximately a 40\% reduction in the sketch size. Furthermore, we obtain as a corollary a theoretical algorithm that compresses the sketch down to 𝑚 log2 log2 log2 log2 𝑚 + 𝑂 (𝑚 log log log 𝑚/log log 𝑚 + log log 𝑛) bits.},
	number = {{arXiv}:2205.11327},
	publisher = {{arXiv}},
	author = {Karppa, Matti and Pagh, Rasmus},
	urldate = {2024-11-17},
	date = {2022-05-23},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2205.11327 [cs]},
	keywords = {Computer Science - Data Structures and Algorithms},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/Z7WYKY7W/Karppa and Pagh - 2022 - HyperLogLogLog Cardinality Estimation With One Log More.pdf:application/pdf},
}

@article{oneil_lru-k_nodate,
	title = {The {LRU}-K Page Replacement Algorithm For Database Disk Buffering},
	abstract = {This paper introduces a new approach to database disk buffering, called the {LRU}-K method. The basic idea of {LRU}-K is to keep track of the times of the last K references to popular database pages, using this information to statistieall y estimate the interarrival times of references on a page by page basis. Although the {LRU}-K approach performs optimal statistical inference under relatively standard assmuptions, it is fairly simple and incurs little bookkeeping overhead. As we demonstrate with simulation experiments, the {LRU}-K algorithm surpasses conventional buffering algorithms in discriminating between frequently and infrequently referenced pages. In fact, {LRU}-K an approach the behavior of buffering algorithms in which page sets with known access frequencies are manually assigned to different buffer pools of specifically tuned sizes. Unlike such customized buffering algorithms however, the {LRU}-K method is self-tuning, and does not rely on external hints about workload characteristics. Furthermore, the {LRU}-K algo rithm adapts in real time to changing patterns of access.},
	author = {O’Neil, J and O’Neill, E},
	langid = {english},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/P7C8ELSA/O’Neil and O’Neill - The LRU-K Page Replacement Algorithm For Database Disk Buffering.pdf:application/pdf},
}

@article{yang_leaper_2020,
	title = {Leaper: a learned prefetcher for cache invalidation in {LSM}-tree based storage engines},
	volume = {13},
	issn = {2150-8097},
	url = {https://dl.acm.org/doi/10.14778/3407790.3407803},
	doi = {10.14778/3407790.3407803},
	shorttitle = {Leaper},
	abstract = {Frequency-based cache replacement policies that work well on page-based database storage engines are no longer suﬃcient for the emerging {LSM}-tree (Log-Structure Merge-tree) based storage engines. Due to the append-only and copyon-write techniques applied to accelerate writes, the stateof-the-art {LSM}-tree adopts mutable record blocks and issues frequent background operations (i.e., compaction, ﬂush) to reorganize records in possibly every block. As a side-eﬀect, such operations invalidate the corresponding entries in the cache for each involved record, causing sudden drops on the cache hit rates and spikes on access latency. Given the observation that existing methods cannot address this cache invalidation problem, we propose Leaper, a machine learning method to predict hot records in an {LSM}-tree storage engine and prefetch them into the cache without being disturbed by background operations. We implement Leaper in a state-of-the-art {LSM}-tree storage engine, X-Engine, as a light-weight plug-in. Evaluation results show that Leaper eliminates about 70\% cache invalidations and 99\% latency spikes with at most 0.95\% overheads as measured in realworld workloads.},
	pages = {1976--1989},
	number = {12},
	journaltitle = {Proceedings of the {VLDB} Endowment},
	shortjournal = {Proc. {VLDB} Endow.},
	author = {Yang, Lei and Wu, Hong and Zhang, Tieying and Cheng, Xuntao and Li, Feifei and Zou, Lei and Wang, Yujie and Chen, Rongyao and Wang, Jianying and Huang, Gui},
	urldate = {2024-11-22},
	date = {2020-08},
	langid = {english},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/85E9BPJ5/Yang et al. - 2020 - Leaper a learned prefetcher for cache invalidation in LSM-tree based storage engines.pdf:application/pdf},
}

@article{huynh_towards_2024,
	title = {Towards flexibility and robustness of {LSM} trees},
	volume = {33},
	issn = {1066-8888, 0949-877X},
	url = {https://link.springer.com/10.1007/s00778-023-00826-9},
	doi = {10.1007/s00778-023-00826-9},
	abstract = {Log-structured merge trees ({LSM} trees) are increasingly used as part of the storage engine behind several data systems, and are frequently deployed in the cloud. As the number of applications relying on {LSM}-based storage backends increases, the problem of performance tuning of {LSM} trees receives increasing attention. We consider both nominal tunings—where workload and execution environment are accurately known a priori—and robust tunings—which consider uncertainty in the workload knowledge. This type of workload uncertainty is common in modern applications, notably in shared infrastructure environments like the public cloud. To address this problem, we introduce Endure, a new paradigm for tuning {LSM} trees in the presence of workload uncertainty. Speciﬁcally, we focus on the impact of the choice of compaction policy, size ratio, and memory allocation on the overall performance. Endure considers a robust formulation of the throughput maximization problem and recommends a tuning that offers near-optimal throughput when the executed workload is not the same, instead in a neighborhood of the expected workload. Additionally, we explore the robustness of ﬂexible {LSM} designs by proposing a new uniﬁed design called K-{LSM} that encompasses existing designs. We deploy our robust tuning system, Endure, on a stateof-the-art key-value store, {RocksDB}, and demonstrate throughput improvements of up to 5× in the presence of uncertainty. Our results indicate that the tunings obtained by Endure are more robust than tunings obtained under our expanded {LSM} design space. This indicates that robustness may not be inherent to a design, instead, it is an outcome of a tuning process that explicitly accounts for uncertainty.},
	pages = {1105--1128},
	number = {4},
	journaltitle = {The {VLDB} Journal},
	shortjournal = {The {VLDB} Journal},
	author = {Huynh, Andy and Chaudhari, Harshal A. and Terzi, Evimaria and Athanassoulis, Manos},
	urldate = {2024-11-22},
	date = {2024-07},
	langid = {english},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/76SE3BEG/Huynh et al. - 2024 - Towards flexibility and robustness of LSM trees.pdf:application/pdf},
}

@inproceedings{dayan_chucky_2021,
	location = {Virtual Event China},
	title = {Chucky: A Succinct Cuckoo Filter for {LSM}-Tree},
	isbn = {978-1-4503-8343-1},
	url = {https://dl.acm.org/doi/10.1145/3448016.3457273},
	doi = {10.1145/3448016.3457273},
	shorttitle = {Chucky},
	abstract = {Modern key-value stores typically rely on an {LSM}-tree in storage ({SSD}) to handle writes and Bloom filters in memory ({DRAM}) to optimize reads. With ongoing advances in {SSD} technology shrinking the performance gap between storage and memory devices, the Bloom filters are now emerging as a performance bottleneck. We propose Chucky, a new design that replaces the multiple Bloom filters by a single Cuckoo filter that maps each data entry to an auxiliary address of its location within the {LSM}-tree. We show that while such a design entails fewer memory accesses than with Bloom filters, its false positive rate off the bat is higher. The reason is that the auxiliary addresses occupy bits that would otherwise be used as parts of the Cuckoo filter’s fingerprints. To address this, we harness techniques from information theory to succinctly encode the auxiliary addresses so that the fingerprints can stay large. As a result, Chucky achieves the best of both worlds: a modest access cost and a low false positive rate at the same time.},
	eventtitle = {{SIGMOD}/{PODS} '21: International Conference on Management of Data},
	pages = {365--378},
	booktitle = {Proceedings of the 2021 International Conference on Management of Data},
	publisher = {{ACM}},
	author = {Dayan, Niv and Twitto, Moshe},
	urldate = {2024-11-22},
	date = {2021-06-09},
	langid = {english},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/PTD42GCU/Dayan and Twitto - 2021 - Chucky A Succinct Cuckoo Filter for LSM-Tree.pdf:application/pdf},
}

@inproceedings{zhang_pipelined_2014,
	location = {Phoenix, {AZ}, {USA}},
	title = {Pipelined Compaction for the {LSM}-Tree},
	isbn = {978-1-4799-3800-1 978-1-4799-3799-8},
	url = {https://ieeexplore.ieee.org/document/6877309},
	doi = {10.1109/IPDPS.2014.85},
	abstract = {Write-optimized data structures like Log-Structured Merge-tree ({LSM}-tree) and its variants are widely used in key-value storage systems like {BigTable} and Cassandra. Due to deferral and batching, the {LSM}-tree based storage systems need background compactions to merge key-value entries and keep them sorted for future queries and scans. Background compactions play a key role on the performance of the {LSM}-tree based storage systems. Existing studies about the background compaction focus on decreasing the compaction frequency, reducing I/Os or conﬁning compactions on hot data key-ranges. They do not pay much attention to the computation time in background compactions. However, the computation time is no longer negligible, and even the computation takes more than 60\% of the total compaction time in storage systems using ﬂashbased {SSDs}. Therefore, an alternative method to speedup the compaction is to make good use of the parallelism of underlying hardware including {CPUs} and I/O devices.},
	eventtitle = {2014 {IEEE} International Parallel \& Distributed Processing Symposium ({IPDPS})},
	pages = {777--786},
	booktitle = {2014 {IEEE} 28th International Parallel and Distributed Processing Symposium},
	publisher = {{IEEE}},
	author = {Zhang, Zigang and Yue, Yinliang and He, Bingsheng and Xiong, Jin and Chen, Mingyu and Zhang, Lixin and Sun, Ninghui},
	urldate = {2024-11-22},
	date = {2014-05},
	langid = {english},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/EEKZTPWU/Zhang et al. - 2014 - Pipelined Compaction for the LSM-Tree.pdf:application/pdf},
}

@article{wu_lsm-trie_nodate,
	title = {{LSM}-trie: An {LSM}-tree-based Ultra-Large Key-Value Store for Small Data},
	abstract = {Key-value ({KV}) stores have become a backbone of largescale applications in today’s data centers. The data set of the store on a single server can grow to billions of {KV} items or many terabytes, while individual data items are often small (with their values as small as a couple of bytes). It is a daunting task to efﬁciently organize such an ultra-large {KV} store to support fast access. Current {KV} storage systems have one or more of the following inadequacies: (1) very high data write ampliﬁcations, (2) large index set, and (3) dramatic degradation of read performance with overspill index out of memory.},
	author = {Wu, Xingbo and Xu, Yuehai and Jiang, Song},
	langid = {english},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/3Z55Q4RB/Wu et al. - LSM-trie An LSM-tree-based Ultra-Large Key-Value Store for Small Data.pdf:application/pdf},
}

@article{dayan_spooky_2022,
	title = {Spooky: granulating {LSM}-tree compactions correctly},
	volume = {15},
	issn = {2150-8097},
	url = {https://dl.acm.org/doi/10.14778/3551793.3551853},
	doi = {10.14778/3551793.3551853},
	shorttitle = {Spooky},
	abstract = {Modern storage engines and key-value stores have come to rely on the log-structured merge-tree ({LSM}-tree) as their core data structure. {LSM}-tree operates by gradually merge-sorting data across levels of exponentially increasing capacities in storage. A crucial design dimension of {LSM}-tree is its compaction granularity. Some designs perform Full Merge, whereby entire levels get compacted at once. Others perform Partial Merge, whereby smaller groups of files with overlapping key ranges are compacted independently. This paper shows that both strategies exhibit serious flaws. With Full Merge, space-amplification is exorbitant. The reason is that while compacting the {LSM}-tree’s largest level, there must be at least twice as much storage space as data to store both the original and new files until the compaction is finished. On the other hand, Partial Merge exhibits excessive write-amplification. The reason is twofold. (1) The files getting compacted typically do not have perfectly overlapping key ranges, and so some non-overlapping data is superfluously rewritten in each compaction. (2) Files with different lifetimes become interspersed within the {SSD} leading to high {SSD} garbage-collection overheads. As the data size grows, these problems grow in magnitude.},
	pages = {3071--3084},
	number = {11},
	journaltitle = {Proceedings of the {VLDB} Endowment},
	shortjournal = {Proc. {VLDB} Endow.},
	author = {Dayan, Niv and Weiss, Tamar and Dashevsky, Shmuel and Pan, Michael and Bortnikov, Edward and Twitto, Moshe},
	urldate = {2024-11-22},
	date = {2022-07},
	langid = {english},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/YS9XVDED/Dayan et al. - 2022 - Spooky granulating LSM-tree compactions correctly.pdf:application/pdf},
}

@article{matsunobu_myrocks_2020,
	title = {{MyRocks}: {LSM}-tree database storage engine serving Facebook's social graph},
	volume = {13},
	issn = {2150-8097},
	url = {https://dl.acm.org/doi/10.14778/3415478.3415546},
	doi = {10.14778/3415478.3415546},
	shorttitle = {{MyRocks}},
	abstract = {Facebook uses {MySQL} to manage tens of petabytes of data in its main database named the User Database ({UDB}). {UDB} serves social activities such as likes, comments, and shares. In the past, Facebook used {InnoDB}, a B+Tree based storage engine as the backend. The challenge was to find an index structure using less space and write amplification [1]. {LSM}-tree [2] has the potential to greatly improve these two bottlenecks. {RocksDB}, an {LSM} tree-based key/value store was already widely used in variety of applications but had a very low-level key-value interface. To overcome these limitations, {MyRocks}, a new {MySQL} storage engine, was built on top of {RocksDB} by adding relational capabilities. With {MyRocks}, using the {RocksDB} {API}, significant efficiency gains were achieved while still benefiting from all the {MySQL} features and tools. The transition was mostly transparent to client applications.},
	pages = {3217--3230},
	number = {12},
	journaltitle = {Proceedings of the {VLDB} Endowment},
	shortjournal = {Proc. {VLDB} Endow.},
	author = {Matsunobu, Yoshinori and Dong, Siying and Lee, Herman},
	urldate = {2024-11-22},
	date = {2020-08},
	langid = {english},
	file = {PDF:/Users/alex/Documents/Zotoro/storage/DF4GMEH3/Matsunobu et al. - 2020 - MyRocks LSM-tree database storage engine serving Facebook's social graph.pdf:application/pdf},
}
